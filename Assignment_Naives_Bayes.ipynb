{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opdracht classificatie - Naive Bayes & NLP\n",
    "\n",
    "Sinds enkele jaren schieten de Natural Language Processing toepassingen als paddenstoelen uit de grond. Eén van de belangrijkste redenen daarvoor is de steeds groter wordende beschikbaarheid van tekstuele data aangeleverd door bijvoorbeeld social media. \n",
    "\n",
    "In deze opdracht zal NLP toegepast worden in het kader van sentiment analysis.\n",
    "De bedoeling van sentiment analysis is om uit een tekstueel bericht zoals een email, sms, twitter bericht, Trip Advisor review het sentiment te voorspellen.\n",
    "Bedrijven weten bijvoorbeeld graag wat het sentiment is in de berichten die online over hen verschijnen.\n",
    "\n",
    "\n",
    "De opdracht bestaat uit vier deelopdrachten.\n",
    "- De eerste deelopdracht gaat rond het uitvoeren van pure sentiment analysis van tekstberichten.\n",
    "- Bij de tweede deelopdracht is het de bedoeling om op basis van een review die een klant over een gekocht product heeft geschreven de rating te voorspellen die de klant aan het gekochte product toekent. \n",
    "- De derde deelopdracht gaat over het opsporen van cyber trolls aan de hand van de berichten die ze op het internet plaatsen.\n",
    "- De vierde deelopdracht bestaat uit het detecteren van sarcasme in tekstberichten \n",
    "\n",
    "Telkens wordt het bag-of-words model gebruikt om tekst voor te stellen en vervolgens worden verschillende classifiers getraind om het sentiment/rating te voorspellen.\n",
    "\n",
    "Het bag-of-words model beschrijft het voorkomen van woorden binnen een document en doet dit op bais van een vocabulair van gekende woorden en meet de aanwezigheid van deze gekende woorden.\n",
    "De grote beperking van het bag-of-words model is dat het enkel rekening houdt met welke woorden in een bericht voorkomen en niet met de volgorde ervan. Daardoor is het bag-of-words model heel beperkt in het capteren van de context waarin woorden in een bericht voorkomen .\n",
    "Tijdens de module deep learning zullen we afstappen van het bag-of-words model en gebruik maken van word embeddings in combinatie met LSTM neurale netwerken. Op deze manier kunnen we modellen trainen die wel rekening houden met de context en woordvolgordes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re #regular expressions\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deel 1 - Sentiment analysis \n",
    "\n",
    "Bij deze deelopdracht is het de bedoeling om het sentiment van tekstberichten te classificeren in negatief of positief.\n",
    "De training set en de test set zijn te vinden in de bestanden *sentiment_train.csv* en *sentiment_test.csv*.\n",
    "\n",
    "De stappen die doorlopen dienen te worden zijn:\n",
    "\n",
    "1. Vooranalyse van de data.\n",
    "2. Preprocessing van de tekst.\n",
    "3. Omzetten naar bag-of-words.\n",
    "4. Trainen van de classifiers.\n",
    "5. Testen van de getrainde classifiers + uitvoeren van hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5918,)\n",
      "(5918,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Da Vinci Code book is just awesome.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Oh, and Brokeback Mountain was a terrible movie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>He's like,'YEAH I GOT ACNE AND I LOVE BROKEBAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1st and 2nd Harry Potter movies are clearly th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Mission Impossible 3 was quite boring.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          1            The Da Vinci Code book is just awesome.\n",
       "1          0   Oh, and Brokeback Mountain was a terrible movie.\n",
       "2          1  He's like,'YEAH I GOT ACNE AND I LOVE BROKEBAC...\n",
       "3          1  1st and 2nd Harry Potter movies are clearly th...\n",
       "4          0             Mission Impossible 3 was quite boring."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importeren van de datasets\n",
    "\n",
    "dataset_train = pd.read_csv('sentiment_train.csv')\n",
    "dataset_test = pd.read_csv('sentiment_test.csv')\n",
    "\n",
    "# Opsplitsen in features en targets\n",
    "X_train = dataset_train['text'].values\n",
    "y_train = dataset_train['sentiment'].values\n",
    "\n",
    "X_test = dataset_test['text'].values\n",
    "y_test = dataset_test['sentiment'].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "dataset_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Vooranalyse van de data\n",
    "\n",
    "- Onderzoek of er ontbrekende waarden in de datasets voorkomen.\n",
    "- Is de dataset gebalanceerd?\n",
    "- Onderzoek of er een correlatie te vinden is tussen de lengte van een bericht enerzijds en het sentiment anderzijds. Dit mag grafisch (via bijvoorbeeld een boxplot) of via correlatiecoëfficiënten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment         0\n",
      "text              0\n",
      "Message Length    0\n",
      "dtype: int64\n",
      "No missing values in training set.\n",
      "sentiment    0\n",
      "text         0\n",
      "dtype: int64\n",
      "No missing values in test set.\n"
     ]
    }
   ],
   "source": [
    "# Vooranalyse van de data\n",
    "# onderzoek of er ontbrekende waarden in de datasets voorkomen\n",
    "print(dataset_train.isnull().sum())\n",
    "print('No missing values in training set.')\n",
    "# test\n",
    "print(dataset_test.isnull().sum())\n",
    "print('No missing values in test set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3383\n",
       "0    2535\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# gebalanceerdheid controleren\n",
    "sns.countplot(x='sentiment',data=dataset_train)\n",
    "\n",
    "dataset_train['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not perfectly balanced. There are approximately 850 samples more in the positive class than in the negative class. The classifier has a preference for the class with sentiment (class 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c1c22f87c0>"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Onderzoek of er een correlatie te vinden is tussen de lengte van een bericht enerzijds en het sentiment anderzijds. Dit mag grafisch (via bijvoorbeeld een boxplot) of via correlatiecoëfficiënten.\n",
    "\n",
    "dataset_train['Message Length']=dataset_train['text'].apply(len)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.boxplot(x='sentiment', y='Message Length', data=dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Message Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.046637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Message Length</th>\n",
       "      <td>-0.046637</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                sentiment  Message Length\n",
       "sentiment        1.000000       -0.046637\n",
       "Message Length  -0.046637        1.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation coefficient of -0.04 indicates that the relationship is negative and has very little, almost no correlation. This means that the sentiment and the message length has no correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing van de tekst\n",
    "\n",
    "- Kuis de teksten op: verwijder stopwoorden en niet-letters, zet alles om naar lowercase, ... \n",
    "- Pas stemming toe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing van de tekst\n",
    "\n",
    "def text_preprocessing(text, language, minWordSize):\n",
    "    \n",
    "    # remove html\n",
    "    text_no_html = BeautifulSoup(str(text),\"html.parser\" ).get_text()\n",
    "    \n",
    "    # remove non-letters\n",
    "    text_alpha_chars = re.sub(\"[^a-zA-Z']\", \" \", str(text_no_html)) \n",
    "        \n",
    "    # convert to lower-case\n",
    "    text_lower = text_alpha_chars.lower()\n",
    "    \n",
    "    # remove stop words\n",
    "    stops = set(stopwords.words(language)) \n",
    "    text_no_stop_words = ' '\n",
    "    \n",
    "    for w in text_lower.split():\n",
    "        if w not in stops:  \n",
    "            text_no_stop_words = text_no_stop_words + w + ' '\n",
    "      \n",
    "       # do stemming\n",
    "    text_stemmer = ' '\n",
    "    stemmer = SnowballStemmer(language)\n",
    "    for w in text_no_stop_words.split():\n",
    "        text_stemmer = text_stemmer + stemmer.stem(w) + ' '\n",
    "         \n",
    "    # remove short words\n",
    "    text_no_short_words = ' '\n",
    "    for w in text_stemmer.split(): \n",
    "        if len(w) >=minWordSize:\n",
    "            text_no_short_words = text_no_short_words + w + ' '\n",
    " \n",
    "\n",
    "    return text_no_short_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert training and test set to bag of words\n",
    "language = 'english'\n",
    "minWordLength = 2\n",
    "\n",
    "for i in range(X_train.size):\n",
    "    X_train[i] = text_preprocessing(X_train[i], language, minWordLength)\n",
    "    \n",
    "    \n",
    "for i in range(X_test.size):\n",
    "    X_test[i] = text_preprocessing(X_test[i], language, minWordLength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Omzetten naar bag-of-words\n",
    "\n",
    "Maak gebruik van de CountVectorizer en TfidfTransformer om een bag-of-words model te creëren. \n",
    "\n",
    "Meer info: \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 88)\t1\n",
      "  (0, 149)\t1\n",
      "  (0, 247)\t1\n",
      "  (0, 314)\t1\n",
      "  (0, 1502)\t1\n",
      "  (1, 166)\t1\n",
      "  (1, 939)\t1\n",
      "  (1, 942)\t1\n",
      "  (1, 987)\t1\n",
      "  (1, 1389)\t1\n",
      "  (2, 12)\t1\n",
      "  (2, 166)\t1\n",
      "  (2, 596)\t1\n",
      "  (2, 637)\t1\n",
      "  (2, 834)\t1\n",
      "  (2, 860)\t1\n",
      "  (2, 939)\t1\n",
      "  (2, 1576)\t1\n",
      "  (3, 120)\t1\n",
      "  (3, 234)\t1\n",
      "  (3, 554)\t1\n",
      "  (3, 631)\t1\n",
      "  (3, 942)\t1\n",
      "  (3, 960)\t1\n",
      "  (3, 1080)\t1\n",
      "  :\t:\n",
      "  (5914, 787)\t1\n",
      "  (5914, 834)\t1\n",
      "  (5914, 923)\t1\n",
      "  (5914, 927)\t1\n",
      "  (5914, 1370)\t1\n",
      "  (5915, 166)\t1\n",
      "  (5915, 397)\t1\n",
      "  (5915, 860)\t1\n",
      "  (5915, 939)\t1\n",
      "  (5916, 247)\t1\n",
      "  (5916, 314)\t1\n",
      "  (5916, 798)\t1\n",
      "  (5916, 860)\t1\n",
      "  (5916, 948)\t1\n",
      "  (5916, 1035)\t1\n",
      "  (5916, 1502)\t1\n",
      "  (5916, 1560)\t1\n",
      "  (5917, 43)\t1\n",
      "  (5917, 298)\t1\n",
      "  (5917, 609)\t1\n",
      "  (5917, 631)\t1\n",
      "  (5917, 634)\t1\n",
      "  (5917, 798)\t1\n",
      "  (5917, 1080)\t1\n",
      "  (5917, 1513)\t1\n"
     ]
    }
   ],
   "source": [
    "# Omzetten naar bag-of-words\n",
    "\n",
    "# Make sparse features vectors \n",
    "\n",
    "# create instance \n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "# train the object on the training set\n",
    "X_train_bag_of_words = count_vect.fit(X_train)\n",
    "\n",
    "# apply  the function on train\n",
    "X_train_bag_of_words = count_vect.transform(X_train)\n",
    "# apply  the function on test\n",
    "X_test_bag_of_words = count_vect.transform(X_test)\n",
    "\n",
    "print(X_train_bag_of_words)\n",
    "#print(X_test_bag_of_words)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_bag_of_words)\n",
    "X_train_tf = tf_transformer.transform(X_train_bag_of_words)\n",
    "X_test_tf = tf_transformer.transform(X_test_bag_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Trainen van de classifiers\n",
    "\n",
    "Train drie verschillende classifiers op de bag-of-words data: naive bayes classifier, logistic regression classifier en een Support Vector Machine classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Naive bayes classifier\n",
    "\n",
    "NBclassifier = MultinomialNB(alpha=1)\n",
    "\n",
    "NBclassifier.fit(X_train_tf, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       440\n",
      "           1       0.97      0.99      0.98       560\n",
      "\n",
      "    accuracy                           0.98      1000\n",
      "   macro avg       0.98      0.98      0.98      1000\n",
      "weighted avg       0.98      0.98      0.98      1000\n",
      "\n",
      "[[422  18]\n",
      " [  5 555]]\n",
      "97.7\n"
     ]
    }
   ],
   "source": [
    "# test Naive Bayes classifier\n",
    "\n",
    "y_pred = NBclassifier.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a logistic regression classifier\n",
    "lregclassifier = LogisticRegression(C=10)\n",
    "\n",
    "lregclassifier.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       440\n",
      "           1       0.99      1.00      0.99       560\n",
      "\n",
      "    accuracy                           0.99      1000\n",
      "   macro avg       0.99      0.99      0.99      1000\n",
      "weighted avg       0.99      0.99      0.99      1000\n",
      "\n",
      "[[434   6]\n",
      " [  1 559]]\n",
      "99.3\n"
     ]
    }
   ],
   "source": [
    "# test logistic classifier\n",
    "\n",
    "y_pred = lregclassifier.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, kernel='linear')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a SVM\n",
    "SVMlinear = svm.SVC(kernel='linear',C=0.1)\n",
    "SVMlinear.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       440\n",
      "           1       0.99      1.00      0.99       560\n",
      "\n",
      "    accuracy                           0.99      1000\n",
      "   macro avg       0.99      0.99      0.99      1000\n",
      "weighted avg       0.99      0.99      0.99      1000\n",
      "\n",
      "[[432   8]\n",
      " [  0 560]]\n",
      "99.2\n"
     ]
    }
   ],
   "source": [
    "# test SVM\n",
    "y_pred = SVMlinear.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression has the highest accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Testen en hyperparameter tuning\n",
    "\n",
    "- Voer hyperparameter tuning uit via grid-search, random search of Bayes Optimization.\n",
    "- Welke classifier heeft jouw voorkeur? Beargumenteer in de context van accuracy, f1-score en berekeningstijd.\n",
    "- Stel dat er continu bijgeleerd moet worden op nieuwe data (dagelijks komen er nieuwe reviews/beoordelingen bij), welke methode geniet dan jouw voorkeur?\n",
    "- Welke classifier valt te verkiezen als je zo weinig mogelijk false positives wilt? (false positive = een tekst die verkeerdelijk als positief wordt geklassificeerd. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 5 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.9827639715987173\n",
      "Best parameters : {'alpha': 1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       440\n",
      "           1       0.97      0.99      0.98       560\n",
      "\n",
      "    accuracy                           0.98      1000\n",
      "   macro avg       0.98      0.98      0.98      1000\n",
      "weighted avg       0.98      0.98      0.98      1000\n",
      "\n",
      "[[422  18]\n",
      " [  5 555]]\n",
      "97.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning Naive Bayes - Grid Search\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "model = MultinomialNB()\n",
    "paramaters = [\n",
    "             {'alpha' : [0.001, 0.01, 0.1, 1, 10]}                                       \n",
    "             ]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = paramaters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 20,\n",
    "                           n_jobs = -1,\n",
    "                           verbose=5)\n",
    "grid_search = grid_search.fit(X_train_tf, y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_ \n",
    "best_parameters = grid_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', grid_search.best_score_)\n",
    "print('Best parameters :', grid_search.best_params_  )\n",
    "\n",
    "y_pred = grid_search.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best accuracy :  0.9832718866372712\n",
      "Best parameters : {'alpha': 1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       440\n",
      "           1       0.97      0.99      0.98       560\n",
      "\n",
      "    accuracy                           0.98      1000\n",
      "   macro avg       0.98      0.98      0.98      1000\n",
      "weighted avg       0.98      0.98      0.98      1000\n",
      "\n",
      "[[422  18]\n",
      " [  5 555]]\n",
      "97.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dominic Ho\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:278: UserWarning: The total space of parameters 5 is smaller than n_iter=20. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  25 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning Naive Bayes - Random Search\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# distributions\n",
    "from scipy.stats import randint \n",
    "from scipy.stats import uniform\n",
    "\n",
    "\n",
    "model = MultinomialNB()\n",
    "parameters = [\n",
    "             {'alpha' : [0.001, 0.01, 0.1, 1, 10]}                                       \n",
    "             ]\n",
    "\n",
    "# random search zoeken, bv 20 willekeurig random searches\n",
    "n_iter_search = 20\n",
    "\n",
    "# cv = cross validatie\n",
    "random_search = RandomizedSearchCV(model, param_distributions=parameters,cv=5,n_iter=n_iter_search,n_jobs = -1,verbose=1)\n",
    "\n",
    "random_search = random_search.fit(X_train_tf, y_train)\n",
    "\n",
    "best_accuracy = random_search.best_score_ \n",
    "best_parameters = random_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', random_search.best_score_)\n",
    "print('Best parameters :',random_search.best_params_  )\n",
    "\n",
    "y_pred = random_search.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 50 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done 970 tasks      | elapsed:   19.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.9957758818140174\n",
      "Best parameters : {'C': 100, 'class_weight': 'balanced', 'solver': 'saga'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       440\n",
      "           1       0.99      1.00      0.99       560\n",
      "\n",
      "    accuracy                           0.99      1000\n",
      "   macro avg       0.99      0.99      0.99      1000\n",
      "weighted avg       0.99      0.99      0.99      1000\n",
      "\n",
      "[[436   4]\n",
      " [  2 558]]\n",
      "99.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   20.7s finished\n",
      "C:\\Users\\Dominic Ho\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning Logistic Regression - Grid Search\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "paramaters = [\n",
    "             {'C' : [0.01, 0.1, 1, 10, 100], \n",
    "              'solver': ['liblinear','lbfgs', 'newton-cg', 'sag','saga'], \n",
    "              'class_weight': [None, 'balanced']},                                       \n",
    "             ]\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = paramaters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 20,\n",
    "                           n_jobs = -1,\n",
    "                           verbose=5)\n",
    "grid_search = grid_search.fit(X_train_tf, y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_ \n",
    "best_parameters = grid_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', grid_search.best_score_)\n",
    "print('Best parameters :', grid_search.best_params_  )\n",
    "\n",
    "y_pred = grid_search.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 20 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.9952691250572606\n",
      "Best parameters : {'C': 7.911338786767389, 'class_weight': None, 'solver': 'liblinear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       440\n",
      "           1       0.99      1.00      0.99       560\n",
      "\n",
      "    accuracy                           0.99      1000\n",
      "   macro avg       0.99      0.99      0.99      1000\n",
      "weighted avg       0.99      0.99      0.99      1000\n",
      "\n",
      "[[434   6]\n",
      " [  1 559]]\n",
      "99.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    9.4s finished\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning Logistic Regression - Random Search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint \n",
    "from scipy.stats import uniform\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "parameters = [\n",
    "             {'C' : uniform(0.01, 20), \n",
    "              'solver': ['liblinear','lbfgs', 'newton-cg', 'sag','saga'],\n",
    "              'class_weight': [None, 'balanced']}\n",
    "             ]\n",
    "\n",
    "              \n",
    "\n",
    "n_iter_search = 20\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_distributions=parameters,cv=20,n_iter=n_iter_search,n_jobs = -1,verbose=1)\n",
    "\n",
    "random_search = random_search.fit(X_train_tf, y_train)\n",
    "\n",
    "best_accuracy = random_search.best_score_ \n",
    "best_parameters = random_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', random_search.best_score_)\n",
    "print('Best parameters :',random_search.best_params_  )\n",
    "\n",
    "y_pred = random_search.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 960 candidates, totalling 19200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 16.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2170 tasks      | elapsed: 23.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed: 32.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3034 tasks      | elapsed: 41.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3520 tasks      | elapsed: 47.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed: 54.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4600 tasks      | elapsed: 61.5min\n",
      "[Parallel(n_jobs=-1)]: Done 5194 tasks      | elapsed: 68.1min\n",
      "[Parallel(n_jobs=-1)]: Done 5824 tasks      | elapsed: 75.5min\n",
      "[Parallel(n_jobs=-1)]: Done 6490 tasks      | elapsed: 83.3min\n",
      "[Parallel(n_jobs=-1)]: Done 7192 tasks      | elapsed: 90.0min\n",
      "[Parallel(n_jobs=-1)]: Done 7930 tasks      | elapsed: 98.9min\n",
      "[Parallel(n_jobs=-1)]: Done 8704 tasks      | elapsed: 108.7min\n",
      "[Parallel(n_jobs=-1)]: Done 9514 tasks      | elapsed: 118.9min\n",
      "[Parallel(n_jobs=-1)]: Done 10360 tasks      | elapsed: 129.7min\n",
      "[Parallel(n_jobs=-1)]: Done 11242 tasks      | elapsed: 140.2min\n",
      "[Parallel(n_jobs=-1)]: Done 12160 tasks      | elapsed: 159.4min\n",
      "[Parallel(n_jobs=-1)]: Done 13114 tasks      | elapsed: 176.4min\n",
      "[Parallel(n_jobs=-1)]: Done 14104 tasks      | elapsed: 195.1min\n",
      "[Parallel(n_jobs=-1)]: Done 15130 tasks      | elapsed: 215.6min\n",
      "[Parallel(n_jobs=-1)]: Done 16192 tasks      | elapsed: 234.1min\n",
      "[Parallel(n_jobs=-1)]: Done 17290 tasks      | elapsed: 258.9min\n",
      "[Parallel(n_jobs=-1)]: Done 18424 tasks      | elapsed: 279.3min\n",
      "[Parallel(n_jobs=-1)]: Done 19200 out of 19200 | elapsed: 293.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.9957758818140174\n",
      "Best parameters : {'C': 6.673333333333333, 'class_weight': None, 'degree': 2, 'gamma': 0.2, 'kernel': 'rbf'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       440\n",
      "           1       0.99      1.00      0.99       560\n",
      "\n",
      "    accuracy                           0.99      1000\n",
      "   macro avg       0.99      0.99      0.99      1000\n",
      "weighted avg       0.99      0.99      0.99      1000\n",
      "\n",
      "[[436   4]\n",
      " [  2 558]]\n",
      "99.4\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning SVM - Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC()\n",
    "\n",
    "paramaters = [ \n",
    "        {'kernel': ['linear'], \n",
    "         'C': np.linspace(0.01,20,10), \n",
    "         'degree': [2,3,4], \n",
    "         'class_weight': [None, 'balanced']},\n",
    "        {'kernel': ['rbf', 'poly', 'sigmoid'], \n",
    "         'C': np.linspace(0.01,20,10), \n",
    "         'gamma': [0.0001, 0.001, 0.01, 0.1, 0.2], \n",
    "         'degree': [2,3,4], \n",
    "         'class_weight': [None, 'balanced']},\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = paramaters,\n",
    "                           scoring = 'accuracy', \n",
    "                           cv = 20,\n",
    "                           n_jobs = -1,\n",
    "                           verbose =5)\n",
    "grid_search = grid_search.fit(X_train_tf, y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_ \n",
    "best_parameters = grid_search.best_params_  \n",
    "print('Best accuracy : ', grid_search.best_score_)\n",
    "print('Best parameters :', grid_search.best_params_  )\n",
    "\n",
    "\n",
    "y_pred = grid_search.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   55.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.9962817847433231\n",
      "Best parameters : {'C': 10.723832850344332, 'class_weight': 'balanced', 'degree': 3, 'gamma': 0.0999159800285068, 'kernel': 'rbf'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       440\n",
      "           1       0.99      1.00      0.99       560\n",
      "\n",
      "    accuracy                           0.99      1000\n",
      "   macro avg       0.99      0.99      0.99      1000\n",
      "weighted avg       0.99      0.99      0.99      1000\n",
      "\n",
      "[[436   4]\n",
      " [  2 558]]\n",
      "99.4\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning SVM - Random Search\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint \n",
    "from scipy.stats import uniform\n",
    "\n",
    "\n",
    "#svc trainen\n",
    "model = SVC()\n",
    "\n",
    "parameters = [\n",
    "    {'kernel': ['linear'], \n",
    "     'C': uniform(0.01, 20), \n",
    "     'degree': [2,3,4], \n",
    "     'class_weight': [None, 'balanced']\n",
    "    },\n",
    "    {'kernel': ['rbf', 'poly', 'sigmoid'], \n",
    "     'C': uniform(0.01, 20), \n",
    "     'gamma': uniform(0.001, 0.2), \n",
    "     'degree': [2,3,4], \n",
    "     'class_weight': [None, 'balanced']}\n",
    "]\n",
    " \n",
    "n_iter_search = 20\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_distributions=parameters,cv=5,n_iter=n_iter_search,n_jobs = -1,verbose=1)\n",
    "\n",
    "random_search = random_search.fit(X_train_tf, y_train)\n",
    "\n",
    "best_accuracy = random_search.best_score_ \n",
    "best_parameters = random_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', random_search.best_score_)\n",
    "print('Best parameters :',random_search.best_params_  )\n",
    "\n",
    "y_pred = random_search.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Welke classifier heeft jouw voorkeur? Beargumenteer in de context van accuracy, f1-score en berekeningstijd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general if we compare the 3 classifiers, we can see that they all are doing well when it comes to the scores with a minimum of 97% which is ideal for the model. Therefore, the execution time is important for deciding the most suitable classifier. When it comes to execution time the order is as follows: Naive Bayes, Logistic Regression and SVM.Eventhough the accuracy rate of SVM is similar as Logistic Regression, the execution is the slowest. Therefore SVM is not an option. On the other hand, is Naive Bayes the fastest with an accuracy rate of 97.7%, slightly less than the logistic regression with 99.4%. This means that there are always upsides and downsides when it comes to choosing classifiers. At last, if I had to choose then the logistic regression classifier will be my preference for this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Stel dat er continu bijgeleerd moet worden op nieuwe data (dagelijks komen er nieuwe reviews/beoordelingen bij), welke methode geniet dan jouw voorkeur?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive bayes as this is the fastest for processing new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Welke classifier valt te verkiezen als je zo weinig mogelijk false positives wilt? (false positive = een tekst die verkeerdelijk als positief wordt geklassificeerd. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By evaluating the model we can see in the confusion matrix that the logistic regression (grid search) and SVM (grid search and random search) are the most suitable classifier when it comes to the least false positives. Both have 4 samples while Naive Bayes has 18."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deel 2 - Webshop women clothing\n",
    "\n",
    "Het bestand 'Womens_Clothing_Reviews.csv' bevat een collectie reviews over aangekochte kledij bij een bepaalde webwinkel. Deze dataset bestaat uit 23486 rijen met telkens 10 variabelen:\n",
    "\n",
    "- clothing ID: categorische variabele die verwijst naar het gereviewde product.\n",
    "- Age: de leeftijd van de reviewer.\n",
    "- Titel: titel van de review.\n",
    "- Review text: de review zelf.\n",
    "- Rating: Een score die door de reviewer aan het product werd toegekend. De slechtst mogelijke score is 1, de best is 5.\n",
    "- Recommended IND: binaire variabele die aanduidt of de klant het product aanbeveelt. 1 = aanbevolen, 0 = niet aanbevolen.\n",
    "- Positive feedback count: getal dat aangeeft hoeveel andere klanten deze review positief vonden.\n",
    "- Division name: categorische variabele van de afdeling waartoe het product behoort.\n",
    "- Department name: categorische variabele die het type product weergeeft.\n",
    "- Class name: categorische variabele die de subcategorie weergeeft.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23486, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clothing ID  Age                    Title  \\\n",
       "0          767   33                      NaN   \n",
       "1         1080   34                      NaN   \n",
       "2         1077   60  Some major design flaws   \n",
       "3         1049   50         My favorite buy!   \n",
       "4          847   47         Flattering shirt   \n",
       "\n",
       "                                         Review Text  Rating  Recommended IND  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4                1   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5                1   \n",
       "2  I had such high hopes for this dress and reall...       3                0   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
       "4  This shirt is very flattering to all due to th...       5                1   \n",
       "\n",
       "   Positive Feedback Count   Division Name Department Name Class Name  \n",
       "0                        0       Initmates        Intimate  Intimates  \n",
       "1                        4         General         Dresses    Dresses  \n",
       "2                        0         General         Dresses    Dresses  \n",
       "3                        0  General Petite         Bottoms      Pants  \n",
       "4                        6         General            Tops    Blouses  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inlezen van de dataset\n",
    "\n",
    "dataset = pd.read_csv('./Womens_Clothing_Reviews.csv')\n",
    "\n",
    "# verwijder kolom unnamed\n",
    "dataset.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Vooranalyse van de data\n",
    "\n",
    "- Ga op zoek naar mogelijks ontbrekende waarden en verwijder de volledige rij via listwise deletion. Hoeveel reviews blijven nog over?\n",
    "- Welke leeftijdscategorie heeft het meest reviews gegeven (visualiseer via een histogram: https://matplotlib.org/api/_as_gen/matplotlib.pyplot.hist.html).\n",
    "\n",
    "- Stop alle reviews in een matrix X, de targets (= ratings) in een vector y.\n",
    "\n",
    "- Creëer een nieuwe vector ys (simplified y). positief sentiment = 1, neutraal sentiment = 0, negatief sentiment=-1. Bij een positief sentiment is de rating groter dan 3, bij een negatief sentiment kleiner dan 3 en tot slotte bij een neutraal sentiment gelijk aan 3.\n",
    "\n",
    "- In welke mate is de vector y gebalanceerd en in welke mate de vector ys? Visualiseer met een histogram.\n",
    "\n",
    "- Is er een verband tussen de lengte van een review en het sentiment?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ga op zoek naar mogelijks ontbrekende waarden en verwijder de volledige rij via listwise deletion. Hoeveel reviews blijven nog over?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23486, 10)\n",
      "(19662, 10)\n"
     ]
    }
   ],
   "source": [
    "# Vooranalyse van de data\n",
    "\n",
    "# total reviews\n",
    "print(dataset.shape)\n",
    "#Verwijderen van rijen met NaN waarden \n",
    "dataset.dropna(axis=0,inplace=True)\n",
    "print(dataset.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total there are 23486 reviews. As you can see above we have deleted the rows with missing values and it has decreased to 19662. Therefore in total there are still 19662 review remaining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Welke leeftijdscategorie heeft het meest reviews gegeven (visualiseer via een histogram: https://matplotlib.org/api/_as_gen/matplotlib.pyplot.hist.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x23e40bf0be0>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset['Age'].plot.hist(edgecolor='k')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The age category between 34-41 has the most reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Stop alle reviews in een matrix X, de targets (= ratings) in een vector y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so small in fact that i could not zip it up! i reordered it in petite medium, which was just ok. overall, the top half was comfortable and fit nicely, but the bottom half had a very tight under layer and several somewhat cheap (net) over layers. imo, a major design flaw was the net over layer sewn directly into the zipper - it c'\n",
      " \"I love, love, love this jumpsuit. it's fun, flirty, and fabulous! every time i wear it, i get nothing but great compliments!\"\n",
      " 'This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. love this shirt!!!'\n",
      " ...\n",
      " \"This fit well, but the top was very see through. this never would have worked for me. i'm glad i was able to try it on in the store and didn't order it online. with different fabric, it would have been great.\"\n",
      " \"I bought this dress for a wedding i have this summer, and it's so cute. unfortunately the fit isn't perfect. the medium fits my waist perfectly, but was way too long and too big in the bust and shoulders. if i wanted to spend the money, i could get it tailored, but i just felt like it might not be worth it. side note - this dress was delivered to me with a nordstrom tag on it and i found it much cheaper there after looking!\"\n",
      " 'This dress in a lovely platinum is feminine and fits perfectly, easy to wear and comfy, too! highly recommend!']\n",
      "[3 5 5 ... 3 3 5]\n",
      "(19662,)\n",
      "(19662,)\n"
     ]
    }
   ],
   "source": [
    "X = dataset['Review Text'].values\n",
    "y = dataset['Rating'].values\n",
    "\n",
    "print(X)\n",
    "print(y)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creëer een nieuwe vector ys (simplified y). positief sentiment = 1, neutraal sentiment = 0, negatief sentiment=-1. Bij een positief sentiment is de rating groter dan 3, bij een negatief sentiment kleiner dan 3 en tot slotte bij een neutraal sentiment gelijk aan 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1080</td>\n",
       "      <td>49</td>\n",
       "      <td>Not for the very petite</td>\n",
       "      <td>I love tracy reese dresses, but this one is no...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>858</td>\n",
       "      <td>39</td>\n",
       "      <td>Cagrcoal shimmer fun</td>\n",
       "      <td>I aded this in my basket at hte last mintue to...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Knits</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clothing ID  Age                    Title  \\\n",
       "2         1077   60  Some major design flaws   \n",
       "3         1049   50         My favorite buy!   \n",
       "4          847   47         Flattering shirt   \n",
       "5         1080   49  Not for the very petite   \n",
       "6          858   39     Cagrcoal shimmer fun   \n",
       "\n",
       "                                         Review Text  Rating  Recommended IND  \\\n",
       "2  I had such high hopes for this dress and reall...       3                0   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
       "4  This shirt is very flattering to all due to th...       5                1   \n",
       "5  I love tracy reese dresses, but this one is no...       2                0   \n",
       "6  I aded this in my basket at hte last mintue to...       5                1   \n",
       "\n",
       "   Positive Feedback Count   Division Name Department Name Class Name  \\\n",
       "2                        0         General         Dresses    Dresses   \n",
       "3                        0  General Petite         Bottoms      Pants   \n",
       "4                        6         General            Tops    Blouses   \n",
       "5                        4         General         Dresses    Dresses   \n",
       "6                        1  General Petite            Tops      Knits   \n",
       "\n",
       "   Sentiment  \n",
       "2          0  \n",
       "3          1  \n",
       "4          1  \n",
       "5         -1  \n",
       "6          1  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of our conditions\n",
    "\n",
    "conditions = [\n",
    "    (dataset['Rating'] > 3),\n",
    "    (dataset['Rating'] < 3),\n",
    "    (dataset['Rating'] == 3)\n",
    "]\n",
    "\n",
    "# create a list of the values we want to assign for each conditon\n",
    "values = [1, -1, 0]\n",
    "\n",
    "# create a new column and use np.select to assign to it using our lists as arguments\n",
    "dataset['Sentiment'] = np.select(conditions, values)\n",
    "\n",
    "# display updated DataFrame\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = dataset['Sentiment'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In welke mate is de vector y gebalanceerd en in welke mate de vector ys? Visualiseer met een histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  691.,     0.,  1360.,     0.,     0.,  2464.,     0.,  4289.,\n",
       "            0., 10858.]),\n",
       " array([1. , 1.4, 1.8, 2.2, 2.6, 3. , 3.4, 3.8, 4.2, 4.6, 5. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2051.,     0.,     0.,     0.,     0.,  2464.,     0.,     0.,\n",
       "            0., 15147.]),\n",
       " array([-1. , -0.8, -0.6, -0.4, -0.2,  0. ,  0.2,  0.4,  0.6,  0.8,  1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2051.,     0.,     0.,     0.,     0.,  2464.,     0.,     0.,\n",
       "            0., 15147.]),\n",
       " array([-1. , -0.8, -0.6, -0.4, -0.2,  0. ,  0.2,  0.4,  0.6,  0.8,  1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD4CAYAAADsKpHdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAATK0lEQVR4nO3df6zdd33f8edrNg0BZkjITerda2ZvGFrHWqG5ytxFmqCGxWsRTisiXVSItXmyFrkbZZ1YPKSh/WEVtKnpIi2RLJLFaVGClYJitQrFdYKiSibuDYQ6jjG5a7rk1m58Oyj1NuHW4b0/zsfSyfWxfe851/fcaz8f0tH5ft/fz+d7319B/LrfH+fcVBWSJP2dYTcgSVoaDARJEmAgSJIaA0GSBBgIkqRm5bAb6NcNN9xQa9euHXYbkrSsPPfcc39ZVSO9ti3bQFi7di2Tk5PDbkOSlpUk/+tC27xkJEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQKW8SeVtYw8/RtzG/fBXZe3D0kX5RmCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAuYQCEkeSnIqyQs9tv37JJXkhq7ariRTSY4nub2rfkuSI23bfUnS6tck+XKrP5tk7cIcmiRpPuZyhvAwsGV2Mcka4MPAK121DcAEcHObc3+SFW3zA8AOYH17ndvnduAHVfVu4F7gC/0ciCRpMJcMhKp6Bvh+j033Ap8Bqqu2FXisqs5U1cvAFHBrktXAqqo6VFUFPALc0TVnb1t+HNh87uxBkrR4+rqHkOSjwJ9X1XdmbRoFXu1an2610bY8u/6GOVV1Fvgh8M4L/NwdSSaTTM7MzPTTuiTpAuYdCEneAnwW+E+9Nveo1UXqF5tzfrFqT1WNV9X4yMjIXNqVJM1RP2cI/xBYB3wnyZ8BY8C3kvwknd/813SNHQNOtPpYjzrdc5KsBN5O70tUkqTLaN6BUFVHqurGqlpbVWvp/IP+s1X1F8B+YKI9ObSOzs3jw1V1EjidZFO7P3AX8ETb5X5gW1v+GPBUu88gSVpEc3ns9FHgEPDeJNNJtl9obFUdBfYBLwJfA3ZW1ett893AF+ncaP6fwJOt/iDwziRTwL8D7unzWCRJA7jk31Suqo9fYvvaWeu7gd09xk0CG3vUfwTceak+JEmXl59UliQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAEGgiSpMRAkSYCBIElqDARJEmAgSJIaA0GSBBgIkqTGQJAkAQaCJKkxECRJwBwCIclDSU4leaGr9l+SfDfJnyT5apJ3dG3blWQqyfEkt3fVb0lypG27L0la/ZokX271Z5OsXdhDlCTNxVzOEB4GtsyqHQA2VtU/Ar4H7AJIsgGYAG5uc+5PsqLNeQDYAaxvr3P73A78oKreDdwLfKHfg5Ek9e+SgVBVzwDfn1X7elWdbavfBMba8lbgsao6U1UvA1PArUlWA6uq6lBVFfAIcEfXnL1t+XFg87mzB0nS4lmIewj/EniyLY8Cr3Ztm2610bY8u/6GOS1kfgi8s9cPSrIjyWSSyZmZmQVoXZJ0zkCBkOSzwFngS+dKPYbVReoXm3N+sWpPVY1X1fjIyMh825UkXUTfgZBkG/AR4FfaZSDo/Oa/pmvYGHCi1cd61N8wJ8lK4O3MukQlSbr8+gqEJFuA/wB8tKr+X9em/cBEe3JoHZ2bx4er6iRwOsmmdn/gLuCJrjnb2vLHgKe6AkaStEhWXmpAkkeBDwA3JJkGPkfnqaJrgAPt/u83q+pfV9XRJPuAF+lcStpZVa+3Xd1N54mla+ncczh33+FB4LeTTNE5M5hYmEOTJM3HJQOhqj7eo/zgRcbvBnb3qE8CG3vUfwTceak+JEmXl59UliQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAFz+KSyJKl/9x743oLv89Mffs+C7xM8Q5AkNQaCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJGAOgZDkoSSnkrzQVbs+yYEkL7X367q27UoyleR4ktu76rckOdK23Zf2x5iTXJPky63+bJK1C3uIkqS5mMsZwsPAllm1e4CDVbUeONjWSbIBmABubnPuT7KizXkA2AGsb69z+9wO/KCq3g3cC3yh34ORJPXvkoFQVc8A359V3grsbct7gTu66o9V1ZmqehmYAm5NshpYVVWHqqqAR2bNObevx4HN584eJEmLp997CDdV1UmA9n5jq48Cr3aNm2610bY8u/6GOVV1Fvgh8M5ePzTJjiSTSSZnZmb6bF2S1MtC31Tu9Zt9XaR+sTnnF6v2VNV4VY2PjIz02aIkqZd+A+G1dhmI9n6q1aeBNV3jxoATrT7Wo/6GOUlWAm/n/EtUkqTLrN9A2A9sa8vbgCe66hPtyaF1dG4eH26XlU4n2dTuD9w1a865fX0MeKrdZ5AkLaJL/j2EJI8CHwBuSDINfA74PLAvyXbgFeBOgKo6mmQf8CJwFthZVa+3Xd1N54mla4En2wvgQeC3k0zROTOYWJAjkyTNyyUDoao+foFNmy8wfjewu0d9EtjYo/4jWqBIkobHTypLkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1AwUCEk+neRokheSPJrkzUmuT3IgyUvt/bqu8buSTCU5nuT2rvotSY60bfclySB9SZLmr+9ASDIK/FtgvKo2AiuACeAe4GBVrQcOtnWSbGjbbwa2APcnWdF29wCwA1jfXlv67UuS1J9BLxmtBK5NshJ4C3AC2Arsbdv3Ane05a3AY1V1pqpeBqaAW5OsBlZV1aGqKuCRrjmSpEXSdyBU1Z8D/xV4BTgJ/LCqvg7cVFUn25iTwI1tyijwatcupltttC3Prp8nyY4kk0kmZ2Zm+m1dktTDIJeMrqPzW/864O8Bb03yiYtN6VGri9TPL1btqarxqhofGRmZb8uSpIsY5JLRh4CXq2qmqv4W+ArwT4DX2mUg2vupNn4aWNM1f4zOJabptjy7LklaRIMEwivApiRvaU8FbQaOAfuBbW3MNuCJtrwfmEhyTZJ1dG4eH26XlU4n2dT2c1fXHEnSIlnZ78SqejbJ48C3gLPAt4E9wNuAfUm20wmNO9v4o0n2AS+28Tur6vW2u7uBh4FrgSfbS5K0iPoOBICq+hzwuVnlM3TOFnqN3w3s7lGfBDYO0oskaTB+UlmSBBgIkqTGQJAkAQaCJKkxECRJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAEDBkKSdyR5PMl3kxxL8nNJrk9yIMlL7f26rvG7kkwlOZ7k9q76LUmOtG33JckgfUmS5m/QM4T/Bnytqn4K+BngGHAPcLCq1gMH2zpJNgATwM3AFuD+JCvafh4AdgDr22vLgH1Jkuap70BIsgr4p8CDAFX1N1X1V8BWYG8bthe4oy1vBR6rqjNV9TIwBdyaZDWwqqoOVVUBj3TNkSQtkkHOEP4BMAP8jyTfTvLFJG8FbqqqkwDt/cY2fhR4tWv+dKuNtuXZ9fMk2ZFkMsnkzMzMAK1LkmYbJBBWAj8LPFBV7wf+L+3y0AX0ui9QF6mfX6zaU1XjVTU+MjIy334lSRcxSCBMA9NV9Wxbf5xOQLzWLgPR3k91jV/TNX8MONHqYz3qkqRF1HcgVNVfAK8meW8rbQZeBPYD21ptG/BEW94PTCS5Jsk6OjePD7fLSqeTbGpPF93VNUeStEhWDjj/3wBfSvITwJ8C/4JOyOxLsh14BbgToKqOJtlHJzTOAjur6vW2n7uBh4FrgSfbS5K0iAYKhKp6HhjvsWnzBcbvBnb3qE8CGwfpRZI0GD+pLEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgb/E5qSNFT3Hvjegu7v0x9+z4LubzkZ+AwhyYok307ye239+iQHkrzU3q/rGrsryVSS40lu76rfkuRI23ZfkgzalyRpfhbiktGngGNd6/cAB6tqPXCwrZNkAzAB3AxsAe5PsqLNeQDYAaxvry0L0JckaR4GCoQkY8AvAl/sKm8F9rblvcAdXfXHqupMVb0MTAG3JlkNrKqqQ1VVwCNdcyRJi2TQM4TfAj4D/LirdlNVnQRo7ze2+ijwate46VYbbcuz6+dJsiPJZJLJmZmZAVuXJHXrOxCSfAQ4VVXPzXVKj1pdpH5+sWpPVY1X1fjIyMgcf6wkaS4GecroNuCjSX4BeDOwKsnvAK8lWV1VJ9vloFNt/DSwpmv+GHCi1cd61CVJi6jvM4Sq2lVVY1W1ls7N4qeq6hPAfmBbG7YNeKIt7wcmklyTZB2dm8eH22Wl00k2taeL7uqaI0laJJfjcwifB/Yl2Q68AtwJUFVHk+wDXgTOAjur6vU2527gYeBa4Mn2kiQtogUJhKr6BvCNtvy/gc0XGLcb2N2jPglsXIheJEn98asrJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAEGgiSpMRAkSYCBIElqDARJEmAgSJIaA0GSBBgIkqTGQJAkAZfnD+RoMT39G3Mb98Fdl7cPXZHuPfC9Bd3fpz/8ngXdnxaWZwiSJMBAkCQ1fQdCkjVJnk5yLMnRJJ9q9euTHEjyUnu/rmvOriRTSY4nub2rfkuSI23bfUky2GFJkuZrkDOEs8CvV9VPA5uAnUk2APcAB6tqPXCwrdO2TQA3A1uA+5OsaPt6ANgBrG+vLQP0JUnqQ9+BUFUnq+pbbfk0cAwYBbYCe9uwvcAdbXkr8FhVnamql4Ep4NYkq4FVVXWoqgp4pGuOJGmRLMhTRknWAu8HngVuqqqT0AmNJDe2YaPAN7umTbfa37bl2fVeP2cHnTMJ3vWud/XfsE/mSNJ5Br6pnORtwO8Cv1ZVf32xoT1qdZH6+cWqPVU1XlXjIyMj829WknRBAwVCkjfRCYMvVdVXWvm1dhmI9n6q1aeBNV3Tx4ATrT7Woy5JWkSDPGUU4EHgWFX9Ztem/cC2trwNeKKrPpHkmiTr6Nw8PtwuL51Osqnt866uOZKkRTLIPYTbgE8CR5I832r/Efg8sC/JduAV4E6AqjqaZB/wIp0nlHZW1ett3t3Aw8C1wJPtJUlaRH0HQlX9Eb2v/wNsvsCc3cDuHvVJYGO/vUiSBucnlSVJgIEgSWoMBEkS4NdfS3O20F8FDX4dtJYWzxAkSYCBIElqDARJEmAgSJIaA0GSBBgIkqTGQJAkAQaCJKnxg2laMhb6g19+6EuaH88QJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkZskEQpItSY4nmUpyz7D7kaSrzZIIhCQrgP8O/HNgA/DxJBuG25UkXV2WRCAAtwJTVfWnVfU3wGPA1iH3JElXlVTVsHsgyceALVX1r9r6J4F/XFW/OmvcDmBHW30vcLzPH3kD8Jd9zl1qPJal50o5DvBYlqpBjuXvV9VIrw1L5asr0qN2XlJV1R5gz8A/LJmsqvFB97MUeCxLz5VyHOCxLFWX61iWyiWjaWBN1/oYcGJIvUjSVWmpBMIfA+uTrEvyE8AEsH/IPUnSVWVJXDKqqrNJfhX4A2AF8FBVHb2MP3Lgy05LiMey9FwpxwEey1J1WY5lSdxUliQN31K5ZCRJGjIDQZIEXMWBkOTOJEeT/DjJsnsU7Ur6qo8kDyU5leSFYfcyiCRrkjyd5Fj7/9anht1Tv5K8OcnhJN9px/Kfh93TIJKsSPLtJL837F4GkeTPkhxJ8nySyYXe/1UbCMALwC8Dzwy7kfm6Ar/q42Fgy7CbWABngV+vqp8GNgE7l/H/LmeAn6+qnwHeB2xJsmnIPQ3iU8CxYTexQD5YVe+7kj+HsOiq6lhV9ftJ52G7or7qo6qeAb4/7D4GVVUnq+pbbfk0nX+ARofbVX+q4/+01Te117J8AiXJGPCLwBeH3ctSd9UGwjI3CrzatT7NMv2H50qVZC3wfuDZ4XbSv3aZ5XngFHCgqpbrsfwW8Bngx8NuZAEU8PUkz7Wv8llQS+JzCJdLkj8EfrLHps9W1ROL3c8CmtNXfWg4krwN+F3g16rqr4fdT7+q6nXgfUneAXw1ycaqWlb3eZJ8BDhVVc8l+cCw+1kAt1XViSQ3AgeSfLedYS+IKzoQqupDw+7hMvGrPpaoJG+iEwZfqqqvDLufhVBVf5XkG3Tu8yyrQABuAz6a5BeANwOrkvxOVX1iyH31papOtPdTSb5K5/LxggWCl4yWJ7/qYwlKEuBB4FhV/eaw+xlEkpF2ZkCSa4EPAd8dblfzV1W7qmqsqtbS+e/kqeUaBknemuTvnlsG/hkLHNBXbSAk+aUk08DPAb+f5A+G3dNcVdVZ4NxXfRwD9l3mr/q4rJI8ChwC3ptkOsn2YffUp9uATwI/3x4LfL79ZrocrQaeTvIndH4BOVBVy/qRzSvATcAfJfkOcBj4/ar62kL+AL+6QpIEXMVnCJKkNzIQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKk5v8DXlCUVjesYnEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.hist([y, ys])\n",
    "plt.hist(y, alpha=0.5)\n",
    "plt.hist(ys, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the histograms, both plots are not balanced. Moreover, the higher the rating, the higher the column is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is er een verband tussen de lengte van een review en het sentiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x23e31c3ae80>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset['Review Length']=dataset['Review Text'].apply(len)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.boxplot(x='Sentiment', y='Review Length', data=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot we can see that the rating 3 and 4 have a longer review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Review Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Clothing ID</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012547</td>\n",
       "      <td>-0.013529</td>\n",
       "      <td>-0.012949</td>\n",
       "      <td>0.041300</td>\n",
       "      <td>-0.011054</td>\n",
       "      <td>0.088266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.012547</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034910</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.041167</td>\n",
       "      <td>0.028176</td>\n",
       "      <td>0.022189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rating</th>\n",
       "      <td>-0.013529</td>\n",
       "      <td>0.034910</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.793145</td>\n",
       "      <td>-0.056659</td>\n",
       "      <td>0.923051</td>\n",
       "      <td>-0.054845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recommended IND</th>\n",
       "      <td>-0.012949</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.793145</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.059452</td>\n",
       "      <td>0.839159</td>\n",
       "      <td>-0.027640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <td>0.041300</td>\n",
       "      <td>0.041167</td>\n",
       "      <td>-0.056659</td>\n",
       "      <td>-0.059452</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.056920</td>\n",
       "      <td>0.192506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <td>-0.011054</td>\n",
       "      <td>0.028176</td>\n",
       "      <td>0.923051</td>\n",
       "      <td>0.839159</td>\n",
       "      <td>-0.056920</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.034135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Review Length</th>\n",
       "      <td>0.088266</td>\n",
       "      <td>0.022189</td>\n",
       "      <td>-0.054845</td>\n",
       "      <td>-0.027640</td>\n",
       "      <td>0.192506</td>\n",
       "      <td>-0.034135</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Clothing ID       Age    Rating  Recommended IND  \\\n",
       "Clothing ID                 1.000000  0.012547 -0.013529        -0.012949   \n",
       "Age                         0.012547  1.000000  0.034910         0.035407   \n",
       "Rating                     -0.013529  0.034910  1.000000         0.793145   \n",
       "Recommended IND            -0.012949  0.035407  0.793145         1.000000   \n",
       "Positive Feedback Count     0.041300  0.041167 -0.056659        -0.059452   \n",
       "Sentiment                  -0.011054  0.028176  0.923051         0.839159   \n",
       "Review Length               0.088266  0.022189 -0.054845        -0.027640   \n",
       "\n",
       "                         Positive Feedback Count  Sentiment  Review Length  \n",
       "Clothing ID                             0.041300  -0.011054       0.088266  \n",
       "Age                                     0.041167   0.028176       0.022189  \n",
       "Rating                                 -0.056659   0.923051      -0.054845  \n",
       "Recommended IND                        -0.059452   0.839159      -0.027640  \n",
       "Positive Feedback Count                 1.000000  -0.056920       0.192506  \n",
       "Sentiment                              -0.056920   1.000000      -0.034135  \n",
       "Review Length                           0.192506  -0.034135       1.000000  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.corr() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation coefficient of -0.03 indicates that the relationship is negative and has very little, almost no correlation. This means that the sentiment and the message length has no correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing van de tekst\n",
    "\n",
    "- Kuis de teksten op: verwijder stopwoorden en niet-letters, zet alles om naar lowercase, ... \n",
    "- Pas stemming toe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing van de tekst.\n",
    "\n",
    "def text_preprocessing(text, language, minWordSize):\n",
    "    \n",
    "    # remove html\n",
    "    text_no_html = BeautifulSoup(str(text),\"html.parser\" ).get_text()\n",
    "    \n",
    "    # remove non-letters\n",
    "    text_alpha_chars = re.sub(\"[^a-zA-Z']\", \" \", str(text_no_html)) \n",
    "        \n",
    "    # convert to lower-case\n",
    "    text_lower = text_alpha_chars.lower()\n",
    "    \n",
    "    # remove stop words\n",
    "    stops = set(stopwords.words(language)) \n",
    "    text_no_stop_words = ' '\n",
    "    \n",
    "    for w in text_lower.split():\n",
    "        if w not in stops:  \n",
    "            text_no_stop_words = text_no_stop_words + w + ' '\n",
    "      \n",
    "       # do stemming\n",
    "    text_stemmer = ' '\n",
    "    stemmer = SnowballStemmer(language)\n",
    "    for w in text_no_stop_words.split():\n",
    "        text_stemmer = text_stemmer + stemmer.stem(w) + ' '\n",
    "         \n",
    "    # remove short words\n",
    "    text_no_short_words = ' '\n",
    "    for w in text_stemmer.split(): \n",
    "        if len(w) >=minWordSize:\n",
    "            text_no_short_words = text_no_short_words + w + ' '\n",
    " \n",
    "\n",
    "    return text_no_short_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Omzetten naar bag-of-words\n",
    "\n",
    "\n",
    "Creëer een training set en een test set. Zorg ervoor dat er 5000 reviews in de test set zitten.\n",
    "\n",
    "Maak gebruik van de CountVectorizer en TfidfTransformer om een bag-of-words model te creëren. \n",
    "\n",
    "Meer info:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opsplitsen in training set en test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ys, test_size=5000, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert training and test set to bag of words\n",
    "language = 'english'\n",
    "minWordLength = 2\n",
    "\n",
    "for i in range(X_train.size):\n",
    "    X_train[i] = text_preprocessing(X_train[i], language, minWordLength)\n",
    "    \n",
    "    \n",
    "for i in range(X_test.size):\n",
    "    X_test[i] = text_preprocessing(X_test[i], language, minWordLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bought moss navi fit perfect love style roll waist excel qualiti bought peachi color top eleph wear moss color one receiv lot compliment \n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 780)\t2\n",
      "  (0, 1311)\t2\n",
      "  (0, 1379)\t1\n",
      "  (0, 2142)\t1\n",
      "  (0, 2295)\t1\n",
      "  (0, 2495)\t1\n",
      "  (0, 3913)\t1\n",
      "  (0, 3926)\t1\n",
      "  (0, 4317)\t2\n",
      "  (0, 4416)\t1\n",
      "  (0, 4638)\t1\n",
      "  (0, 4886)\t1\n",
      "  (0, 4931)\t1\n",
      "  (0, 5334)\t1\n",
      "  (0, 5431)\t1\n",
      "  (0, 5677)\t1\n",
      "  (0, 6580)\t1\n",
      "  (0, 7019)\t1\n",
      "  (0, 7496)\t1\n",
      "  (0, 7556)\t1\n",
      "  (1, 1311)\t1\n",
      "  (1, 1999)\t1\n",
      "  (1, 2916)\t2\n",
      "  (1, 3522)\t1\n",
      "  (1, 3755)\t1\n",
      "  :\t:\n",
      "  (14661, 1803)\t1\n",
      "  (14661, 1812)\t1\n",
      "  (14661, 2199)\t1\n",
      "  (14661, 2432)\t1\n",
      "  (14661, 2495)\t1\n",
      "  (14661, 2689)\t1\n",
      "  (14661, 2875)\t1\n",
      "  (14661, 3430)\t1\n",
      "  (14661, 3755)\t1\n",
      "  (14661, 3845)\t1\n",
      "  (14661, 3926)\t2\n",
      "  (14661, 4682)\t1\n",
      "  (14661, 4742)\t1\n",
      "  (14661, 4916)\t1\n",
      "  (14661, 4931)\t1\n",
      "  (14661, 5431)\t1\n",
      "  (14661, 5733)\t1\n",
      "  (14661, 5931)\t1\n",
      "  (14661, 6035)\t1\n",
      "  (14661, 6129)\t1\n",
      "  (14661, 6580)\t1\n",
      "  (14661, 6998)\t1\n",
      "  (14661, 7019)\t2\n",
      "  (14661, 7289)\t1\n",
      "  (14661, 7366)\t1\n"
     ]
    }
   ],
   "source": [
    "# Omzetten naar bag-of-words\n",
    "\n",
    "# Make sparse features vectors \n",
    "\n",
    "# create instance \n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "# train the object on the training set\n",
    "X_train_bag_of_words = count_vect.fit(X_train)\n",
    "\n",
    "# apply  the function on train\n",
    "X_train_bag_of_words = count_vect.transform(X_train)\n",
    "# apply  the function on test\n",
    "X_test_bag_of_words = count_vect.transform(X_test)\n",
    "\n",
    "print(X_train_bag_of_words)\n",
    "#print(X_test_bag_of_words)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_bag_of_words)\n",
    "X_train_tf = tf_transformer.transform(X_train_bag_of_words)\n",
    "X_test_tf = tf_transformer.transform(X_test_bag_of_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Trainen van de classifiers\n",
    "\n",
    "Train drie verschillende classifiers op de bag-of-words data: naive bayes classifier, logistic regression classifier en een Support Vector Machine classifier.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Naive bayes classifier\n",
    "\n",
    "NBclassifier = MultinomialNB(alpha=1)\n",
    "\n",
    "NBclassifier.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.01      0.02       551\n",
      "           0       0.00      0.00      0.00       600\n",
      "           1       0.77      1.00      0.87      3849\n",
      "\n",
      "    accuracy                           0.77      5000\n",
      "   macro avg       0.59      0.34      0.30      5000\n",
      "weighted avg       0.70      0.77      0.67      5000\n",
      "\n",
      "[[   6    1  544]\n",
      " [   0    0  600]\n",
      " [   0    0 3849]]\n",
      "77.10000000000001\n"
     ]
    }
   ],
   "source": [
    "# test Naive Bayes classifier\n",
    "\n",
    "y_pred = NBclassifier.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dominic Ho\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a logistic regression classifier\n",
    "lregclassifier = LogisticRegression(C=10)\n",
    "\n",
    "lregclassifier.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.57      0.43      0.49       551\n",
      "           0       0.38      0.33      0.35       600\n",
      "           1       0.89      0.94      0.91      3849\n",
      "\n",
      "    accuracy                           0.81      5000\n",
      "   macro avg       0.61      0.57      0.59      5000\n",
      "weighted avg       0.79      0.81      0.80      5000\n",
      "\n",
      "[[ 238  147  166]\n",
      " [ 101  198  301]\n",
      " [  79  171 3599]]\n",
      "80.7\n"
     ]
    }
   ],
   "source": [
    "# test logistic classifier\n",
    "\n",
    "y_pred = lregclassifier.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, kernel='linear')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a SVM\n",
    "SVMlinear = svm.SVC(kernel='linear',C=0.1)\n",
    "SVMlinear.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.05      0.09       551\n",
      "           0       0.00      0.00      0.00       600\n",
      "           1       0.77      1.00      0.87      3849\n",
      "\n",
      "    accuracy                           0.78      5000\n",
      "   macro avg       0.56      0.35      0.32      5000\n",
      "weighted avg       0.69      0.78      0.68      5000\n",
      "\n",
      "[[  26    0  525]\n",
      " [   3    0  597]\n",
      " [   0    0 3849]]\n",
      "77.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dominic Ho\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# test SVM\n",
    "y_pred = SVMlinear.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression has the highest accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Testen en hyperparameter tuning\n",
    "\n",
    "- Voer hyperparameter tuning uit via grid-search, random search of Bayes Optimization.\n",
    "- Welke classifier heeft jouw voorkeur? Beargumenteer in de context van accuracy, f1-score en berekeningstijd.\n",
    "- Bekijk enkele verkeerd geklassificeerde reviews. Is er een verklaring voor te vinden?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 5 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    2.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.7876826598168849\n",
      "Best parameters : {'alpha': 0.01}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.67      0.17      0.27       551\n",
      "           0       0.42      0.09      0.14       600\n",
      "           1       0.80      0.99      0.89      3849\n",
      "\n",
      "    accuracy                           0.79      5000\n",
      "   macro avg       0.63      0.41      0.43      5000\n",
      "weighted avg       0.74      0.79      0.73      5000\n",
      "\n",
      "[[  94   42  415]\n",
      " [  28   52  520]\n",
      " [  18   30 3801]]\n",
      "78.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.2s finished\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning Naive Bayes - Grid Search\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "model = MultinomialNB()\n",
    "paramaters = [\n",
    "             {'alpha' : [0.001, 0.01, 0.1, 1, 10]}                                       \n",
    "             ]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = paramaters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 20,\n",
    "                           n_jobs = -1,\n",
    "                           verbose=5)\n",
    "grid_search = grid_search.fit(X_train_tf, y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_ \n",
    "best_parameters = grid_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', grid_search.best_score_)\n",
    "print('Best parameters :', grid_search.best_params_  )\n",
    "\n",
    "y_pred = grid_search.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dominic Ho\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:278: UserWarning: The total space of parameters 5 is smaller than n_iter=20. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 out of  25 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.7876144535834175\n",
      "Best parameters : {'alpha': 0.01}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.67      0.17      0.27       551\n",
      "           0       0.42      0.09      0.14       600\n",
      "           1       0.80      0.99      0.89      3849\n",
      "\n",
      "    accuracy                           0.79      5000\n",
      "   macro avg       0.63      0.41      0.43      5000\n",
      "weighted avg       0.74      0.79      0.73      5000\n",
      "\n",
      "[[  94   42  415]\n",
      " [  28   52  520]\n",
      " [  18   30 3801]]\n",
      "78.94\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning Naive Bayes - Random Search\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# distributions\n",
    "from scipy.stats import randint \n",
    "from scipy.stats import uniform\n",
    "\n",
    "\n",
    "model = MultinomialNB()\n",
    "parameters = [\n",
    "             {'alpha' : [0.001, 0.01, 0.1, 1, 10]}                                       \n",
    "             ]\n",
    "\n",
    "# random search zoeken, bv 20 willekeurig random searches\n",
    "n_iter_search = 20\n",
    "\n",
    "# cv = cross validatie\n",
    "random_search = RandomizedSearchCV(model, param_distributions=parameters,cv=5,n_iter=n_iter_search,n_jobs = -1,verbose=1)\n",
    "\n",
    "random_search = random_search.fit(X_train_tf, y_train)\n",
    "\n",
    "best_accuracy = random_search.best_score_ \n",
    "best_parameters = random_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', random_search.best_score_)\n",
    "print('Best parameters :',random_search.best_params_  )\n",
    "\n",
    "y_pred = random_search.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 50 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   19.5s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:   41.7s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  6.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.8179655292906238\n",
      "Best parameters : {'C': 1, 'class_weight': None, 'solver': 'saga'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.65      0.39      0.49       551\n",
      "           0       0.39      0.24      0.30       600\n",
      "           1       0.86      0.96      0.91      3849\n",
      "\n",
      "    accuracy                           0.81      5000\n",
      "   macro avg       0.64      0.53      0.57      5000\n",
      "weighted avg       0.78      0.81      0.79      5000\n",
      "\n",
      "[[ 216  119  216]\n",
      " [  79  143  378]\n",
      " [  36  102 3711]]\n",
      "81.39999999999999\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning Logistic Regression - Grid Search\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "paramaters = [\n",
    "             {'C' : [0.01, 0.1, 1, 10, 100], \n",
    "              'solver': ['liblinear','lbfgs', 'newton-cg', 'sag','saga'], \n",
    "              'class_weight': [None, 'balanced']},                                       \n",
    "             ]\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = paramaters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 20,\n",
    "                           n_jobs = -1,\n",
    "                           verbose=5)\n",
    "grid_search = grid_search.fit(X_train_tf, y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_ \n",
    "best_parameters = grid_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', grid_search.best_score_)\n",
    "print('Best parameters :', grid_search.best_params_  )\n",
    "\n",
    "y_pred = grid_search.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 20 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   19.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  4.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.8200806844329787\n",
      "Best parameters : {'C': 1.7440212848786218, 'class_weight': None, 'solver': 'newton-cg'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.64      0.41      0.50       551\n",
      "           0       0.39      0.27      0.32       600\n",
      "           1       0.87      0.96      0.91      3849\n",
      "\n",
      "    accuracy                           0.81      5000\n",
      "   macro avg       0.63      0.55      0.58      5000\n",
      "weighted avg       0.79      0.81      0.79      5000\n",
      "\n",
      "[[ 228  125  198]\n",
      " [  86  159  355]\n",
      " [  43  121 3685]]\n",
      "81.44\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning Logistic Regression - Random Search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint \n",
    "from scipy.stats import uniform\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "parameters = [\n",
    "             {'C' : uniform(0.01, 20), \n",
    "              'solver': ['liblinear','lbfgs', 'newton-cg', 'sag','saga'],\n",
    "              'class_weight': [None, 'balanced']}\n",
    "             ]\n",
    "\n",
    "n_iter_search = 20\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_distributions=parameters,cv=20,n_iter=n_iter_search,n_jobs = -1,verbose=1)\n",
    "\n",
    "random_search = random_search.fit(X_train_tf, y_train)\n",
    "\n",
    "best_accuracy = random_search.best_score_ \n",
    "best_parameters = random_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', random_search.best_score_)\n",
    "print('Best parameters :',random_search.best_params_  )\n",
    "\n",
    "y_pred = random_search.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 130 candidates, totalling 650 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 16.4min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 51.3min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 104.1min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 162.0min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed: 234.5min\n",
      "[Parallel(n_jobs=-1)]: Done 650 out of 650 | elapsed: 239.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.8217162374429563\n",
      "Best parameters : {'C': 10, 'class_weight': None, 'degree': 2, 'gamma': 0.1, 'kernel': 'sigmoid'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.43      0.51       551\n",
      "           0       0.40      0.24      0.30       600\n",
      "           1       0.87      0.96      0.91      3849\n",
      "\n",
      "    accuracy                           0.82      5000\n",
      "   macro avg       0.63      0.54      0.57      5000\n",
      "weighted avg       0.79      0.82      0.79      5000\n",
      "\n",
      "[[ 236  120  195]\n",
      " [  91  147  362]\n",
      " [  53  103 3693]]\n",
      "81.52000000000001\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning SVM - Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC()\n",
    "\n",
    "paramaters = [ \n",
    "        {'kernel': ['linear'], \n",
    "         'C': [0.01, 0.1, 1, 10, 100], \n",
    "         'degree': [2], \n",
    "         'class_weight': [None, 'balanced']},\n",
    "        {'kernel': ['rbf', 'poly', 'sigmoid'], \n",
    "         'C': [0.01, 0.1, 1, 10, 100], \n",
    "         'gamma': [0.001, 0.01, 0.1, 0.2], \n",
    "         'degree': [2], \n",
    "         'class_weight': [None, 'balanced']},\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = paramaters,\n",
    "                           scoring = 'accuracy', \n",
    "                           cv = 5,\n",
    "                           n_jobs = -1,\n",
    "                           verbose =5)\n",
    "grid_search = grid_search.fit(X_train_tf, y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_ \n",
    "best_parameters = grid_search.best_params_  \n",
    "print('Best accuracy : ', grid_search.best_score_)\n",
    "print('Best parameters :', grid_search.best_params_  )\n",
    "\n",
    "\n",
    "y_pred = grid_search.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 15.9min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 33.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.8215798117949346\n",
      "Best parameters : {'C': 1, 'class_weight': None, 'degree': 4, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.43      0.51       551\n",
      "           0       0.40      0.24      0.30       600\n",
      "           1       0.87      0.96      0.91      3849\n",
      "\n",
      "    accuracy                           0.82      5000\n",
      "   macro avg       0.63      0.54      0.57      5000\n",
      "weighted avg       0.79      0.82      0.79      5000\n",
      "\n",
      "[[ 236  120  195]\n",
      " [  91  147  362]\n",
      " [  53  103 3693]]\n",
      "81.52000000000001\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning SVM - Random Search\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint \n",
    "from scipy.stats import uniform\n",
    "\n",
    "\n",
    "#svc trainen\n",
    "model = SVC()\n",
    "\n",
    "parameters = [\n",
    "    {'kernel': ['linear'], \n",
    "     'C': [0.01, 0.1, 1, 10, 100], \n",
    "     'degree': [2,3,4], \n",
    "     'class_weight': [None, 'balanced']\n",
    "    },\n",
    "    {'kernel': ['rbf', 'poly', 'sigmoid'], \n",
    "     'C': [0.01, 0.1, 1, 10, 100], \n",
    "     'gamma': uniform(0.001, 0.2), \n",
    "     'degree': [2,3,4], \n",
    "     'class_weight': [None, 'balanced']}\n",
    "]\n",
    " \n",
    "n_iter_search = 20\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_distributions=parameters,cv=5,n_iter=n_iter_search,n_jobs = -1,verbose=1)\n",
    "\n",
    "random_search = random_search.fit(X_train_tf, y_train)\n",
    "\n",
    "best_accuracy = random_search.best_score_ \n",
    "best_parameters = random_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', random_search.best_score_)\n",
    "print('Best parameters :',random_search.best_params_  )\n",
    "\n",
    "y_pred = random_search.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Welke classifier heeft jouw voorkeur? Beargumenteer in de context van accuracy, f1-score en berekeningstijd.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general if we compare the 3 classifiers, we can see that there are differences in scores. Based on the scores the order is as follows: SVM (81,52%), Logistic regression (81,44%) and Naive Bayes (78,94%). Moreover, if we take the execution time into consideration then the logistic regression would be the most suitable classifier for this case.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bekijk enkele verkeerd geklassificeerde reviews. Is er een verklaring voor te vinden?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [i for i in range(len(y_test)) if y_test[i] != y_pred[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Review Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1080</td>\n",
       "      <td>49</td>\n",
       "      <td>Not for the very petite</td>\n",
       "      <td>I love tracy reese dresses, but this one is no...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>-1</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>858</td>\n",
       "      <td>39</td>\n",
       "      <td>Cagrcoal shimmer fun</td>\n",
       "      <td>I aded this in my basket at hte last mintue to...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Knits</td>\n",
       "      <td>1</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>767</td>\n",
       "      <td>44</td>\n",
       "      <td>Runs big</td>\n",
       "      <td>Bought the black xs to go under the larkspur m...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "      <td>1</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1077</td>\n",
       "      <td>34</td>\n",
       "      <td>Like it, but don't love it.</td>\n",
       "      <td>Cute little dress fits tts. it is a little hig...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>0</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5963</th>\n",
       "      <td>873</td>\n",
       "      <td>41</td>\n",
       "      <td>Flattering tank</td>\n",
       "      <td>I purchased the coral color. i'm usually betwe...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Knits</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5964</th>\n",
       "      <td>1004</td>\n",
       "      <td>23</td>\n",
       "      <td>Love the structure, not the length</td>\n",
       "      <td>I got this skirt earlier this week and wore it...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Skirts</td>\n",
       "      <td>1</td>\n",
       "      <td>489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5974</th>\n",
       "      <td>839</td>\n",
       "      <td>56</td>\n",
       "      <td>Darling summer top</td>\n",
       "      <td>I usually try to avoid paying full price for i...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "      <td>1</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5978</th>\n",
       "      <td>1086</td>\n",
       "      <td>29</td>\n",
       "      <td>Very cute dress, but odd sizing</td>\n",
       "      <td>The pattern and fabric are very nice! i'm usua...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>1</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5979</th>\n",
       "      <td>873</td>\n",
       "      <td>51</td>\n",
       "      <td>Great too</td>\n",
       "      <td>This is a perfect casual too to pair with jns ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Knits</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>928 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Clothing ID  Age                               Title  \\\n",
       "2            1077   60             Some major design flaws   \n",
       "5            1080   49             Not for the very petite   \n",
       "6             858   39                Cagrcoal shimmer fun   \n",
       "13            767   44                            Runs big   \n",
       "23           1077   34         Like it, but don't love it.   \n",
       "...           ...  ...                                 ...   \n",
       "5963          873   41                     Flattering tank   \n",
       "5964         1004   23  Love the structure, not the length   \n",
       "5974          839   56                  Darling summer top   \n",
       "5978         1086   29     Very cute dress, but odd sizing   \n",
       "5979          873   51                           Great too   \n",
       "\n",
       "                                            Review Text  Rating  \\\n",
       "2     I had such high hopes for this dress and reall...       3   \n",
       "5     I love tracy reese dresses, but this one is no...       2   \n",
       "6     I aded this in my basket at hte last mintue to...       5   \n",
       "13    Bought the black xs to go under the larkspur m...       5   \n",
       "23    Cute little dress fits tts. it is a little hig...       3   \n",
       "...                                                 ...     ...   \n",
       "5963  I purchased the coral color. i'm usually betwe...       5   \n",
       "5964  I got this skirt earlier this week and wore it...       4   \n",
       "5974  I usually try to avoid paying full price for i...       5   \n",
       "5978  The pattern and fabric are very nice! i'm usua...       4   \n",
       "5979  This is a perfect casual too to pair with jns ...       5   \n",
       "\n",
       "      Recommended IND  Positive Feedback Count   Division Name  \\\n",
       "2                   0                        0         General   \n",
       "5                   0                        4         General   \n",
       "6                   1                        1  General Petite   \n",
       "13                  1                        0       Initmates   \n",
       "23                  1                        0         General   \n",
       "...               ...                      ...             ...   \n",
       "5963                1                        1         General   \n",
       "5964                1                        4  General Petite   \n",
       "5974                1                        1         General   \n",
       "5978                0                        1         General   \n",
       "5979                1                        0         General   \n",
       "\n",
       "     Department Name Class Name  Sentiment  Review Length  \n",
       "2            Dresses    Dresses          0            500  \n",
       "5            Dresses    Dresses         -1            488  \n",
       "6               Tops      Knits          1            496  \n",
       "13          Intimate  Intimates          1            377  \n",
       "23           Dresses    Dresses          0            202  \n",
       "...              ...        ...        ...            ...  \n",
       "5963            Tops      Knits          1            173  \n",
       "5964         Bottoms     Skirts          1            489  \n",
       "5974            Tops    Blouses          1            284  \n",
       "5978         Dresses    Dresses          1            219  \n",
       "5979            Tops      Knits          1             69  \n",
       "\n",
       "[928 rows x 12 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_predictions = dataset.iloc[indices,:]\n",
    "wrong_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2       I had such high hopes for this dress and reall...\n",
       "5       I love tracy reese dresses, but this one is no...\n",
       "6       I aded this in my basket at hte last mintue to...\n",
       "13      Bought the black xs to go under the larkspur m...\n",
       "23      Cute little dress fits tts. it is a little hig...\n",
       "                              ...                        \n",
       "5963    I purchased the coral color. i'm usually betwe...\n",
       "5964    I got this skirt earlier this week and wore it...\n",
       "5974    I usually try to avoid paying full price for i...\n",
       "5978    The pattern and fabric are very nice! i'm usua...\n",
       "5979    This is a perfect casual too to pair with jns ...\n",
       "Name: Review Text, Length: 928, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_predictions['Review Text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Uitbreidingen\n",
    "\n",
    "- Bij niet gebalanceerde data kan het helpen om de data op te splitsen via stratified sampling. Zoek het verschil uit tussen stratified sampling en random sampling. Meer info: http://statl6.blogspot.com/2015/11/other-effective-sampling-methods.html.\n",
    "Pas deze stratified sampling toe via StratifiedShuffleSplit: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html. Train de modellen opnieuw en vergelijk de accuracy en f1-score met de deze bekomen via het trainen van de modellen op random sampled data.\n",
    "\n",
    "- Voorspel in plaats van het sentiment (negatief, neutraal, positief) de rating zelf.\n",
    "\n",
    "- Gebruik andere features om betere sentiment predicties te bekomen. Dit kan door andere features (zoals de recommended IND) mee te nemen als input features. Een andere optie is om de output van de reeds getrainde text classifier als nieuwe feature te zien en daarmee samen met andere features (bijvoorbeeld recommended IND, lengte review, leeftijd) een nieuwe classifier te trainen die het sentiment of rating voorspelt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bij niet gebalanceerde data kan het helpen om de data op te splitsen via stratified sampling. Zoek het verschil uit tussen stratified sampling en random sampling. Meer info: http://statl6.blogspot.com/2015/11/other-effective-sampling-methods.html.\n",
    "Pas deze stratified sampling toe via StratifiedShuffleSplit: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html. Train de modellen opnieuw en vergelijk de accuracy en f1-score met de deze bekomen via het trainen van de modellen op random sampled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "y = ys\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedShuffleSplit(n_splits=5, random_state=0, test_size=5000,\n",
      "            train_size=None)\n",
      "TRAIN: [ 8619 13698 12159 ...  2788 17404  5926] TEST: [10181 15066  3865 ...  3520 17056  7081]\n",
      "TRAIN: [ 5296 12948  4483 ... 11925 16813 10017] TEST: [18309  7973  6250 ... 17115  6955 10745]\n",
      "TRAIN: [  120  1728 17998 ... 17681 18365  1331] TEST: [14940   193  5163 ...  6177 13093  6135]\n",
      "TRAIN: [ 7428  9917   725 ...  6097 14217 17586] TEST: [ 8128 15355  6112 ... 13610 15551 13318]\n",
      "TRAIN: [19007  4916 10409 ... 17132  7165 16981] TEST: [10392  1117 10688 ...  5696 11158  9694]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=5000, random_state=0)\n",
    "sss.get_n_splits(X, y)\n",
    "print(sss)\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert training and test set to bag of words\n",
    "language = 'english'\n",
    "minWordLength = 2\n",
    "\n",
    "for i in range(X_train.size):\n",
    "    X_train[i] = text_preprocessing(X_train[i], language, minWordLength)\n",
    "    \n",
    "    \n",
    "for i in range(X_test.size):\n",
    "    X_test[i] = text_preprocessing(X_test[i], language, minWordLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 424)\t1\n",
      "  (0, 524)\t1\n",
      "  (0, 1129)\t1\n",
      "  (0, 1299)\t1\n",
      "  (0, 2010)\t1\n",
      "  (0, 2342)\t2\n",
      "  (0, 2792)\t1\n",
      "  (0, 2818)\t1\n",
      "  (0, 3097)\t1\n",
      "  (0, 3902)\t1\n",
      "  (0, 4324)\t1\n",
      "  (0, 5377)\t1\n",
      "  (0, 5914)\t1\n",
      "  (0, 7453)\t1\n",
      "  (1, 1129)\t1\n",
      "  (1, 1299)\t1\n",
      "  (1, 1807)\t1\n",
      "  (1, 3097)\t1\n",
      "  (1, 3324)\t1\n",
      "  (1, 3655)\t1\n",
      "  (1, 5156)\t1\n",
      "  (1, 5964)\t1\n",
      "  (1, 6245)\t1\n",
      "  (1, 7216)\t1\n",
      "  (1, 7587)\t1\n",
      "  :\t:\n",
      "  (14660, 5644)\t1\n",
      "  (14660, 5692)\t1\n",
      "  (14660, 6175)\t1\n",
      "  (14660, 6522)\t2\n",
      "  (14660, 7587)\t1\n",
      "  (14661, 21)\t1\n",
      "  (14661, 590)\t1\n",
      "  (14661, 710)\t1\n",
      "  (14661, 903)\t1\n",
      "  (14661, 1477)\t1\n",
      "  (14661, 1627)\t1\n",
      "  (14661, 1797)\t1\n",
      "  (14661, 2010)\t2\n",
      "  (14661, 2426)\t1\n",
      "  (14661, 2454)\t1\n",
      "  (14661, 2482)\t2\n",
      "  (14661, 3902)\t1\n",
      "  (14661, 4618)\t1\n",
      "  (14661, 5608)\t1\n",
      "  (14661, 5776)\t1\n",
      "  (14661, 6144)\t1\n",
      "  (14661, 6849)\t1\n",
      "  (14661, 7222)\t1\n",
      "  (14661, 7667)\t1\n",
      "  (14661, 7691)\t1\n"
     ]
    }
   ],
   "source": [
    "# Make sparse features vectors\n",
    "\n",
    "# Omzetten naar bag-of-words\n",
    "\n",
    "# create instance \n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "# train the object on the training set\n",
    "X_train_bag_of_words = count_vect.fit(X_train)\n",
    "\n",
    "# apply  the function on train\n",
    "X_train_bag_of_words = count_vect.transform(X_train)\n",
    "# apply  the function on test\n",
    "X_test_bag_of_words = count_vect.transform(X_test)\n",
    "\n",
    "print(X_train_bag_of_words)\n",
    "#print(X_test_bag_of_words)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_bag_of_words)\n",
    "X_train_tf = tf_transformer.transform(X_train_bag_of_words)\n",
    "X_test_tf = tf_transformer.transform(X_test_bag_of_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Naive bayes classifier\n",
    "\n",
    "NBclassifier = MultinomialNB(alpha=1)\n",
    "\n",
    "NBclassifier.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.01      0.03       521\n",
      "           0       0.00      0.00      0.00       627\n",
      "           1       0.77      1.00      0.87      3852\n",
      "\n",
      "    accuracy                           0.77      5000\n",
      "   macro avg       0.55      0.34      0.30      5000\n",
      "weighted avg       0.69      0.77      0.67      5000\n",
      "\n",
      "[[   7    1  513]\n",
      " [   1    0  626]\n",
      " [   0    0 3852]]\n",
      "77.18\n"
     ]
    }
   ],
   "source": [
    "# test Naive Bayes classifier\n",
    "\n",
    "y_pred = NBclassifier.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dominic Ho\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a logistic regression classifier\n",
    "lregclassifier = LogisticRegression(C=10)\n",
    "\n",
    "lregclassifier.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.53      0.44      0.48       521\n",
      "           0       0.41      0.29      0.34       627\n",
      "           1       0.89      0.95      0.92      3852\n",
      "\n",
      "    accuracy                           0.81      5000\n",
      "   macro avg       0.61      0.56      0.58      5000\n",
      "weighted avg       0.79      0.81      0.80      5000\n",
      "\n",
      "[[ 227  133  161]\n",
      " [ 136  183  308]\n",
      " [  69  130 3653]]\n",
      "81.26\n"
     ]
    }
   ],
   "source": [
    "# test logistic classifier\n",
    "\n",
    "y_pred = lregclassifier.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, kernel='linear')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a SVM\n",
    "SVMlinear = svm.SVC(kernel='linear',C=0.1)\n",
    "SVMlinear.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.06      0.10       521\n",
      "           0       0.00      0.00      0.00       627\n",
      "           1       0.78      1.00      0.87      3852\n",
      "\n",
      "    accuracy                           0.78      5000\n",
      "   macro avg       0.53      0.35      0.33      5000\n",
      "weighted avg       0.68      0.78      0.68      5000\n",
      "\n",
      "[[  29    0  492]\n",
      " [   7    0  620]\n",
      " [   0    0 3852]]\n",
      "77.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dominic Ho\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# test SVM\n",
    "y_pred = SVMlinear.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testen en hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 5 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.7894561003081659\n",
      "Best parameters : {'alpha': 0.01}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.63      0.17      0.27       521\n",
      "           0       0.38      0.08      0.13       627\n",
      "           1       0.81      0.99      0.89      3852\n",
      "\n",
      "    accuracy                           0.79      5000\n",
      "   macro avg       0.60      0.41      0.43      5000\n",
      "weighted avg       0.73      0.79      0.73      5000\n",
      "\n",
      "[[  91   53  377]\n",
      " [  40   49  538]\n",
      " [  14   27 3811]]\n",
      "79.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.7s finished\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning Naive Bayes - Grid Search\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "model = MultinomialNB()\n",
    "paramaters = [\n",
    "             {'alpha' : [0.001, 0.01, 0.1, 1, 10]}                                       \n",
    "             ]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = paramaters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 20,\n",
    "                           n_jobs = -1,\n",
    "                           verbose=5)\n",
    "grid_search = grid_search.fit(X_train_tf, y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_ \n",
    "best_parameters = grid_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', grid_search.best_score_)\n",
    "print('Best parameters :', grid_search.best_params_  )\n",
    "\n",
    "y_pred = grid_search.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dominic Ho\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:278: UserWarning: The total space of parameters 5 is smaller than n_iter=20. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  25 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.7884328214154313\n",
      "Best parameters : {'alpha': 0.1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.70      0.15      0.24       521\n",
      "           0       0.34      0.04      0.08       627\n",
      "           1       0.80      1.00      0.89      3852\n",
      "\n",
      "    accuracy                           0.79      5000\n",
      "   macro avg       0.61      0.40      0.40      5000\n",
      "weighted avg       0.73      0.79      0.72      5000\n",
      "\n",
      "[[  76   43  402]\n",
      " [  27   28  572]\n",
      " [   6   12 3834]]\n",
      "78.75999999999999\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning Naive Bayes - Random Search\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# distributions\n",
    "from scipy.stats import randint \n",
    "from scipy.stats import uniform\n",
    "\n",
    "\n",
    "model = MultinomialNB()\n",
    "parameters = [\n",
    "             {'alpha' : [0.001, 0.01, 0.1, 1, 10]}                                       \n",
    "             ]\n",
    "\n",
    "# random search zoeken, bv 20 willekeurig random searches\n",
    "n_iter_search = 20\n",
    "\n",
    "# cv = cross validatie\n",
    "random_search = RandomizedSearchCV(model, param_distributions=parameters,cv=5,n_iter=n_iter_search,n_jobs = -1,verbose=1)\n",
    "\n",
    "random_search = random_search.fit(X_train_tf, y_train)\n",
    "\n",
    "best_accuracy = random_search.best_score_ \n",
    "best_parameters = random_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', random_search.best_score_)\n",
    "print('Best parameters :',random_search.best_params_  )\n",
    "\n",
    "y_pred = random_search.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 50 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:   43.7s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  6.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.8181013044076264\n",
      "Best parameters : {'C': 1, 'class_weight': None, 'solver': 'newton-cg'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.59      0.39      0.47       521\n",
      "           0       0.41      0.20      0.27       627\n",
      "           1       0.86      0.97      0.91      3852\n",
      "\n",
      "    accuracy                           0.82      5000\n",
      "   macro avg       0.62      0.52      0.55      5000\n",
      "weighted avg       0.78      0.82      0.79      5000\n",
      "\n",
      "[[ 204  110  207]\n",
      " [ 107  127  393]\n",
      " [  35   71 3746]]\n",
      "81.54\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning Logistic Regression - Grid Search\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "paramaters = [\n",
    "             {'C' : [0.01, 0.1, 1, 10, 100], \n",
    "              'solver': ['liblinear','lbfgs', 'newton-cg', 'sag','saga'], \n",
    "              'class_weight': [None, 'balanced']},                                       \n",
    "             ]\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = paramaters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 20,\n",
    "                           n_jobs = -1,\n",
    "                           verbose=5)\n",
    "grid_search = grid_search.fit(X_train_tf, y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_ \n",
    "best_parameters = grid_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', grid_search.best_score_)\n",
    "print('Best parameters :', grid_search.best_params_  )\n",
    "\n",
    "y_pred = grid_search.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 20 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   26.9s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  3.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.8166007152123893\n",
      "Best parameters : {'C': 2.5042558060299855, 'class_weight': None, 'solver': 'newton-cg'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.57      0.43      0.49       521\n",
      "           0       0.42      0.25      0.31       627\n",
      "           1       0.88      0.96      0.92      3852\n",
      "\n",
      "    accuracy                           0.82      5000\n",
      "   macro avg       0.62      0.55      0.57      5000\n",
      "weighted avg       0.79      0.82      0.80      5000\n",
      "\n",
      "[[ 226  125  170]\n",
      " [ 125  155  347]\n",
      " [  46   92 3714]]\n",
      "81.89999999999999\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning Logistic Regression - Random Search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint \n",
    "from scipy.stats import uniform\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "parameters = [\n",
    "             {'C' : uniform(0.01, 20), \n",
    "              'solver': ['liblinear','lbfgs', 'newton-cg', 'sag','saga'],\n",
    "              'class_weight': [None, 'balanced']}\n",
    "             ]\n",
    "\n",
    "n_iter_search = 20\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_distributions=parameters,cv=20,n_iter=n_iter_search,n_jobs = -1,verbose=1)\n",
    "\n",
    "random_search = random_search.fit(X_train_tf, y_train)\n",
    "\n",
    "best_accuracy = random_search.best_score_ \n",
    "best_parameters = random_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', random_search.best_score_)\n",
    "print('Best parameters :',random_search.best_params_  )\n",
    "\n",
    "y_pred = random_search.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 14.7min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 35.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.816327982514446\n",
      "Best parameters : {'C': 1, 'class_weight': None, 'degree': 2, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.57      0.44      0.50       521\n",
      "           0       0.42      0.22      0.29       627\n",
      "           1       0.87      0.97      0.92      3852\n",
      "\n",
      "    accuracy                           0.82      5000\n",
      "   macro avg       0.62      0.54      0.57      5000\n",
      "weighted avg       0.79      0.82      0.80      5000\n",
      "\n",
      "[[ 230  120  171]\n",
      " [ 122  138  367]\n",
      " [  50   70 3732]]\n",
      "82.0\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning SVM - Random Search\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint \n",
    "from scipy.stats import uniform\n",
    "\n",
    "\n",
    "#svc trainen\n",
    "model = SVC()\n",
    "\n",
    "parameters = [\n",
    "    {'kernel': ['linear'], \n",
    "     'C': [0.01, 0.1, 1, 10, 100], \n",
    "     'degree': [2,3,4], \n",
    "     'class_weight': [None, 'balanced']\n",
    "    },\n",
    "    {'kernel': ['rbf', 'poly', 'sigmoid'], \n",
    "     'C': [0.01, 0.1, 1, 10, 100], \n",
    "     'gamma': uniform(0.001, 0.2), \n",
    "     'degree': [2,3,4], \n",
    "     'class_weight': [None, 'balanced']}\n",
    "]\n",
    " \n",
    "n_iter_search = 20\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_distributions=parameters,cv=5,n_iter=n_iter_search,n_jobs = -1,verbose=1)\n",
    "\n",
    "random_search = random_search.fit(X_train_tf, y_train)\n",
    "\n",
    "best_accuracy = random_search.best_score_ \n",
    "best_parameters = random_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', random_search.best_score_)\n",
    "print('Best parameters :',random_search.best_params_  )\n",
    "\n",
    "y_pred = random_search.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general there is a slight increase for the 3 classifiers. Therefore the use of StratifiedShuffleSplit is recommended as it improves the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Voorspel in plaats van het sentiment (negatief, neutraal, positief) de rating zelf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19662, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1080</td>\n",
       "      <td>49</td>\n",
       "      <td>Not for the very petite</td>\n",
       "      <td>I love tracy reese dresses, but this one is no...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>858</td>\n",
       "      <td>39</td>\n",
       "      <td>Cagrcoal shimmer fun</td>\n",
       "      <td>I aded this in my basket at hte last mintue to...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Knits</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clothing ID  Age                    Title  \\\n",
       "2         1077   60  Some major design flaws   \n",
       "3         1049   50         My favorite buy!   \n",
       "4          847   47         Flattering shirt   \n",
       "5         1080   49  Not for the very petite   \n",
       "6          858   39     Cagrcoal shimmer fun   \n",
       "\n",
       "                                         Review Text  Rating  Recommended IND  \\\n",
       "2  I had such high hopes for this dress and reall...       3                0   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
       "4  This shirt is very flattering to all due to th...       5                1   \n",
       "5  I love tracy reese dresses, but this one is no...       2                0   \n",
       "6  I aded this in my basket at hte last mintue to...       5                1   \n",
       "\n",
       "   Positive Feedback Count   Division Name Department Name Class Name  \n",
       "2                        0         General         Dresses    Dresses  \n",
       "3                        0  General Petite         Bottoms      Pants  \n",
       "4                        6         General            Tops    Blouses  \n",
       "5                        4         General         Dresses    Dresses  \n",
       "6                        1  General Petite            Tops      Knits  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inlezen van de dataset\n",
    "\n",
    "dataset = pd.read_csv('./Womens_Clothing_Reviews.csv')\n",
    "\n",
    "# verwijder kolom unnamed\n",
    "dataset.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "#Verwijderen van rijen met NaN waarden \n",
    "dataset.dropna(axis=0,inplace=True)\n",
    "\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so small in fact that i could not zip it up! i reordered it in petite medium, which was just ok. overall, the top half was comfortable and fit nicely, but the bottom half had a very tight under layer and several somewhat cheap (net) over layers. imo, a major design flaw was the net over layer sewn directly into the zipper - it c'\n",
      " \"I love, love, love this jumpsuit. it's fun, flirty, and fabulous! every time i wear it, i get nothing but great compliments!\"\n",
      " 'This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. love this shirt!!!'\n",
      " ...\n",
      " \"This fit well, but the top was very see through. this never would have worked for me. i'm glad i was able to try it on in the store and didn't order it online. with different fabric, it would have been great.\"\n",
      " \"I bought this dress for a wedding i have this summer, and it's so cute. unfortunately the fit isn't perfect. the medium fits my waist perfectly, but was way too long and too big in the bust and shoulders. if i wanted to spend the money, i could get it tailored, but i just felt like it might not be worth it. side note - this dress was delivered to me with a nordstrom tag on it and i found it much cheaper there after looking!\"\n",
      " 'This dress in a lovely platinum is feminine and fits perfectly, easy to wear and comfy, too! highly recommend!']\n",
      "[3 5 5 ... 3 3 5]\n",
      "(19662,)\n",
      "(19662,)\n"
     ]
    }
   ],
   "source": [
    "X = dataset['Review Text'].values\n",
    "y = dataset['Rating'].values\n",
    "\n",
    "print(X)\n",
    "print(y)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing van de tekst.\n",
    "\n",
    "def text_preprocessing(text, language, minWordSize):\n",
    "    \n",
    "    # remove html\n",
    "    text_no_html = BeautifulSoup(str(text),\"html.parser\" ).get_text()\n",
    "    \n",
    "    # remove non-letters\n",
    "    text_alpha_chars = re.sub(\"[^a-zA-Z']\", \" \", str(text_no_html)) \n",
    "        \n",
    "    # convert to lower-case\n",
    "    text_lower = text_alpha_chars.lower()\n",
    "    \n",
    "    # remove stop words\n",
    "    stops = set(stopwords.words(language)) \n",
    "    text_no_stop_words = ' '\n",
    "    \n",
    "    for w in text_lower.split():\n",
    "        if w not in stops:  \n",
    "            text_no_stop_words = text_no_stop_words + w + ' '\n",
    "      \n",
    "       # do stemming\n",
    "    text_stemmer = ' '\n",
    "    stemmer = SnowballStemmer(language)\n",
    "    for w in text_no_stop_words.split():\n",
    "        text_stemmer = text_stemmer + stemmer.stem(w) + ' '\n",
    "         \n",
    "    # remove short words\n",
    "    text_no_short_words = ' '\n",
    "    for w in text_stemmer.split(): \n",
    "        if len(w) >=minWordSize:\n",
    "            text_no_short_words = text_no_short_words + w + ' '\n",
    " \n",
    "\n",
    "    return text_no_short_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedShuffleSplit(n_splits=5, random_state=0, test_size=5000,\n",
      "            train_size=None)\n",
      "TRAIN: [ 4582 16410 10951 ...  5575  1668  5133] TEST: [  430  7563 16048 ...  9540  7920 17310]\n",
      "TRAIN: [ 9009  2014 14354 ...  6782  7831  6013] TEST: [17985  3640 10105 ... 11760 14736  4901]\n",
      "TRAIN: [ 1420 17234  7739 ...  4823 18817 13779] TEST: [12306 15253  5823 ...  4765 12923 15106]\n",
      "TRAIN: [ 6446 19023 12143 ... 18254  5918 17758] TEST: [17267  8389 17226 ...  8518 13056 16730]\n",
      "TRAIN: [ 3286  4332  5867 ...  3634  4439 12416] TEST: [ 5485 12406  3059 ... 12932  4341  9573]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=5000, random_state=0)\n",
    "sss.get_n_splits(X, y)\n",
    "print(sss)\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert training and test set to bag of words\n",
    "language = 'english'\n",
    "minWordLength = 2\n",
    "\n",
    "for i in range(X_train.size):\n",
    "    X_train[i] = text_preprocessing(X_train[i], language, minWordLength)\n",
    "    \n",
    "    \n",
    "for i in range(X_test.size):\n",
    "    X_test[i] = text_preprocessing(X_test[i], language, minWordLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 187)\t1\n",
      "  (0, 438)\t1\n",
      "  (0, 451)\t1\n",
      "  (0, 766)\t1\n",
      "  (0, 960)\t1\n",
      "  (0, 1102)\t1\n",
      "  (0, 1109)\t1\n",
      "  (0, 1805)\t1\n",
      "  (0, 2268)\t2\n",
      "  (0, 2545)\t1\n",
      "  (0, 2692)\t1\n",
      "  (0, 3650)\t1\n",
      "  (0, 3683)\t1\n",
      "  (0, 3740)\t1\n",
      "  (0, 3839)\t1\n",
      "  (0, 4031)\t1\n",
      "  (0, 4060)\t1\n",
      "  (0, 4375)\t1\n",
      "  (0, 4656)\t2\n",
      "  (0, 4798)\t1\n",
      "  (0, 5208)\t1\n",
      "  (0, 5869)\t1\n",
      "  (0, 6019)\t2\n",
      "  (0, 6077)\t1\n",
      "  (0, 6243)\t1\n",
      "  :\t:\n",
      "  (14661, 1256)\t1\n",
      "  (14661, 2013)\t1\n",
      "  (14661, 2339)\t1\n",
      "  (14661, 2354)\t1\n",
      "  (14661, 2442)\t1\n",
      "  (14661, 2497)\t2\n",
      "  (14661, 2526)\t1\n",
      "  (14661, 2692)\t1\n",
      "  (14661, 2795)\t1\n",
      "  (14661, 3129)\t1\n",
      "  (14661, 3575)\t1\n",
      "  (14661, 3708)\t2\n",
      "  (14661, 3743)\t1\n",
      "  (14661, 3797)\t1\n",
      "  (14661, 3997)\t1\n",
      "  (14661, 4251)\t1\n",
      "  (14661, 4254)\t1\n",
      "  (14661, 4635)\t1\n",
      "  (14661, 4947)\t2\n",
      "  (14661, 5998)\t1\n",
      "  (14661, 6169)\t1\n",
      "  (14661, 6349)\t1\n",
      "  (14661, 6580)\t1\n",
      "  (14661, 7335)\t3\n",
      "  (14661, 7434)\t1\n"
     ]
    }
   ],
   "source": [
    "# Make sparse features vectors\n",
    "\n",
    "# Omzetten naar bag-of-words\n",
    "\n",
    "# create instance \n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "# train the object on the training set\n",
    "X_train_bag_of_words = count_vect.fit(X_train)\n",
    "\n",
    "# apply  the function on train\n",
    "X_train_bag_of_words = count_vect.transform(X_train)\n",
    "# apply  the function on test\n",
    "X_test_bag_of_words = count_vect.transform(X_test)\n",
    "\n",
    "print(X_train_bag_of_words)\n",
    "#print(X_test_bag_of_words)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_bag_of_words)\n",
    "X_train_tf = tf_transformer.transform(X_train_bag_of_words)\n",
    "X_test_tf = tf_transformer.transform(X_test_bag_of_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Naive bayes classifier\n",
    "\n",
    "NBclassifier = MultinomialNB(alpha=1)\n",
    "\n",
    "NBclassifier.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       176\n",
      "           2       0.00      0.00      0.00       346\n",
      "           3       0.17      0.01      0.02       626\n",
      "           4       0.24      0.01      0.01      1091\n",
      "           5       0.56      1.00      0.72      2761\n",
      "\n",
      "    accuracy                           0.55      5000\n",
      "   macro avg       0.19      0.20      0.15      5000\n",
      "weighted avg       0.38      0.55      0.40      5000\n",
      "\n",
      "[[   0    0   10    4  162]\n",
      " [   0    0   12    6  328]\n",
      " [   0    0    5   13  608]\n",
      " [   0    0    3    8 1080]\n",
      " [   0    0    0    2 2759]]\n",
      "55.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dominic Ho\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# test Naive Bayes classifier\n",
    "\n",
    "y_pred = NBclassifier.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dominic Ho\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a logistic regression classifier\n",
    "lregclassifier = LogisticRegression(C=10)\n",
    "\n",
    "lregclassifier.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.32      0.20      0.25       176\n",
      "           2       0.26      0.21      0.23       346\n",
      "           3       0.35      0.36      0.36       626\n",
      "           4       0.39      0.33      0.36      1091\n",
      "           5       0.76      0.85      0.80      2761\n",
      "\n",
      "    accuracy                           0.61      5000\n",
      "   macro avg       0.42      0.39      0.40      5000\n",
      "weighted avg       0.58      0.61      0.59      5000\n",
      "\n",
      "[[  36   51   59    8   22]\n",
      " [  40   72  134   59   41]\n",
      " [  24   93  225  161  123]\n",
      " [   4   43  154  355  535]\n",
      " [   8   19   68  325 2341]]\n",
      "60.58\n"
     ]
    }
   ],
   "source": [
    "# test logistic classifier\n",
    "\n",
    "y_pred = lregclassifier.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, kernel='linear')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a SVM\n",
    "SVMlinear = svm.SVC(kernel='linear',C=0.1)\n",
    "SVMlinear.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       176\n",
      "           2       0.00      0.00      0.00       346\n",
      "           3       0.39      0.19      0.25       626\n",
      "           4       0.62      0.00      0.01      1091\n",
      "           5       0.59      1.00      0.74      2761\n",
      "\n",
      "    accuracy                           0.58      5000\n",
      "   macro avg       0.32      0.24      0.20      5000\n",
      "weighted avg       0.51      0.58      0.44      5000\n",
      "\n",
      "[[   0    0   49    0  127]\n",
      " [   0    0   83    0  263]\n",
      " [   0    0  118    3  505]\n",
      " [   0    0   51    5 1035]\n",
      " [   0    0    4    0 2757]]\n",
      "57.599999999999994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dominic Ho\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# test SVM\n",
    "y_pred = SVMlinear.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 5 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    2.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.590369167060083\n",
      "Best parameters : {'alpha': 0.1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.03      0.05       176\n",
      "           2       0.25      0.03      0.06       346\n",
      "           3       0.36      0.19      0.25       626\n",
      "           4       0.35      0.12      0.18      1091\n",
      "           5       0.63      0.97      0.77      2761\n",
      "\n",
      "    accuracy                           0.59      5000\n",
      "   macro avg       0.39      0.27      0.26      5000\n",
      "weighted avg       0.50      0.59      0.50      5000\n",
      "\n",
      "[[   5   20   56   19   76]\n",
      " [   5   12  100   52  177]\n",
      " [   3   13  120  105  385]\n",
      " [   0    3   50  135  903]\n",
      " [   1    0    9   73 2678]]\n",
      "59.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.4s finished\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning Naive Bayes - Grid Search\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "model = MultinomialNB()\n",
    "paramaters = [\n",
    "             {'alpha' : [0.001, 0.01, 0.1, 1, 10]}                                       \n",
    "             ]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = paramaters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 20,\n",
    "                           n_jobs = -1,\n",
    "                           verbose=5)\n",
    "grid_search = grid_search.fit(X_train_tf, y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_ \n",
    "best_parameters = grid_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', grid_search.best_score_)\n",
    "print('Best parameters :', grid_search.best_params_  )\n",
    "\n",
    "y_pred = grid_search.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dominic Ho\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:278: UserWarning: The total space of parameters 5 is smaller than n_iter=20. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 out of  25 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.5885279658624236\n",
      "Best parameters : {'alpha': 0.1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.03      0.05       176\n",
      "           2       0.25      0.03      0.06       346\n",
      "           3       0.36      0.19      0.25       626\n",
      "           4       0.35      0.12      0.18      1091\n",
      "           5       0.63      0.97      0.77      2761\n",
      "\n",
      "    accuracy                           0.59      5000\n",
      "   macro avg       0.39      0.27      0.26      5000\n",
      "weighted avg       0.50      0.59      0.50      5000\n",
      "\n",
      "[[   5   20   56   19   76]\n",
      " [   5   12  100   52  177]\n",
      " [   3   13  120  105  385]\n",
      " [   0    3   50  135  903]\n",
      " [   1    0    9   73 2678]]\n",
      "59.0\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning Naive Bayes - Random Search\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# distributions\n",
    "from scipy.stats import randint \n",
    "from scipy.stats import uniform\n",
    "\n",
    "\n",
    "model = MultinomialNB()\n",
    "parameters = [\n",
    "             {'alpha' : [0.001, 0.01, 0.1, 1, 10]}                                       \n",
    "             ]\n",
    "\n",
    "# random search zoeken, bv 20 willekeurig random searches\n",
    "n_iter_search = 20\n",
    "\n",
    "# cv = cross validatie\n",
    "random_search = RandomizedSearchCV(model, param_distributions=parameters,cv=5,n_iter=n_iter_search,n_jobs = -1,verbose=1)\n",
    "\n",
    "random_search = random_search.fit(X_train_tf, y_train)\n",
    "\n",
    "best_accuracy = random_search.best_score_ \n",
    "best_parameters = random_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', random_search.best_score_)\n",
    "print('Best parameters :',random_search.best_params_  )\n",
    "\n",
    "y_pred = random_search.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 50 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   35.5s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 10.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.6320392102925159\n",
      "Best parameters : {'C': 1, 'class_weight': None, 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.12      0.20       176\n",
      "           2       0.36      0.16      0.23       346\n",
      "           3       0.39      0.37      0.38       626\n",
      "           4       0.42      0.29      0.35      1091\n",
      "           5       0.73      0.91      0.81      2761\n",
      "\n",
      "    accuracy                           0.63      5000\n",
      "   macro avg       0.48      0.37      0.39      5000\n",
      "weighted avg       0.59      0.63      0.59      5000\n",
      "\n",
      "[[  22   32   73   14   35]\n",
      " [  17   57  145   57   70]\n",
      " [   3   50  230  169  174]\n",
      " [   0   17  110  321  643]\n",
      " [   2    4   38  202 2515]]\n",
      "62.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dominic Ho\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning Logistic Regression - Grid Search\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "paramaters = [\n",
    "             {'C' : [0.01, 0.1, 1, 10, 100], \n",
    "              'solver': ['liblinear','lbfgs', 'newton-cg', 'sag','saga'], \n",
    "              'class_weight': [None, 'balanced']},                                       \n",
    "             ]\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = paramaters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 20,\n",
    "                           n_jobs = -1,\n",
    "                           verbose=5)\n",
    "grid_search = grid_search.fit(X_train_tf, y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_ \n",
    "best_parameters = grid_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', grid_search.best_score_)\n",
    "print('Best parameters :', grid_search.best_params_  )\n",
    "\n",
    "y_pred = grid_search.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 20 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  5.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.6320398608235351\n",
      "Best parameters : {'C': 1.0809497939862422, 'class_weight': None, 'solver': 'newton-cg'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.13      0.21       176\n",
      "           2       0.35      0.17      0.23       346\n",
      "           3       0.39      0.37      0.38       626\n",
      "           4       0.42      0.30      0.35      1091\n",
      "           5       0.73      0.91      0.81      2761\n",
      "\n",
      "    accuracy                           0.63      5000\n",
      "   macro avg       0.48      0.38      0.40      5000\n",
      "weighted avg       0.59      0.63      0.60      5000\n",
      "\n",
      "[[  23   33   73   14   33]\n",
      " [  17   58  145   59   67]\n",
      " [   3   52  233  167  171]\n",
      " [   0   17  111  326  637]\n",
      " [   2    4   38  208 2509]]\n",
      "62.980000000000004\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning Logistic Regression - Random Search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint \n",
    "from scipy.stats import uniform\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "parameters = [\n",
    "             {'C' : uniform(0.01, 20), \n",
    "              'solver': ['liblinear','lbfgs', 'newton-cg', 'sag','saga'],\n",
    "              'class_weight': [None, 'balanced']}\n",
    "             ]\n",
    "\n",
    "n_iter_search = 20\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_distributions=parameters,cv=20,n_iter=n_iter_search,n_jobs = -1,verbose=1)\n",
    "\n",
    "random_search = random_search.fit(X_train_tf, y_train)\n",
    "\n",
    "best_accuracy = random_search.best_score_ \n",
    "best_parameters = random_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', random_search.best_score_)\n",
    "print('Best parameters :',random_search.best_params_  )\n",
    "\n",
    "y_pred = random_search.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 19.5min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 50.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.6260397164690829\n",
      "Best parameters : {'C': 1, 'class_weight': None, 'degree': 2, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.14      0.20       176\n",
      "           2       0.33      0.19      0.24       346\n",
      "           3       0.38      0.41      0.39       626\n",
      "           4       0.41      0.28      0.33      1091\n",
      "           5       0.74      0.90      0.81      2761\n",
      "\n",
      "    accuracy                           0.63      5000\n",
      "   macro avg       0.45      0.38      0.40      5000\n",
      "weighted avg       0.59      0.63      0.60      5000\n",
      "\n",
      "[[  24   44   72   13   23]\n",
      " [  20   67  156   55   48]\n",
      " [  11   60  256  147  152]\n",
      " [   1   22  137  302  629]\n",
      " [   3   13   51  215 2479]]\n",
      "62.56\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning SVM - Random Search\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint \n",
    "from scipy.stats import uniform\n",
    "\n",
    "\n",
    "#svc trainen\n",
    "model = SVC()\n",
    "\n",
    "parameters = [\n",
    "    {'kernel': ['linear'], \n",
    "     'C': [0.01, 0.1, 1, 10, 100], \n",
    "     'degree': [2,3,4], \n",
    "     'class_weight': [None, 'balanced']\n",
    "    },\n",
    "    {'kernel': ['rbf', 'poly', 'sigmoid'], \n",
    "     'C': [0.01, 0.1, 1, 10, 100], \n",
    "     'gamma': uniform(0.001, 0.2), \n",
    "     'degree': [2,3,4], \n",
    "     'class_weight': [None, 'balanced']}\n",
    "]\n",
    " \n",
    "n_iter_search = 20\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_distributions=parameters,cv=5,n_iter=n_iter_search,n_jobs = -1,verbose=1)\n",
    "\n",
    "random_search = random_search.fit(X_train_tf, y_train)\n",
    "\n",
    "best_accuracy = random_search.best_score_ \n",
    "best_parameters = random_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', random_search.best_score_)\n",
    "print('Best parameters :',random_search.best_params_  )\n",
    "\n",
    "y_pred = random_search.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we compare the models between the sentiment and the rating. We can see that the models that predicts with the sentiment scores higher.Therefore the StratifiedShuffleSplit on the rating models are not improving the models at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gebruik andere features om betere sentiment predicties te bekomen. Dit kan door andere features (zoals de recommended IND) mee te nemen als input features. Een andere optie is om de output van de reeds getrainde text classifier als nieuwe feature te zien en daarmee samen met andere features (bijvoorbeeld recommended IND, lengte review, leeftijd) een nieuwe classifier te trainen die het sentiment of rating voorspelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19662, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1080</td>\n",
       "      <td>49</td>\n",
       "      <td>Not for the very petite</td>\n",
       "      <td>I love tracy reese dresses, but this one is no...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>858</td>\n",
       "      <td>39</td>\n",
       "      <td>Cagrcoal shimmer fun</td>\n",
       "      <td>I aded this in my basket at hte last mintue to...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Knits</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clothing ID  Age                    Title  \\\n",
       "2         1077   60  Some major design flaws   \n",
       "3         1049   50         My favorite buy!   \n",
       "4          847   47         Flattering shirt   \n",
       "5         1080   49  Not for the very petite   \n",
       "6          858   39     Cagrcoal shimmer fun   \n",
       "\n",
       "                                         Review Text  Rating  Recommended IND  \\\n",
       "2  I had such high hopes for this dress and reall...       3                0   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
       "4  This shirt is very flattering to all due to th...       5                1   \n",
       "5  I love tracy reese dresses, but this one is no...       2                0   \n",
       "6  I aded this in my basket at hte last mintue to...       5                1   \n",
       "\n",
       "   Positive Feedback Count   Division Name Department Name Class Name  \n",
       "2                        0         General         Dresses    Dresses  \n",
       "3                        0  General Petite         Bottoms      Pants  \n",
       "4                        6         General            Tops    Blouses  \n",
       "5                        4         General         Dresses    Dresses  \n",
       "6                        1  General Petite            Tops      Knits  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inlezen van de dataset\n",
    "\n",
    "dataset = pd.read_csv('./Womens_Clothing_Reviews.csv')\n",
    "\n",
    "# verwijder kolom unnamed\n",
    "dataset.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "\n",
    "#Verwijderen van rijen met NaN waarden \n",
    "dataset.dropna(axis=0,inplace=True)\n",
    "\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1080</td>\n",
       "      <td>49</td>\n",
       "      <td>Not for the very petite</td>\n",
       "      <td>I love tracy reese dresses, but this one is no...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>858</td>\n",
       "      <td>39</td>\n",
       "      <td>Cagrcoal shimmer fun</td>\n",
       "      <td>I aded this in my basket at hte last mintue to...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Knits</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clothing ID  Age                    Title  \\\n",
       "2         1077   60  Some major design flaws   \n",
       "3         1049   50         My favorite buy!   \n",
       "4          847   47         Flattering shirt   \n",
       "5         1080   49  Not for the very petite   \n",
       "6          858   39     Cagrcoal shimmer fun   \n",
       "\n",
       "                                         Review Text  Rating  Recommended IND  \\\n",
       "2  I had such high hopes for this dress and reall...       3                0   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
       "4  This shirt is very flattering to all due to th...       5                1   \n",
       "5  I love tracy reese dresses, but this one is no...       2                0   \n",
       "6  I aded this in my basket at hte last mintue to...       5                1   \n",
       "\n",
       "   Positive Feedback Count   Division Name Department Name Class Name  \\\n",
       "2                        0         General         Dresses    Dresses   \n",
       "3                        0  General Petite         Bottoms      Pants   \n",
       "4                        6         General            Tops    Blouses   \n",
       "5                        4         General         Dresses    Dresses   \n",
       "6                        1  General Petite            Tops      Knits   \n",
       "\n",
       "   Sentiment  \n",
       "2          0  \n",
       "3          1  \n",
       "4          1  \n",
       "5         -1  \n",
       "6          1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of our conditions\n",
    "\n",
    "conditions = [\n",
    "    (dataset['Rating'] > 3),\n",
    "    (dataset['Rating'] < 3),\n",
    "    (dataset['Rating'] == 3)\n",
    "]\n",
    "\n",
    "# create a list of the values we want to assign for each conditon\n",
    "values = [1, -1, 0]\n",
    "\n",
    "# create a new column and use np.select to assign to it using our lists as arguments\n",
    "dataset['Sentiment'] = np.select(conditions, values)\n",
    "\n",
    "# display updated DataFrame\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Review Length']=dataset['Review Text'].apply(len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 60   0   0 500]\n",
      " [ 50   1   0 124]\n",
      " [ 47   1   6 192]\n",
      " ...\n",
      " [ 31   0   1 208]\n",
      " [ 28   1   2 427]\n",
      " [ 52   1  22 110]]\n",
      "[0 1 1 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.drop(['Clothing ID'], axis=1)\n",
    "dataset = dataset.drop(['Rating'], axis=1)\n",
    "dataset = dataset.drop(['Division Name'], axis=1)\n",
    "dataset = dataset.drop(['Department Name'], axis= 1)\n",
    "dataset = dataset.drop(['Class Name'], axis=1)\n",
    "dataset = dataset.drop(['Review Text'], axis=1)\n",
    "dataset = dataset.drop(['Title'], axis=1)\n",
    "\n",
    "\n",
    "X = dataset.drop(['Sentiment'], axis=1).values\n",
    "y = dataset['Sentiment'].values\n",
    "\n",
    "print(X)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14662, 4)\n",
      "(14662,)\n",
      "(5000, 4)\n",
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "# Opsplitsen in training set en test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=5000, random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainen van de classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Naive bayes classifier\n",
    "\n",
    "NBclassifier = MultinomialNB(alpha=1)\n",
    "\n",
    "NBclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.42      0.10      0.16       551\n",
      "           0       0.18      0.23      0.20       600\n",
      "           1       0.81      0.86      0.83      3849\n",
      "\n",
      "    accuracy                           0.70      5000\n",
      "   macro avg       0.47      0.40      0.40      5000\n",
      "weighted avg       0.69      0.70      0.68      5000\n",
      "\n",
      "[[  55  133  363]\n",
      " [  41  140  419]\n",
      " [  34  515 3300]]\n",
      "69.89999999999999\n"
     ]
    }
   ],
   "source": [
    "# test Naive Bayes classifier\n",
    "\n",
    "y_pred = NBclassifier.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dominic Ho\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a logistic regression classifier\n",
    "lregclassifier = LogisticRegression(C=10)\n",
    "\n",
    "lregclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.61      0.49      0.55       551\n",
      "           0       0.41      0.32      0.36       600\n",
      "           1       0.93      0.99      0.96      3849\n",
      "\n",
      "    accuracy                           0.85      5000\n",
      "   macro avg       0.65      0.60      0.62      5000\n",
      "weighted avg       0.83      0.85      0.84      5000\n",
      "\n",
      "[[ 272  256   23]\n",
      " [ 153  191  256]\n",
      " [  21   23 3805]]\n",
      "85.36\n"
     ]
    }
   ],
   "source": [
    "# test logistic classifier\n",
    "\n",
    "y_pred = lregclassifier.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, kernel='linear')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a SVM\n",
    "SVMlinear = svm.SVC(kernel='linear',C=0.1)\n",
    "SVMlinear.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.58      0.96      0.72       551\n",
      "           0       0.00      0.00      0.00       600\n",
      "           1       0.93      0.99      0.96      3849\n",
      "\n",
      "    accuracy                           0.87      5000\n",
      "   macro avg       0.50      0.65      0.56      5000\n",
      "weighted avg       0.78      0.87      0.82      5000\n",
      "\n",
      "[[ 528    0   23]\n",
      " [ 344    0  256]\n",
      " [  44    0 3805]]\n",
      "86.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dominic Ho\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# test SVM\n",
    "y_pred = SVMlinear.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 5 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.6912435736828605\n",
      "Best parameters : {'alpha': 0.001}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.42      0.10      0.16       551\n",
      "           0       0.18      0.23      0.20       600\n",
      "           1       0.81      0.86      0.83      3849\n",
      "\n",
      "    accuracy                           0.70      5000\n",
      "   macro avg       0.47      0.40      0.40      5000\n",
      "weighted avg       0.69      0.70      0.68      5000\n",
      "\n",
      "[[  55  133  363]\n",
      " [  41  140  419]\n",
      " [  34  515 3300]]\n",
      "69.89999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.3s finished\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning Naive Bayes - Grid Search\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "model = MultinomialNB()\n",
    "paramaters = [\n",
    "             {'alpha' : [0.001, 0.01, 0.1, 1, 10]}                                       \n",
    "             ]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = paramaters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 20,\n",
    "                           n_jobs = -1,\n",
    "                           verbose=5)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_ \n",
    "best_parameters = grid_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', grid_search.best_score_)\n",
    "print('Best parameters :', grid_search.best_params_  )\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best accuracy :  0.6913092955031632\n",
      "Best parameters : {'alpha': 0.001}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.42      0.10      0.16       551\n",
      "           0       0.18      0.23      0.20       600\n",
      "           1       0.81      0.86      0.83      3849\n",
      "\n",
      "    accuracy                           0.70      5000\n",
      "   macro avg       0.47      0.40      0.40      5000\n",
      "weighted avg       0.69      0.70      0.68      5000\n",
      "\n",
      "[[  55  133  363]\n",
      " [  41  140  419]\n",
      " [  34  515 3300]]\n",
      "69.89999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dominic Ho\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:278: UserWarning: The total space of parameters 5 is smaller than n_iter=20. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  25 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning Naive Bayes - Random Search\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# distributions\n",
    "from scipy.stats import randint \n",
    "from scipy.stats import uniform\n",
    "\n",
    "\n",
    "model = MultinomialNB()\n",
    "parameters = [\n",
    "             {'alpha' : [0.001, 0.01, 0.1, 1, 10]}                                       \n",
    "             ]\n",
    "\n",
    "# random search zoeken, bv 20 willekeurig random searches\n",
    "n_iter_search = 20\n",
    "\n",
    "# cv = cross validatie\n",
    "random_search = RandomizedSearchCV(model, param_distributions=parameters,cv=5,n_iter=n_iter_search,n_jobs = -1,verbose=1)\n",
    "\n",
    "random_search = random_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = random_search.best_score_ \n",
    "best_parameters = random_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', random_search.best_score_)\n",
    "print('Best parameters :',random_search.best_params_  )\n",
    "\n",
    "y_pred = random_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 50 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   36.3s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.860524012029248\n",
      "Best parameters : {'C': 0.1, 'class_weight': None, 'solver': 'newton-cg'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.58      0.95      0.72       551\n",
      "           0       0.00      0.00      0.00       600\n",
      "           1       0.93      0.99      0.96      3849\n",
      "\n",
      "    accuracy                           0.87      5000\n",
      "   macro avg       0.50      0.65      0.56      5000\n",
      "weighted avg       0.78      0.87      0.82      5000\n",
      "\n",
      "[[ 526    2   23]\n",
      " [ 344    0  256]\n",
      " [  44    0 3805]]\n",
      "86.61999999999999\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning Logistic Regression - Grid Search\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "paramaters = [\n",
    "             {'C' : [0.01, 0.1, 1, 10, 100], \n",
    "              'solver': ['liblinear','lbfgs', 'newton-cg', 'sag','saga'], \n",
    "              'class_weight': [None, 'balanced']},                                       \n",
    "             ]\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = paramaters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 20,\n",
    "                           n_jobs = -1,\n",
    "                           verbose=5)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_ \n",
    "best_parameters = grid_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', grid_search.best_score_)\n",
    "print('Best parameters :', grid_search.best_params_  )\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 20 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   32.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.8602511607332042\n",
      "Best parameters : {'C': 12.267933515119251, 'class_weight': None, 'solver': 'liblinear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.58      0.95      0.72       551\n",
      "           0       0.00      0.00      0.00       600\n",
      "           1       0.93      0.99      0.96      3849\n",
      "\n",
      "    accuracy                           0.87      5000\n",
      "   macro avg       0.50      0.65      0.56      5000\n",
      "weighted avg       0.78      0.87      0.82      5000\n",
      "\n",
      "[[ 526    2   23]\n",
      " [ 344    0  256]\n",
      " [  44    0 3805]]\n",
      "86.61999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  2.6min finished\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning Logistic Regression - Random Search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint \n",
    "from scipy.stats import uniform\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "parameters = [\n",
    "             {'C' : uniform(0.01, 20), \n",
    "              'solver': ['liblinear','lbfgs', 'newton-cg', 'sag','saga'],\n",
    "              'class_weight': [None, 'balanced']}\n",
    "             ]\n",
    "\n",
    "              \n",
    "\n",
    "n_iter_search = 20\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_distributions=parameters,cv=20,n_iter=n_iter_search,n_jobs = -1,verbose=1)\n",
    "\n",
    "random_search = random_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = random_search.best_score_ \n",
    "best_parameters = random_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', random_search.best_score_)\n",
    "print('Best parameters :',random_search.best_params_  )\n",
    "\n",
    "y_pred = random_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### svm - grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC()\n",
    "\n",
    "paramaters = [ \n",
    "        {'kernel': ['linear'], \n",
    "         'C': [0.1, 1, 10], \n",
    "         'class_weight': [None, 'balanced']},\n",
    "        {'kernel': ['rbf', 'poly', 'sigmoid'], \n",
    "         'C': [0.1, 1, 10], \n",
    "         'gamma': [0.001, 0.01, 0.1, 0.2], \n",
    "         'class_weight': [None, 'balanced']},\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = paramaters,\n",
    "                           scoring = 'accuracy', \n",
    "                           cv = 2,\n",
    "                           n_jobs = -1,\n",
    "                           verbose =5)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_ \n",
    "best_parameters = grid_search.best_params_  \n",
    "print('Best accuracy : ', grid_search.best_score_)\n",
    "print('Best parameters :', grid_search.best_params_  )\n",
    "\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 20.2min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 46.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.7705633639690235\n",
      "Best parameters : {'kernel': 'sigmoid', 'gamma': 0.01, 'degree': 3, 'class_weight': None, 'C': 10}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       551\n",
      "           0       0.00      0.00      0.00       600\n",
      "           1       0.77      1.00      0.87      3849\n",
      "\n",
      "    accuracy                           0.77      5000\n",
      "   macro avg       0.26      0.33      0.29      5000\n",
      "weighted avg       0.59      0.77      0.67      5000\n",
      "\n",
      "[[   0    0  551]\n",
      " [   0    0  600]\n",
      " [   0    0 3849]]\n",
      "76.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dominic Ho\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning SVM - Random Search\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint \n",
    "from scipy.stats import uniform\n",
    "\n",
    "#svc trainen\n",
    "model = SVC()\n",
    "\n",
    "parameters = [\n",
    "    {'kernel': ['linear'], \n",
    "     'C': [0.01, 0.1, 1, 10], \n",
    "     'degree': [2,3,4], \n",
    "     'class_weight': [None, 'balanced']\n",
    "    },\n",
    "    {'kernel': ['rbf', 'poly', 'sigmoid'], \n",
    "     'C': [0.01, 0.1, 1, 10],\n",
    "     'gamma': [0.001, 0.01, 0.1, 0.2], \n",
    "     'degree': [2,3,4], \n",
    "     'class_weight': [None, 'balanced']}\n",
    "]\n",
    " \n",
    "n_iter_search = 20\n",
    "\n",
    "random_search_svm = RandomizedSearchCV(model, param_distributions=parameters,cv=5,n_iter=n_iter_search,n_jobs = -1,verbose=1)\n",
    "\n",
    "random_search_svm = random_search_svm.fit(X_train_tf, y_train)\n",
    "\n",
    "best_accuracy = random_search_svm.best_score_ \n",
    "best_parameters = random_search_svm.best_params_  \n",
    "\n",
    "print('Best accuracy : ', random_search_svm.best_score_)\n",
    "print('Best parameters :',random_search_svm.best_params_  )\n",
    "\n",
    "y_pred = random_search_svm.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general if we compare the 3 classifiers, we can see that there are differences in scores. Based on the scores the order is as follows: Logistic regression (86,61%), SVM (76,98%) and Naive Bayes (69,89%). Moreover, if we take the execution time into consideration then the logistic regression would be the most suitable classifier with a preference for class 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deel 3 - Cyber trolls\n",
    "\n",
    "Een cyber troll heeft als bedoeling emotionele reacties uit te lokken door opzettelijk verkeerde, kwetsende en agressieve berichten te plaatsen op forums, newsgroups, social media, etc. \n",
    "Online platformen hebben er een groot belang bij om deze cyber trolls te kunnen detecteren en weren van hun platform. Daarvoor gebruiken ze geavanceerde nlp algoritmes.\n",
    "Ontwerp zelf een cyber troll detector op basis. Je kan daarvoor beroep doen op de dataset 'Cybetrolls.csv'.\n",
    "Om de dataset te evalueren gebruik je een test set van 5000 berichten.\n",
    "\n",
    "Voor het evalueren van de classifier gebruik je de volgende metrics: accuracy, f1 score en de ROC. Formuleer conclusies. Bijvoorbeeld naar de keuze toe van de classifier, interpretatie van de ROC of auROC. Toon enkele verkeerd geclassificeerde berichten en probeer te achterhalen waarom ze verkeerd geclassificeerd werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Get fucking real dude.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>She is as dirty as they come  and that crook ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>why did you fuck it up. I could do it all day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Dude they dont finish enclosing the fucking s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>WTF are you talking about Men? No men thats n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   annotation                                            content\n",
       "0           1                             Get fucking real dude.\n",
       "1           1   She is as dirty as they come  and that crook ...\n",
       "2           1   why did you fuck it up. I could do it all day...\n",
       "3           1   Dude they dont finish enclosing the fucking s...\n",
       "4           1   WTF are you talking about Men? No men thats n..."
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('Cybetrolls.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Vooranalyse van de data.\n",
    "2. Preprocessing van de tekst.\n",
    "3. Omzetten naar bag-of-words.\n",
    "4. Trainen van de classifiers.\n",
    "5. Testen van de getrainde classifiers + uitvoeren van hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uitwerking Cyber trolls\n",
    "X = dataset.drop(['annotation'], axis=1).values\n",
    "y = dataset['annotation'].values\n",
    "\n",
    "\n",
    "# Opsplitsen in training set en test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=5000, random_state=0)\n",
    "X_train = X_train.reshape(-1)\n",
    "X_test = X_test.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Vooranalyse van de data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Onderzoek of er ontbrekende waarden in de datasets voorkomen.\n",
    "- Is de dataset gebalanceerd?\n",
    "- Onderzoek of er een correlatie te vinden is tussen de lengte van een bericht enerzijds en het sentiment anderzijds. Dit mag grafisch (via bijvoorbeeld een boxplot) of via correlatiecoëfficiënten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotation    0\n",
      "content       0\n",
      "dtype: int64\n",
      "No missing values.\n"
     ]
    }
   ],
   "source": [
    "# to find existing missing values\n",
    "print(dataset.isnull().sum())\n",
    "print('No missing values.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12179\n",
       "1     7822\n",
       "Name: annotation, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# is de dataset gebalanceerd?\n",
    "\n",
    "# gebalanceerdheid controleren\n",
    "sns.countplot(x='annotation',data=dataset)\n",
    "\n",
    "dataset['annotation'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not perfectly balanced. There are approximately 4350 samples more in the negative class than in the positive class. The classifier has a preference for the class without annotation (class 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1eebd461eb0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset['Content Length']=dataset['content'].apply(len)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.boxplot(x='annotation', y='Content Length', data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation</th>\n",
       "      <th>Content Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>annotation</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.053249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Content Length</th>\n",
       "      <td>0.053249</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                annotation  Content Length\n",
       "annotation        1.000000        0.053249\n",
       "Content Length    0.053249        1.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation coefficient of 0.05 indicates that the relationship is positive and has very little, almost no correlation. This means that the annotation and the content length has no correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing van de tekst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Kuis de teksten op: verwijder stopwoorden en niet-letters, zet alles om naar lowercase, ... \n",
    "- Pas stemming toe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing van de tekst\n",
    "\n",
    "def text_preprocessing(text, language, minWordSize):\n",
    "    \n",
    "    # remove html\n",
    "    text_no_html = BeautifulSoup(str(text),\"html.parser\" ).get_text()\n",
    "    \n",
    "    # remove non-letters\n",
    "    text_alpha_chars = re.sub(\"[^a-zA-Z']\", \" \", str(text_no_html)) \n",
    "        \n",
    "    # convert to lower-case\n",
    "    text_lower = text_alpha_chars.lower()\n",
    "    \n",
    "    # remove stop words\n",
    "    stops = set(stopwords.words(language)) \n",
    "    text_no_stop_words = ' '\n",
    "    \n",
    "    for w in text_lower.split():\n",
    "        if w not in stops:  \n",
    "            text_no_stop_words = text_no_stop_words + w + ' '\n",
    "      \n",
    "       # do stemming\n",
    "    text_stemmer = ' '\n",
    "    stemmer = SnowballStemmer(language)\n",
    "    for w in text_no_stop_words.split():\n",
    "        text_stemmer = text_stemmer + stemmer.stem(w) + ' '\n",
    "         \n",
    "    # remove short words\n",
    "    text_no_short_words = ' '\n",
    "    for w in text_stemmer.split(): \n",
    "        if len(w) >=minWordSize:\n",
    "            text_no_short_words = text_no_short_words + w + ' '\n",
    " \n",
    "\n",
    "    return text_no_short_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dominic Ho\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \"  ..\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dominic Ho\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:414: MarkupResemblesLocatorWarning: \"http://tinyurl.com/these-hats-are-damn-tradition\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dominic Ho\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \"  .\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dominic Ho\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \"  ....\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dominic Ho\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \" .\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Convert training and test set to bag of words\n",
    "language = 'english'\n",
    "minWordLength = 2\n",
    "\n",
    "for i in range(X_train.size):\n",
    "    X_train[i] = text_preprocessing(X_train[i], language, minWordLength)\n",
    "    \n",
    "    \n",
    "for i in range(X_test.size):\n",
    "    X_test[i] = text_preprocessing(X_test[i], language, minWordLength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Omzetten naar bag-of-words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maak gebruik van de CountVectorizer en TfidfTransformer om een bag-of-words model te creëren. \n",
    "\n",
    "Meer info: \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3317)\t1\n",
      "  (0, 5689)\t1\n",
      "  (0, 5979)\t1\n",
      "  (0, 7363)\t1\n",
      "  (1, 1673)\t1\n",
      "  (1, 3256)\t1\n",
      "  (1, 6575)\t1\n",
      "  (1, 8098)\t1\n",
      "  (1, 8588)\t1\n",
      "  (1, 9563)\t1\n",
      "  (1, 10611)\t2\n",
      "  (2, 659)\t1\n",
      "  (2, 1007)\t1\n",
      "  (2, 3336)\t2\n",
      "  (2, 4671)\t1\n",
      "  (2, 5689)\t1\n",
      "  (2, 5951)\t2\n",
      "  (2, 7283)\t1\n",
      "  (2, 7585)\t1\n",
      "  (2, 7908)\t1\n",
      "  (2, 8241)\t1\n",
      "  (2, 8648)\t1\n",
      "  (2, 9314)\t1\n",
      "  (2, 9558)\t1\n",
      "  (3, 391)\t1\n",
      "  :\t:\n",
      "  (14996, 7952)\t1\n",
      "  (14996, 9804)\t1\n",
      "  (14996, 10662)\t1\n",
      "  (14997, 8694)\t1\n",
      "  (14997, 11094)\t1\n",
      "  (14998, 2225)\t1\n",
      "  (14998, 3668)\t1\n",
      "  (14998, 6701)\t1\n",
      "  (14998, 8785)\t1\n",
      "  (14998, 9336)\t1\n",
      "  (14998, 9590)\t1\n",
      "  (14999, 491)\t1\n",
      "  (14999, 3968)\t1\n",
      "  (14999, 5781)\t1\n",
      "  (14999, 6340)\t1\n",
      "  (14999, 9140)\t1\n",
      "  (14999, 9684)\t1\n",
      "  (14999, 10801)\t1\n",
      "  (15000, 987)\t1\n",
      "  (15000, 1419)\t1\n",
      "  (15000, 3256)\t3\n",
      "  (15000, 3556)\t1\n",
      "  (15000, 4270)\t1\n",
      "  (15000, 5506)\t1\n",
      "  (15000, 7948)\t1\n"
     ]
    }
   ],
   "source": [
    "# Omzetten naar bag-of-words\n",
    "\n",
    "# Make sparse features vectors \n",
    "\n",
    "# create instance \n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "# train the object on the training set\n",
    "X_train_bag_of_words = count_vect.fit(X_train)\n",
    "\n",
    "# apply  the function on train\n",
    "X_train_bag_of_words = count_vect.transform(X_train)\n",
    "# apply  the function on test\n",
    "X_test_bag_of_words = count_vect.transform(X_test)\n",
    "\n",
    "print(X_train_bag_of_words)\n",
    "#print(X_test_bag_of_words)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_bag_of_words)\n",
    "X_train_tf = tf_transformer.transform(X_train_bag_of_words)\n",
    "X_test_tf = tf_transformer.transform(X_test_bag_of_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " like mani photo fb \n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Trainen van de classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train drie verschillende classifiers op de bag-of-words data: naive bayes classifier, logistic regression classifier en een Support Vector Machine classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Naive bayes classifier\n",
    "\n",
    "NBclassifier = MultinomialNB(alpha=1)\n",
    "\n",
    "NBclassifier.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.91      0.83      3053\n",
      "           1       0.80      0.55      0.65      1947\n",
      "\n",
      "    accuracy                           0.77      5000\n",
      "   macro avg       0.78      0.73      0.74      5000\n",
      "weighted avg       0.78      0.77      0.76      5000\n",
      "\n",
      "[[2789  264]\n",
      " [ 876 1071]]\n",
      "77.2\n"
     ]
    }
   ],
   "source": [
    "# test Naive Bayes classifier\n",
    "\n",
    "y_pred = NBclassifier.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dominic Ho\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a logistic regression classifier\n",
    "lregclassifier = LogisticRegression(C=10)\n",
    "\n",
    "lregclassifier.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.87      3053\n",
      "           1       0.76      0.86      0.81      1947\n",
      "\n",
      "    accuracy                           0.84      5000\n",
      "   macro avg       0.83      0.85      0.84      5000\n",
      "weighted avg       0.85      0.84      0.84      5000\n",
      "\n",
      "[[2536  517]\n",
      " [ 267 1680]]\n",
      "84.32\n"
     ]
    }
   ],
   "source": [
    "# test logistic classifier\n",
    "\n",
    "y_pred = lregclassifier.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, kernel='linear', probability=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a SVM\n",
    "SVMlinear = svm.SVC(kernel='linear',C=0.1, probability=True)\n",
    "SVMlinear.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.92      0.79      3053\n",
      "           1       0.72      0.34      0.47      1947\n",
      "\n",
      "    accuracy                           0.69      5000\n",
      "   macro avg       0.71      0.63      0.63      5000\n",
      "weighted avg       0.70      0.69      0.66      5000\n",
      "\n",
      "[[2797  256]\n",
      " [1276  671]]\n",
      "69.36\n"
     ]
    }
   ],
   "source": [
    "# test SVM\n",
    "y_pred = SVMlinear.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression has the highest accuracy rate of 84,32%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Testen van de getrainde classifiers + uitvoeren van hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Voer hyperparameter tuning uit via grid-search, random search of Bayes Optimization.\n",
    "- Welke classifier heeft jouw voorkeur? Beargumenteer in de context van accuracy, f1-score en berekeningstijd.\n",
    "- Bekijk enkele verkeerd geklassificeerde reviews. Is er een verklaring voor te vinden?\n",
    "\n",
    "\n",
    "Voor het evalueren van de classifier gebruik je de volgende metrics: accuracy, f1 score en de ROC. Formuleer conclusies. Bijvoorbeeld naar de keuze toe van de classifier, interpretatie van de ROC of auROC. Toon enkele verkeerd geclassificeerde berichten en probeer te achterhalen waarom ze verkeerd geclassificeerd werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 5 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    2.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.7953489569462937\n",
      "Best parameters : {'alpha': 0.001}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84      3053\n",
      "           1       0.75      0.77      0.76      1947\n",
      "\n",
      "    accuracy                           0.81      5000\n",
      "   macro avg       0.80      0.80      0.80      5000\n",
      "weighted avg       0.81      0.81      0.81      5000\n",
      "\n",
      "[[2549  504]\n",
      " [ 442 1505]]\n",
      "81.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.8s finished\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning Naive Bayes - Grid Search\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "model = MultinomialNB()\n",
    "paramaters = [\n",
    "             {'alpha' : [0.001, 0.01, 0.1, 1, 10]}                                       \n",
    "             ]\n",
    "\n",
    "grid_search_nb = GridSearchCV(estimator = model, \n",
    "                           param_grid = paramaters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 20,\n",
    "                           n_jobs = -1,\n",
    "                           verbose=5)\n",
    "grid_search_nb = grid_search_nb.fit(X_train_tf, y_train)\n",
    "\n",
    "best_accuracy = grid_search_nb.best_score_ \n",
    "best_parameters = grid_search_nb.best_params_  \n",
    "\n",
    "print('Best accuracy : ', grid_search_nb.best_score_)\n",
    "print('Best parameters :', grid_search_nb.best_params_  )\n",
    "\n",
    "y_pred = grid_search_nb.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dominic Ho\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:278: UserWarning: The total space of parameters 5 is smaller than n_iter=20. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  25 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best accuracy :  0.7770822392535821\n",
      "Best parameters : {'alpha': 0.01}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84      3053\n",
      "           1       0.75      0.77      0.76      1947\n",
      "\n",
      "    accuracy                           0.81      5000\n",
      "   macro avg       0.80      0.80      0.80      5000\n",
      "weighted avg       0.81      0.81      0.81      5000\n",
      "\n",
      "[[2548  505]\n",
      " [ 445 1502]]\n",
      "81.0\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning Naive Bayes - Random Search\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# distributions\n",
    "from scipy.stats import randint \n",
    "from scipy.stats import uniform\n",
    "\n",
    "\n",
    "model = MultinomialNB()\n",
    "parameters = [\n",
    "             {'alpha' : [0.001, 0.01, 0.1, 1, 10]}                                       \n",
    "             ]\n",
    "\n",
    "# random search zoeken, bv 20 willekeurig random searches\n",
    "n_iter_search = 20\n",
    "\n",
    "# cv = cross validatie\n",
    "random_search_nb = RandomizedSearchCV(model, param_distributions=parameters,cv=5,n_iter=n_iter_search,n_jobs = -1,verbose=1)\n",
    "\n",
    "random_search_nb = random_search_nb.fit(X_train_tf, y_train)\n",
    "\n",
    "best_accuracy = random_search_nb.best_score_ \n",
    "best_parameters = random_search_nb.best_params_  \n",
    "\n",
    "print('Best accuracy : ', random_search_nb.best_score_)\n",
    "print('Best parameters :',random_search_nb.best_params_  )\n",
    "\n",
    "y_pred = random_search_nb.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "probs = grid_search_nb.predict_proba(X_test_tf)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 50 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 216 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 522 tasks      | elapsed:   22.4s\n",
      "[Parallel(n_jobs=-1)]: Done 648 tasks      | elapsed:   33.2s\n",
      "[Parallel(n_jobs=-1)]: Done 810 tasks      | elapsed:   54.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.8636106524633821\n",
      "Best parameters : {'C': 100, 'class_weight': None, 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87      3053\n",
      "           1       0.76      0.89      0.82      1947\n",
      "\n",
      "    accuracy                           0.85      5000\n",
      "   macro avg       0.84      0.86      0.84      5000\n",
      "weighted avg       0.86      0.85      0.85      5000\n",
      "\n",
      "[[2493  560]\n",
      " [ 205 1742]]\n",
      "84.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dominic Ho\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning Logistic Regression - Grid Search\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "paramaters = [\n",
    "             {'C' : [0.01, 0.1, 1, 10, 100], \n",
    "              'solver': ['liblinear','lbfgs', 'newton-cg', 'sag','saga'], \n",
    "              'class_weight': [None, 'balanced']},                                       \n",
    "             ]\n",
    "\n",
    "\n",
    "grid_search_lr = GridSearchCV(estimator = model, \n",
    "                           param_grid = paramaters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 20,\n",
    "                           n_jobs = -1,\n",
    "                           verbose=5)\n",
    "grid_search_lr = grid_search_lr.fit(X_train_tf, y_train)\n",
    "\n",
    "best_accuracy = grid_search_lr.best_score_ \n",
    "best_parameters = grid_search_lr.best_params_  \n",
    "\n",
    "print('Best accuracy : ', grid_search_lr.best_score_)\n",
    "print('Best parameters :', grid_search_lr.best_params_  )\n",
    "\n",
    "y_pred = grid_search_lr.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 20 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   32.1s\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.8574778517532179\n",
      "Best parameters : {'C': 18.042249491270713, 'class_weight': None, 'solver': 'lbfgs'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.83      0.87      3053\n",
      "           1       0.77      0.88      0.82      1947\n",
      "\n",
      "    accuracy                           0.85      5000\n",
      "   macro avg       0.84      0.86      0.85      5000\n",
      "weighted avg       0.86      0.85      0.85      5000\n",
      "\n",
      "[[2536  517]\n",
      " [ 224 1723]]\n",
      "85.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dominic Ho\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning Logistic Regression - Random Search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint \n",
    "from scipy.stats import uniform\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "parameters = [\n",
    "             {'C' : uniform(0.01, 20), \n",
    "              'solver': ['liblinear','lbfgs', 'newton-cg', 'sag','saga'],\n",
    "              'class_weight': [None, 'balanced']}\n",
    "             ]\n",
    "\n",
    "              \n",
    "\n",
    "n_iter_search = 20\n",
    "\n",
    "random_search_lr = RandomizedSearchCV(model, param_distributions=parameters,cv=20,n_iter=n_iter_search,n_jobs = -1,verbose=1)\n",
    "\n",
    "random_search_lr = random_search_lr.fit(X_train_tf, y_train)\n",
    "\n",
    "best_accuracy = random_search_lr.best_score_ \n",
    "best_parameters = random_search_lr.best_params_  \n",
    "\n",
    "print('Best accuracy : ', random_search_lr.best_score_)\n",
    "print('Best parameters :',random_search_lr.best_params_  )\n",
    "\n",
    "y_pred = random_search_lr.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "probs = random_search_lr.predict_proba(X_test_tf)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 78 candidates, totalling 156 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 14.6min\n",
      "[Parallel(n_jobs=-1)]: Done 156 out of 156 | elapsed: 42.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.8006137759409857\n",
      "Best parameters : {'C': 10, 'class_weight': None, 'gamma': 0.2, 'kernel': 'rbf'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.89      3053\n",
      "           1       0.79      0.92      0.85      1947\n",
      "\n",
      "    accuracy                           0.87      5000\n",
      "   macro avg       0.87      0.88      0.87      5000\n",
      "weighted avg       0.88      0.87      0.88      5000\n",
      "\n",
      "[[2581  472]\n",
      " [ 159 1788]]\n",
      "87.38\n"
     ]
    }
   ],
   "source": [
    "# laten draaien\n",
    "# hyperparameter tuning SVM - Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(probability=True)\n",
    "\n",
    "paramaters = [ \n",
    "        {'kernel': ['linear'], \n",
    "         'C':  [0.1, 1, 10], \n",
    "         'class_weight': [None, 'balanced']},\n",
    "        {'kernel': ['rbf', 'poly', 'sigmoid'], \n",
    "         'C': [0.1, 1, 10], \n",
    "         'gamma': [0.001, 0.01, 0.1, 0.2], \n",
    "         'class_weight': [None, 'balanced']},\n",
    "]\n",
    "\n",
    "grid_search_svm = GridSearchCV(estimator = model, \n",
    "                           param_grid = paramaters,\n",
    "                           scoring = 'accuracy', \n",
    "                           cv = 2,\n",
    "                           n_jobs = -1,\n",
    "                           verbose =5,)\n",
    "\n",
    "grid_search_svm = grid_search_svm.fit(X_train_tf, y_train)\n",
    "\n",
    "best_accuracy = grid_search_svm.best_score_ \n",
    "best_parameters = grid_search_svm.best_params_  \n",
    "print('Best accuracy : ', grid_search_svm.best_score_)\n",
    "print('Best parameters :', grid_search_svm.best_params_  )\n",
    "\n",
    "\n",
    "y_pred = grid_search_svm.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 21.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.8356113073419971\n",
      "Best parameters : {'C': 18.606927335765125, 'class_weight': None, 'degree': 4, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.80      0.86      3053\n",
      "           1       0.74      0.90      0.81      1947\n",
      "\n",
      "    accuracy                           0.84      5000\n",
      "   macro avg       0.83      0.85      0.83      5000\n",
      "weighted avg       0.85      0.84      0.84      5000\n",
      "\n",
      "[[2442  611]\n",
      " [ 199 1748]]\n",
      "83.8\n"
     ]
    }
   ],
   "source": [
    "# laten draaien\n",
    "# hyperparameter tuning SVM - Random Search\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint \n",
    "from scipy.stats import uniform\n",
    "\n",
    "\n",
    "#svc trainen\n",
    "model = SVC()\n",
    "\n",
    "parameters = [\n",
    "    {'kernel': ['linear'], \n",
    "     'C': uniform(0.01, 20), \n",
    "     'degree': [2,3,4], \n",
    "     'class_weight': [None, 'balanced']\n",
    "    },\n",
    "    {'kernel': ['rbf', 'poly', 'sigmoid'], \n",
    "     'C': uniform(0.01, 20), \n",
    "     'gamma': uniform(0.001, 0.2), \n",
    "     'degree': [2,3,4], \n",
    "     'class_weight': [None, 'balanced']}\n",
    "]\n",
    " \n",
    "n_iter_search = 20\n",
    "\n",
    "random_search_svm = RandomizedSearchCV(model, param_distributions=parameters,cv=5,n_iter=n_iter_search,n_jobs = -1,verbose=1)\n",
    "\n",
    "random_search_svm = random_search_svm.fit(X_train_tf, y_train)\n",
    "\n",
    "best_accuracy = random_search_svm.best_score_ \n",
    "best_parameters = random_search_svm.best_params_  \n",
    "\n",
    "print('Best accuracy : ', random_search_svm.best_score_)\n",
    "print('Best parameters :',random_search_svm.best_params_  )\n",
    "\n",
    "y_pred = random_search_svm.predict(X_test_tf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "probs = grid_search_svm.predict_proba(X_test_tf)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general if we compare the 3 classifiers, we can see that there are differences in scores. Based on the scores the order is as follows: SVM - Grid Search(87,38%), Logistic Regression (85,18%) and Naive Bayes (81,08%). Eventhough the SVM has the longest execution time, it is still the most suitable classifier due to the fact that the difference of accuracy is huge between the classifiers. Therefore it is also more reliable.\n",
    "\n",
    "The ROC curve is a good graph to summarize the quality of our classifier. The higher the curve is above the diagonal baseline, the better the predictions. In this case, the highest AUC amounts 0.95 from the SVM (grid search) classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toon enkele verkeerd geclassificeerde berichten en probeer te achterhalen waarom ze verkeerd geclassificeerd werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [i for i in range(len(y_test)) if y_test[i] != y_pred[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Get fucking real dude.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>WTF are you talking about Men? No men thats n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>...go absolutely insane.hate to be the bearer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Lmao  im watching the same thing ahaha. The ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>damn it i totally forgot that one!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4987</th>\n",
       "      <td>1</td>\n",
       "      <td>lol ur whale penis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4988</th>\n",
       "      <td>1</td>\n",
       "      <td>I know there's a bottle of bourbon in that hou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>1</td>\n",
       "      <td>DAMN.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>1</td>\n",
       "      <td>ouch that sucks..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>1</td>\n",
       "      <td>dawns a Fucking twat and @occultclassic that i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1872 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      annotation                                            content\n",
       "0              1                             Get fucking real dude.\n",
       "4              1   WTF are you talking about Men? No men thats n...\n",
       "7              1  ...go absolutely insane.hate to be the bearer ...\n",
       "8              1  Lmao  im watching the same thing ahaha. The ga...\n",
       "14             1                 damn it i totally forgot that one!\n",
       "...          ...                                                ...\n",
       "4987           1                                 lol ur whale penis\n",
       "4988           1  I know there's a bottle of bourbon in that hou...\n",
       "4991           1                                              DAMN.\n",
       "4995           1                                  ouch that sucks..\n",
       "4999           1  dawns a Fucking twat and @occultclassic that i...\n",
       "\n",
       "[1872 rows x 2 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_predictions = dataset.iloc[indices,:]\n",
    "wrong_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the wrong classified predictions, we could say that words with spelling mistakes and slang words are often used."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
