{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "from scipy.stats import randint \n",
    "from scipy.stats import uniform\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import svm\n",
    "\n",
    "# from sklearn.tree import export_graphviz\n",
    "pd.set_option('display.max_rows',1000)\n",
    "pd.set_option('display.max_columns',1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NASA\n",
    "Gegeven is de dataset **nasa.csv**. Deze dataset bevat gegevens en metingen van waargenomen meteorieten. De bedoeling is om op basis van deze metingen (features) een betrouwbare voorspelling te kunnen doen of een bepaalde meteoriet al dan niet gevaarlijk is. Of ze met andere woorden kan inslaan op de aarde.\n",
    "Er wordt een accuracy van minstens 95% geÃ«ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inlezen en preprocessing van de dataset\n",
    "\n",
    "1.  Verwijder de kolommen 'Neo Reference ID', 'Name', 'Close Approach Date','Epoch Date Close Approach', 'Orbiting Body','Orbit Determination Date' en 'Equinox'\n",
    "2. Verwijder de samples met ontbrekende waarden volledig(listwise deletion)\n",
    "3. Ga op zoek onrealistische waarden en verwijder telkens volledige sample (listwise deletion)\n",
    "4. Vervang de waarden uit de target kolom Hazardous: False / True -> 0 / 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neo Reference ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Absolute Magnitude</th>\n",
       "      <th>Est Dia in KM(min)</th>\n",
       "      <th>Est Dia in KM(max)</th>\n",
       "      <th>Close Approach Date</th>\n",
       "      <th>Epoch Date Close Approach</th>\n",
       "      <th>Relative Velocity km per sec</th>\n",
       "      <th>Relative Velocity km per hr</th>\n",
       "      <th>Miss Dist.(Astronomical)</th>\n",
       "      <th>Miss Dist.(lunar)</th>\n",
       "      <th>Miss Dist.(kilometers)</th>\n",
       "      <th>Orbiting Body</th>\n",
       "      <th>Orbit ID</th>\n",
       "      <th>Orbit Determination Date</th>\n",
       "      <th>Orbit Uncertainity</th>\n",
       "      <th>Minimum Orbit Intersection</th>\n",
       "      <th>Jupiter Tisserand Invariant</th>\n",
       "      <th>Epoch Osculation</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>Semi Major Axis</th>\n",
       "      <th>Inclination</th>\n",
       "      <th>Asc Node Longitude</th>\n",
       "      <th>Orbital Period</th>\n",
       "      <th>Perihelion Distance</th>\n",
       "      <th>Perihelion Arg</th>\n",
       "      <th>Aphelion Dist</th>\n",
       "      <th>Perihelion Time</th>\n",
       "      <th>Mean Anomaly</th>\n",
       "      <th>Mean Motion</th>\n",
       "      <th>Equinox</th>\n",
       "      <th>Hazardous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3703080</td>\n",
       "      <td>3703080</td>\n",
       "      <td>21.6</td>\n",
       "      <td>0.127220</td>\n",
       "      <td>0.284472</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>788947200000</td>\n",
       "      <td>6.115834</td>\n",
       "      <td>22017.003799</td>\n",
       "      <td>0.419483</td>\n",
       "      <td>163.178711</td>\n",
       "      <td>62753692.0</td>\n",
       "      <td>Earth</td>\n",
       "      <td>17</td>\n",
       "      <td>2017-04-06 08:36:37</td>\n",
       "      <td>5</td>\n",
       "      <td>0.025282</td>\n",
       "      <td>4634</td>\n",
       "      <td>2458000.5</td>\n",
       "      <td>0.425549</td>\n",
       "      <td>1.407011</td>\n",
       "      <td>6.025981</td>\n",
       "      <td>314.373913</td>\n",
       "      <td>609.599786</td>\n",
       "      <td>0.808259</td>\n",
       "      <td>57.257470</td>\n",
       "      <td>2.005764</td>\n",
       "      <td>2.458162e+06</td>\n",
       "      <td>264.837533</td>\n",
       "      <td>0.590551</td>\n",
       "      <td>J2000</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3723955</td>\n",
       "      <td>3723955</td>\n",
       "      <td>21.3</td>\n",
       "      <td>0.146068</td>\n",
       "      <td>0.326618</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>788947200000</td>\n",
       "      <td>18.113985</td>\n",
       "      <td>65210.346095</td>\n",
       "      <td>0.383014</td>\n",
       "      <td>148.992630</td>\n",
       "      <td>57298148.0</td>\n",
       "      <td>Earth</td>\n",
       "      <td>21</td>\n",
       "      <td>2017-04-06 08:32:49</td>\n",
       "      <td>3</td>\n",
       "      <td>0.186935</td>\n",
       "      <td>5457</td>\n",
       "      <td>2458000.5</td>\n",
       "      <td>0.351674</td>\n",
       "      <td>1.107776</td>\n",
       "      <td>28.412996</td>\n",
       "      <td>136.717242</td>\n",
       "      <td>425.869294</td>\n",
       "      <td>0.718200</td>\n",
       "      <td>313.091975</td>\n",
       "      <td>1.497352</td>\n",
       "      <td>2.457795e+06</td>\n",
       "      <td>173.741112</td>\n",
       "      <td>0.845330</td>\n",
       "      <td>J2000</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2446862</td>\n",
       "      <td>2446862</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0.231502</td>\n",
       "      <td>0.517654</td>\n",
       "      <td>1995-01-08</td>\n",
       "      <td>789552000000</td>\n",
       "      <td>7.590711</td>\n",
       "      <td>27326.560182</td>\n",
       "      <td>0.050956</td>\n",
       "      <td>19.821890</td>\n",
       "      <td>7622911.5</td>\n",
       "      <td>Earth</td>\n",
       "      <td>22</td>\n",
       "      <td>2017-04-06 09:20:19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043058</td>\n",
       "      <td>4557</td>\n",
       "      <td>2458000.5</td>\n",
       "      <td>0.348248</td>\n",
       "      <td>1.458824</td>\n",
       "      <td>4.237961</td>\n",
       "      <td>259.475979</td>\n",
       "      <td>643.580228</td>\n",
       "      <td>0.950791</td>\n",
       "      <td>248.415038</td>\n",
       "      <td>1.966857</td>\n",
       "      <td>2.458120e+06</td>\n",
       "      <td>292.893654</td>\n",
       "      <td>0.559371</td>\n",
       "      <td>J2000</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3092506</td>\n",
       "      <td>3092506</td>\n",
       "      <td>27.4</td>\n",
       "      <td>0.008801</td>\n",
       "      <td>0.019681</td>\n",
       "      <td>1995-01-15</td>\n",
       "      <td>790156800000</td>\n",
       "      <td>11.173874</td>\n",
       "      <td>40225.948191</td>\n",
       "      <td>0.285322</td>\n",
       "      <td>110.990387</td>\n",
       "      <td>42683616.0</td>\n",
       "      <td>Earth</td>\n",
       "      <td>7</td>\n",
       "      <td>2017-04-06 09:15:49</td>\n",
       "      <td>6</td>\n",
       "      <td>0.005512</td>\n",
       "      <td>5093</td>\n",
       "      <td>2458000.5</td>\n",
       "      <td>0.216578</td>\n",
       "      <td>1.255903</td>\n",
       "      <td>7.905894</td>\n",
       "      <td>57.173266</td>\n",
       "      <td>514.082140</td>\n",
       "      <td>0.983902</td>\n",
       "      <td>18.707701</td>\n",
       "      <td>1.527904</td>\n",
       "      <td>2.457902e+06</td>\n",
       "      <td>68.741007</td>\n",
       "      <td>0.700277</td>\n",
       "      <td>J2000</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3514799</td>\n",
       "      <td>3514799</td>\n",
       "      <td>21.6</td>\n",
       "      <td>0.127220</td>\n",
       "      <td>0.284472</td>\n",
       "      <td>1995-01-15</td>\n",
       "      <td>790156800000</td>\n",
       "      <td>9.840831</td>\n",
       "      <td>35426.991794</td>\n",
       "      <td>0.407832</td>\n",
       "      <td>158.646713</td>\n",
       "      <td>61010824.0</td>\n",
       "      <td>Earth</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-04-06 08:57:58</td>\n",
       "      <td>1</td>\n",
       "      <td>0.034798</td>\n",
       "      <td>5154</td>\n",
       "      <td>2458000.5</td>\n",
       "      <td>0.210448</td>\n",
       "      <td>1.225615</td>\n",
       "      <td>16.793382</td>\n",
       "      <td>84.629307</td>\n",
       "      <td>495.597821</td>\n",
       "      <td>0.967687</td>\n",
       "      <td>158.263596</td>\n",
       "      <td>1.483543</td>\n",
       "      <td>2.457814e+06</td>\n",
       "      <td>135.142133</td>\n",
       "      <td>0.726395</td>\n",
       "      <td>J2000</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Neo Reference ID     Name  Absolute Magnitude  Est Dia in KM(min)  \\\n",
       "0           3703080  3703080                21.6            0.127220   \n",
       "1           3723955  3723955                21.3            0.146068   \n",
       "2           2446862  2446862                20.3            0.231502   \n",
       "3           3092506  3092506                27.4            0.008801   \n",
       "4           3514799  3514799                21.6            0.127220   \n",
       "\n",
       "   Est Dia in KM(max) Close Approach Date  Epoch Date Close Approach  \\\n",
       "0            0.284472          1995-01-01               788947200000   \n",
       "1            0.326618          1995-01-01               788947200000   \n",
       "2            0.517654          1995-01-08               789552000000   \n",
       "3            0.019681          1995-01-15               790156800000   \n",
       "4            0.284472          1995-01-15               790156800000   \n",
       "\n",
       "   Relative Velocity km per sec  Relative Velocity km per hr  \\\n",
       "0                      6.115834                 22017.003799   \n",
       "1                     18.113985                 65210.346095   \n",
       "2                      7.590711                 27326.560182   \n",
       "3                     11.173874                 40225.948191   \n",
       "4                      9.840831                 35426.991794   \n",
       "\n",
       "   Miss Dist.(Astronomical)  Miss Dist.(lunar)  Miss Dist.(kilometers)  \\\n",
       "0                  0.419483         163.178711              62753692.0   \n",
       "1                  0.383014         148.992630              57298148.0   \n",
       "2                  0.050956          19.821890               7622911.5   \n",
       "3                  0.285322         110.990387              42683616.0   \n",
       "4                  0.407832         158.646713              61010824.0   \n",
       "\n",
       "  Orbiting Body  Orbit ID Orbit Determination Date  Orbit Uncertainity  \\\n",
       "0         Earth        17      2017-04-06 08:36:37                   5   \n",
       "1         Earth        21      2017-04-06 08:32:49                   3   \n",
       "2         Earth        22      2017-04-06 09:20:19                   0   \n",
       "3         Earth         7      2017-04-06 09:15:49                   6   \n",
       "4         Earth        25      2017-04-06 08:57:58                   1   \n",
       "\n",
       "   Minimum Orbit Intersection  Jupiter Tisserand Invariant  Epoch Osculation  \\\n",
       "0                    0.025282                         4634         2458000.5   \n",
       "1                    0.186935                         5457         2458000.5   \n",
       "2                    0.043058                         4557         2458000.5   \n",
       "3                    0.005512                         5093         2458000.5   \n",
       "4                    0.034798                         5154         2458000.5   \n",
       "\n",
       "   Eccentricity  Semi Major Axis  Inclination  Asc Node Longitude  \\\n",
       "0      0.425549         1.407011     6.025981          314.373913   \n",
       "1      0.351674         1.107776    28.412996          136.717242   \n",
       "2      0.348248         1.458824     4.237961          259.475979   \n",
       "3      0.216578         1.255903     7.905894           57.173266   \n",
       "4      0.210448         1.225615    16.793382           84.629307   \n",
       "\n",
       "   Orbital Period  Perihelion Distance  Perihelion Arg  Aphelion Dist  \\\n",
       "0      609.599786             0.808259       57.257470       2.005764   \n",
       "1      425.869294             0.718200      313.091975       1.497352   \n",
       "2      643.580228             0.950791      248.415038       1.966857   \n",
       "3      514.082140             0.983902       18.707701       1.527904   \n",
       "4      495.597821             0.967687      158.263596       1.483543   \n",
       "\n",
       "   Perihelion Time  Mean Anomaly  Mean Motion Equinox Hazardous  \n",
       "0     2.458162e+06    264.837533     0.590551   J2000       yes  \n",
       "1     2.457795e+06    173.741112     0.845330   J2000        no  \n",
       "2     2.458120e+06    292.893654     0.559371   J2000       yes  \n",
       "3     2.457902e+06     68.741007     0.700277   J2000        no  \n",
       "4     2.457814e+06    135.142133     0.726395   J2000       yes  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inladen van de dataset\n",
    "dataset = pd.read_csv('nasa.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verwijderen van de gevraagde kolommen\n",
    "\n",
    "# Verwijder de kolommen 'Neo Reference ID', 'Name', 'Close Approach Date','Epoch Date Close Approach', 'Orbiting Body','Orbit Determination Date' en 'Equinox'\n",
    "dataset.drop(['Neo Reference ID'], axis=1, inplace=True)\n",
    "dataset.drop(['Name'], axis=1, inplace=True)\n",
    "dataset.drop(['Epoch Date Close Approach'], axis=1, inplace=True)\n",
    "dataset.drop(['Close Approach Date'], axis=1, inplace=True)\n",
    "dataset.drop(['Orbiting Body'], axis=1, inplace=True)\n",
    "dataset.drop(['Orbit Determination Date'], axis=1, inplace=True)\n",
    "dataset.drop(['Equinox'], axis=1, inplace=True)\n",
    "\n",
    "# Vervang de waarden uit de output kolom Hazardous: False / True -> 0 / 1\n",
    "dataset['Hazardous'] = dataset['Hazardous'].map({'no':0 ,'yes':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute Magnitude              0\n",
      "Est Dia in KM(min)              1\n",
      "Est Dia in KM(max)              0\n",
      "Relative Velocity km per sec    0\n",
      "Relative Velocity km per hr     0\n",
      "Miss Dist.(Astronomical)        0\n",
      "Miss Dist.(lunar)               0\n",
      "Miss Dist.(kilometers)          0\n",
      "Orbit ID                        0\n",
      "Orbit Uncertainity              0\n",
      "Minimum Orbit Intersection      0\n",
      "Jupiter Tisserand Invariant     0\n",
      "Epoch Osculation                0\n",
      "Eccentricity                    0\n",
      "Semi Major Axis                 0\n",
      "Inclination                     0\n",
      "Asc Node Longitude              0\n",
      "Orbital Period                  0\n",
      "Perihelion Distance             0\n",
      "Perihelion Arg                  0\n",
      "Aphelion Dist                   0\n",
      "Perihelion Time                 0\n",
      "Mean Anomaly                    0\n",
      "Mean Motion                     0\n",
      "Hazardous                       0\n",
      "dtype: int64\n",
      "(4687, 25)\n",
      "Absolute Magnitude              0\n",
      "Est Dia in KM(min)              0\n",
      "Est Dia in KM(max)              0\n",
      "Relative Velocity km per sec    0\n",
      "Relative Velocity km per hr     0\n",
      "Miss Dist.(Astronomical)        0\n",
      "Miss Dist.(lunar)               0\n",
      "Miss Dist.(kilometers)          0\n",
      "Orbit ID                        0\n",
      "Orbit Uncertainity              0\n",
      "Minimum Orbit Intersection      0\n",
      "Jupiter Tisserand Invariant     0\n",
      "Epoch Osculation                0\n",
      "Eccentricity                    0\n",
      "Semi Major Axis                 0\n",
      "Inclination                     0\n",
      "Asc Node Longitude              0\n",
      "Orbital Period                  0\n",
      "Perihelion Distance             0\n",
      "Perihelion Arg                  0\n",
      "Aphelion Dist                   0\n",
      "Perihelion Time                 0\n",
      "Mean Anomaly                    0\n",
      "Mean Motion                     0\n",
      "Hazardous                       0\n",
      "dtype: int64\n",
      "(4686, 25)\n"
     ]
    }
   ],
   "source": [
    "# Verwijderen van samples met ontbrekende waarden\n",
    "print(dataset.isnull().sum())\n",
    "print(dataset.shape)\n",
    "dataset.dropna(inplace=True)\n",
    "print(dataset.isnull().sum())\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Absolute Magnitude</th>\n",
       "      <th>Est Dia in KM(min)</th>\n",
       "      <th>Est Dia in KM(max)</th>\n",
       "      <th>Relative Velocity km per sec</th>\n",
       "      <th>Relative Velocity km per hr</th>\n",
       "      <th>Miss Dist.(Astronomical)</th>\n",
       "      <th>Miss Dist.(lunar)</th>\n",
       "      <th>Miss Dist.(kilometers)</th>\n",
       "      <th>Orbit ID</th>\n",
       "      <th>Orbit Uncertainity</th>\n",
       "      <th>Minimum Orbit Intersection</th>\n",
       "      <th>Jupiter Tisserand Invariant</th>\n",
       "      <th>Epoch Osculation</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>Semi Major Axis</th>\n",
       "      <th>Inclination</th>\n",
       "      <th>Asc Node Longitude</th>\n",
       "      <th>Orbital Period</th>\n",
       "      <th>Perihelion Distance</th>\n",
       "      <th>Perihelion Arg</th>\n",
       "      <th>Aphelion Dist</th>\n",
       "      <th>Perihelion Time</th>\n",
       "      <th>Mean Anomaly</th>\n",
       "      <th>Mean Motion</th>\n",
       "      <th>Hazardous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4686.000000</td>\n",
       "      <td>4686.000000</td>\n",
       "      <td>4686.000000</td>\n",
       "      <td>4686.000000</td>\n",
       "      <td>4686.000000</td>\n",
       "      <td>4686.000000</td>\n",
       "      <td>4686.000000</td>\n",
       "      <td>4.686000e+03</td>\n",
       "      <td>4686.000000</td>\n",
       "      <td>4686.000000</td>\n",
       "      <td>4686.000000</td>\n",
       "      <td>4686.000000</td>\n",
       "      <td>4.686000e+03</td>\n",
       "      <td>4686.000000</td>\n",
       "      <td>4686.000000</td>\n",
       "      <td>4686.000000</td>\n",
       "      <td>4686.000000</td>\n",
       "      <td>4686.000000</td>\n",
       "      <td>4686.000000</td>\n",
       "      <td>4686.000000</td>\n",
       "      <td>4686.000000</td>\n",
       "      <td>4.686000e+03</td>\n",
       "      <td>4686.000000</td>\n",
       "      <td>4686.000000</td>\n",
       "      <td>4686.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>678.266931</td>\n",
       "      <td>0.204640</td>\n",
       "      <td>0.457589</td>\n",
       "      <td>13.972317</td>\n",
       "      <td>50300.339848</td>\n",
       "      <td>0.256824</td>\n",
       "      <td>138.198644</td>\n",
       "      <td>4.996332e+07</td>\n",
       "      <td>28.303884</td>\n",
       "      <td>3.516219</td>\n",
       "      <td>0.082329</td>\n",
       "      <td>5056.151088</td>\n",
       "      <td>2.457724e+06</td>\n",
       "      <td>0.382601</td>\n",
       "      <td>1.400278</td>\n",
       "      <td>13.374256</td>\n",
       "      <td>172.156059</td>\n",
       "      <td>635.597761</td>\n",
       "      <td>0.813338</td>\n",
       "      <td>183.967256</td>\n",
       "      <td>1.987218</td>\n",
       "      <td>2.457728e+06</td>\n",
       "      <td>181.151697</td>\n",
       "      <td>0.738263</td>\n",
       "      <td>0.161118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3937.393092</td>\n",
       "      <td>0.369605</td>\n",
       "      <td>0.826461</td>\n",
       "      <td>7.293272</td>\n",
       "      <td>26255.780837</td>\n",
       "      <td>0.145779</td>\n",
       "      <td>2623.164517</td>\n",
       "      <td>1.310882e+08</td>\n",
       "      <td>38.303103</td>\n",
       "      <td>3.078214</td>\n",
       "      <td>0.090307</td>\n",
       "      <td>1237.947507</td>\n",
       "      <td>9.203868e+02</td>\n",
       "      <td>0.180450</td>\n",
       "      <td>0.524209</td>\n",
       "      <td>10.937357</td>\n",
       "      <td>103.287765</td>\n",
       "      <td>370.992760</td>\n",
       "      <td>0.242065</td>\n",
       "      <td>103.496175</td>\n",
       "      <td>0.951608</td>\n",
       "      <td>9.443060e+02</td>\n",
       "      <td>107.507352</td>\n",
       "      <td>0.342661</td>\n",
       "      <td>0.367679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-26.100000</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.002260</td>\n",
       "      <td>0.335504</td>\n",
       "      <td>1207.814804</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.069194</td>\n",
       "      <td>2.660989e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2196.000000</td>\n",
       "      <td>2.450164e+06</td>\n",
       "      <td>0.007522</td>\n",
       "      <td>0.615920</td>\n",
       "      <td>0.014513</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>176.557161</td>\n",
       "      <td>0.080744</td>\n",
       "      <td>0.006918</td>\n",
       "      <td>0.803765</td>\n",
       "      <td>2.450100e+06</td>\n",
       "      <td>0.003191</td>\n",
       "      <td>0.086285</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.100000</td>\n",
       "      <td>0.033462</td>\n",
       "      <td>0.074824</td>\n",
       "      <td>8.437212</td>\n",
       "      <td>30373.963274</td>\n",
       "      <td>0.133440</td>\n",
       "      <td>51.908257</td>\n",
       "      <td>2.063112e+07</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014585</td>\n",
       "      <td>4049.250000</td>\n",
       "      <td>2.458000e+06</td>\n",
       "      <td>0.240935</td>\n",
       "      <td>1.000635</td>\n",
       "      <td>4.961828</td>\n",
       "      <td>83.081111</td>\n",
       "      <td>365.605031</td>\n",
       "      <td>0.630834</td>\n",
       "      <td>95.633231</td>\n",
       "      <td>1.266059</td>\n",
       "      <td>2.457815e+06</td>\n",
       "      <td>86.997048</td>\n",
       "      <td>0.453263</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.110804</td>\n",
       "      <td>0.247765</td>\n",
       "      <td>12.921682</td>\n",
       "      <td>46518.055335</td>\n",
       "      <td>0.265155</td>\n",
       "      <td>103.145134</td>\n",
       "      <td>4.029665e+07</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.047379</td>\n",
       "      <td>5071.000000</td>\n",
       "      <td>2.458000e+06</td>\n",
       "      <td>0.372513</td>\n",
       "      <td>1.240929</td>\n",
       "      <td>10.304912</td>\n",
       "      <td>172.625393</td>\n",
       "      <td>504.915377</td>\n",
       "      <td>0.833104</td>\n",
       "      <td>189.767263</td>\n",
       "      <td>1.618175</td>\n",
       "      <td>2.457973e+06</td>\n",
       "      <td>185.435988</td>\n",
       "      <td>0.712991</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24.600000</td>\n",
       "      <td>0.253837</td>\n",
       "      <td>0.567597</td>\n",
       "      <td>18.077871</td>\n",
       "      <td>65080.334830</td>\n",
       "      <td>0.384159</td>\n",
       "      <td>149.437649</td>\n",
       "      <td>5.811893e+07</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.123609</td>\n",
       "      <td>6019.000000</td>\n",
       "      <td>2.458000e+06</td>\n",
       "      <td>0.512437</td>\n",
       "      <td>1.678427</td>\n",
       "      <td>19.515849</td>\n",
       "      <td>255.100144</td>\n",
       "      <td>794.240628</td>\n",
       "      <td>0.997175</td>\n",
       "      <td>271.794410</td>\n",
       "      <td>2.451763</td>\n",
       "      <td>2.458108e+06</td>\n",
       "      <td>276.531946</td>\n",
       "      <td>0.984669</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>29345.000000</td>\n",
       "      <td>15.579552</td>\n",
       "      <td>34.836938</td>\n",
       "      <td>44.633747</td>\n",
       "      <td>160681.487851</td>\n",
       "      <td>0.499884</td>\n",
       "      <td>179625.000000</td>\n",
       "      <td>2.079439e+09</td>\n",
       "      <td>611.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.477891</td>\n",
       "      <td>9025.000000</td>\n",
       "      <td>2.458020e+06</td>\n",
       "      <td>0.960261</td>\n",
       "      <td>5.072008</td>\n",
       "      <td>75.406667</td>\n",
       "      <td>359.905890</td>\n",
       "      <td>4172.231343</td>\n",
       "      <td>1.299832</td>\n",
       "      <td>359.993098</td>\n",
       "      <td>8.983852</td>\n",
       "      <td>2.458839e+06</td>\n",
       "      <td>359.917991</td>\n",
       "      <td>2.039000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Absolute Magnitude  Est Dia in KM(min)  Est Dia in KM(max)  \\\n",
       "count         4686.000000         4686.000000         4686.000000   \n",
       "mean           678.266931            0.204640            0.457589   \n",
       "std           3937.393092            0.369605            0.826461   \n",
       "min            -26.100000            0.001011            0.002260   \n",
       "25%             20.100000            0.033462            0.074824   \n",
       "50%             22.000000            0.110804            0.247765   \n",
       "75%             24.600000            0.253837            0.567597   \n",
       "max          29345.000000           15.579552           34.836938   \n",
       "\n",
       "       Relative Velocity km per sec  Relative Velocity km per hr  \\\n",
       "count                   4686.000000                  4686.000000   \n",
       "mean                      13.972317                 50300.339848   \n",
       "std                        7.293272                 26255.780837   \n",
       "min                        0.335504                  1207.814804   \n",
       "25%                        8.437212                 30373.963274   \n",
       "50%                       12.921682                 46518.055335   \n",
       "75%                       18.077871                 65080.334830   \n",
       "max                       44.633747                160681.487851   \n",
       "\n",
       "       Miss Dist.(Astronomical)  Miss Dist.(lunar)  Miss Dist.(kilometers)  \\\n",
       "count               4686.000000        4686.000000            4.686000e+03   \n",
       "mean                   0.256824         138.198644            4.996332e+07   \n",
       "std                    0.145779        2623.164517            1.310882e+08   \n",
       "min                    0.000178           0.069194            2.660989e+04   \n",
       "25%                    0.133440          51.908257            2.063112e+07   \n",
       "50%                    0.265155         103.145134            4.029665e+07   \n",
       "75%                    0.384159         149.437649            5.811893e+07   \n",
       "max                    0.499884      179625.000000            2.079439e+09   \n",
       "\n",
       "          Orbit ID  Orbit Uncertainity  Minimum Orbit Intersection  \\\n",
       "count  4686.000000         4686.000000                 4686.000000   \n",
       "mean     28.303884            3.516219                    0.082329   \n",
       "std      38.303103            3.078214                    0.090307   \n",
       "min       1.000000            0.000000                    0.000002   \n",
       "25%       9.000000            0.000000                    0.014585   \n",
       "50%      16.000000            3.000000                    0.047379   \n",
       "75%      31.000000            6.000000                    0.123609   \n",
       "max     611.000000            9.000000                    0.477891   \n",
       "\n",
       "       Jupiter Tisserand Invariant  Epoch Osculation  Eccentricity  \\\n",
       "count                  4686.000000      4.686000e+03   4686.000000   \n",
       "mean                   5056.151088      2.457724e+06      0.382601   \n",
       "std                    1237.947507      9.203868e+02      0.180450   \n",
       "min                    2196.000000      2.450164e+06      0.007522   \n",
       "25%                    4049.250000      2.458000e+06      0.240935   \n",
       "50%                    5071.000000      2.458000e+06      0.372513   \n",
       "75%                    6019.000000      2.458000e+06      0.512437   \n",
       "max                    9025.000000      2.458020e+06      0.960261   \n",
       "\n",
       "       Semi Major Axis  Inclination  Asc Node Longitude  Orbital Period  \\\n",
       "count      4686.000000  4686.000000         4686.000000     4686.000000   \n",
       "mean          1.400278    13.374256          172.156059      635.597761   \n",
       "std           0.524209    10.937357          103.287765      370.992760   \n",
       "min           0.615920     0.014513            0.001941      176.557161   \n",
       "25%           1.000635     4.961828           83.081111      365.605031   \n",
       "50%           1.240929    10.304912          172.625393      504.915377   \n",
       "75%           1.678427    19.515849          255.100144      794.240628   \n",
       "max           5.072008    75.406667          359.905890     4172.231343   \n",
       "\n",
       "       Perihelion Distance  Perihelion Arg  Aphelion Dist  Perihelion Time  \\\n",
       "count          4686.000000     4686.000000    4686.000000     4.686000e+03   \n",
       "mean              0.813338      183.967256       1.987218     2.457728e+06   \n",
       "std               0.242065      103.496175       0.951608     9.443060e+02   \n",
       "min               0.080744        0.006918       0.803765     2.450100e+06   \n",
       "25%               0.630834       95.633231       1.266059     2.457815e+06   \n",
       "50%               0.833104      189.767263       1.618175     2.457973e+06   \n",
       "75%               0.997175      271.794410       2.451763     2.458108e+06   \n",
       "max               1.299832      359.993098       8.983852     2.458839e+06   \n",
       "\n",
       "       Mean Anomaly  Mean Motion    Hazardous  \n",
       "count   4686.000000  4686.000000  4686.000000  \n",
       "mean     181.151697     0.738263     0.161118  \n",
       "std      107.507352     0.342661     0.367679  \n",
       "min        0.003191     0.086285     0.000000  \n",
       "25%       86.997048     0.453263     0.000000  \n",
       "50%      185.435988     0.712991     0.000000  \n",
       "75%      276.531946     0.984669     0.000000  \n",
       "max      359.917991     2.039000     1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Absolute Magnitude</th>\n",
       "      <th>Est Dia in KM(min)</th>\n",
       "      <th>Est Dia in KM(max)</th>\n",
       "      <th>Relative Velocity km per sec</th>\n",
       "      <th>Relative Velocity km per hr</th>\n",
       "      <th>Miss Dist.(Astronomical)</th>\n",
       "      <th>Miss Dist.(lunar)</th>\n",
       "      <th>Miss Dist.(kilometers)</th>\n",
       "      <th>Orbit ID</th>\n",
       "      <th>Orbit Uncertainity</th>\n",
       "      <th>Minimum Orbit Intersection</th>\n",
       "      <th>Jupiter Tisserand Invariant</th>\n",
       "      <th>Epoch Osculation</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>Semi Major Axis</th>\n",
       "      <th>Inclination</th>\n",
       "      <th>Asc Node Longitude</th>\n",
       "      <th>Orbital Period</th>\n",
       "      <th>Perihelion Distance</th>\n",
       "      <th>Perihelion Arg</th>\n",
       "      <th>Aphelion Dist</th>\n",
       "      <th>Perihelion Time</th>\n",
       "      <th>Mean Anomaly</th>\n",
       "      <th>Mean Motion</th>\n",
       "      <th>Hazardous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4457.000000</td>\n",
       "      <td>4457.000000</td>\n",
       "      <td>4457.000000</td>\n",
       "      <td>4457.000000</td>\n",
       "      <td>4457.000000</td>\n",
       "      <td>4457.000000</td>\n",
       "      <td>4457.000000</td>\n",
       "      <td>4.457000e+03</td>\n",
       "      <td>4457.000000</td>\n",
       "      <td>4457.000000</td>\n",
       "      <td>4457.000000</td>\n",
       "      <td>4457.000000</td>\n",
       "      <td>4.457000e+03</td>\n",
       "      <td>4457.000000</td>\n",
       "      <td>4457.000000</td>\n",
       "      <td>4457.000000</td>\n",
       "      <td>4457.000000</td>\n",
       "      <td>4457.000000</td>\n",
       "      <td>4457.000000</td>\n",
       "      <td>4457.000000</td>\n",
       "      <td>4457.000000</td>\n",
       "      <td>4.457000e+03</td>\n",
       "      <td>4457.000000</td>\n",
       "      <td>4457.000000</td>\n",
       "      <td>4457.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>74.524669</td>\n",
       "      <td>0.193533</td>\n",
       "      <td>0.432752</td>\n",
       "      <td>14.007638</td>\n",
       "      <td>50427.496694</td>\n",
       "      <td>0.259454</td>\n",
       "      <td>100.927417</td>\n",
       "      <td>3.913578e+07</td>\n",
       "      <td>26.892753</td>\n",
       "      <td>3.431456</td>\n",
       "      <td>0.083663</td>\n",
       "      <td>5055.295266</td>\n",
       "      <td>2.457769e+06</td>\n",
       "      <td>0.382434</td>\n",
       "      <td>1.399211</td>\n",
       "      <td>13.475930</td>\n",
       "      <td>172.167655</td>\n",
       "      <td>634.408384</td>\n",
       "      <td>0.813794</td>\n",
       "      <td>183.969744</td>\n",
       "      <td>1.984629</td>\n",
       "      <td>2.457774e+06</td>\n",
       "      <td>182.247986</td>\n",
       "      <td>0.738006</td>\n",
       "      <td>0.164460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1007.592288</td>\n",
       "      <td>0.240460</td>\n",
       "      <td>0.537685</td>\n",
       "      <td>7.293929</td>\n",
       "      <td>26258.142914</td>\n",
       "      <td>0.144650</td>\n",
       "      <td>56.268857</td>\n",
       "      <td>2.447158e+07</td>\n",
       "      <td>29.348372</td>\n",
       "      <td>3.059747</td>\n",
       "      <td>0.090652</td>\n",
       "      <td>1235.274308</td>\n",
       "      <td>7.687103e+02</td>\n",
       "      <td>0.180427</td>\n",
       "      <td>0.518951</td>\n",
       "      <td>10.925665</td>\n",
       "      <td>103.282188</td>\n",
       "      <td>364.581600</td>\n",
       "      <td>0.243057</td>\n",
       "      <td>103.407024</td>\n",
       "      <td>0.940348</td>\n",
       "      <td>7.974917e+02</td>\n",
       "      <td>107.066958</td>\n",
       "      <td>0.342302</td>\n",
       "      <td>0.370734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-26.100000</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.002260</td>\n",
       "      <td>0.335504</td>\n",
       "      <td>1207.814804</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.069194</td>\n",
       "      <td>2.660989e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2196.000000</td>\n",
       "      <td>2.453140e+06</td>\n",
       "      <td>0.007522</td>\n",
       "      <td>0.615920</td>\n",
       "      <td>0.014513</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>176.557161</td>\n",
       "      <td>0.080744</td>\n",
       "      <td>0.006918</td>\n",
       "      <td>0.803765</td>\n",
       "      <td>2.453089e+06</td>\n",
       "      <td>0.003191</td>\n",
       "      <td>0.160096</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.100000</td>\n",
       "      <td>0.035039</td>\n",
       "      <td>0.078350</td>\n",
       "      <td>8.468191</td>\n",
       "      <td>30485.488153</td>\n",
       "      <td>0.137115</td>\n",
       "      <td>53.337914</td>\n",
       "      <td>2.059791e+07</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015609</td>\n",
       "      <td>4046.000000</td>\n",
       "      <td>2.458000e+06</td>\n",
       "      <td>0.240375</td>\n",
       "      <td>1.001280</td>\n",
       "      <td>5.035044</td>\n",
       "      <td>82.672140</td>\n",
       "      <td>365.958345</td>\n",
       "      <td>0.630305</td>\n",
       "      <td>96.256273</td>\n",
       "      <td>1.266862</td>\n",
       "      <td>2.457819e+06</td>\n",
       "      <td>88.451929</td>\n",
       "      <td>0.452172</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21.800000</td>\n",
       "      <td>0.116026</td>\n",
       "      <td>0.259442</td>\n",
       "      <td>13.005597</td>\n",
       "      <td>46820.148017</td>\n",
       "      <td>0.268401</td>\n",
       "      <td>104.408188</td>\n",
       "      <td>4.018810e+07</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.048679</td>\n",
       "      <td>5075.000000</td>\n",
       "      <td>2.458000e+06</td>\n",
       "      <td>0.372837</td>\n",
       "      <td>1.240195</td>\n",
       "      <td>10.427723</td>\n",
       "      <td>171.715314</td>\n",
       "      <td>504.467747</td>\n",
       "      <td>0.833861</td>\n",
       "      <td>189.385574</td>\n",
       "      <td>1.618195</td>\n",
       "      <td>2.457977e+06</td>\n",
       "      <td>186.864212</td>\n",
       "      <td>0.713623</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24.400000</td>\n",
       "      <td>0.253837</td>\n",
       "      <td>0.567597</td>\n",
       "      <td>18.135814</td>\n",
       "      <td>65288.930834</td>\n",
       "      <td>0.385801</td>\n",
       "      <td>150.076630</td>\n",
       "      <td>5.776776e+07</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.125694</td>\n",
       "      <td>6008.000000</td>\n",
       "      <td>2.458000e+06</td>\n",
       "      <td>0.512357</td>\n",
       "      <td>1.681127</td>\n",
       "      <td>19.765560</td>\n",
       "      <td>255.173379</td>\n",
       "      <td>796.158072</td>\n",
       "      <td>0.998453</td>\n",
       "      <td>271.811263</td>\n",
       "      <td>2.461334</td>\n",
       "      <td>2.458110e+06</td>\n",
       "      <td>276.531946</td>\n",
       "      <td>0.983719</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20224.000000</td>\n",
       "      <td>2.016299</td>\n",
       "      <td>4.508582</td>\n",
       "      <td>44.633747</td>\n",
       "      <td>160681.487851</td>\n",
       "      <td>0.499884</td>\n",
       "      <td>194.454910</td>\n",
       "      <td>5.333644e+08</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.477891</td>\n",
       "      <td>9025.000000</td>\n",
       "      <td>2.458000e+06</td>\n",
       "      <td>0.960261</td>\n",
       "      <td>3.359049</td>\n",
       "      <td>67.310143</td>\n",
       "      <td>359.905890</td>\n",
       "      <td>2248.655832</td>\n",
       "      <td>1.299832</td>\n",
       "      <td>359.993098</td>\n",
       "      <td>5.924213</td>\n",
       "      <td>2.458839e+06</td>\n",
       "      <td>359.917991</td>\n",
       "      <td>2.039000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Absolute Magnitude  Est Dia in KM(min)  Est Dia in KM(max)  \\\n",
       "count         4457.000000         4457.000000         4457.000000   \n",
       "mean            74.524669            0.193533            0.432752   \n",
       "std           1007.592288            0.240460            0.537685   \n",
       "min            -26.100000            0.001011            0.002260   \n",
       "25%             20.100000            0.035039            0.078350   \n",
       "50%             21.800000            0.116026            0.259442   \n",
       "75%             24.400000            0.253837            0.567597   \n",
       "max          20224.000000            2.016299            4.508582   \n",
       "\n",
       "       Relative Velocity km per sec  Relative Velocity km per hr  \\\n",
       "count                   4457.000000                  4457.000000   \n",
       "mean                      14.007638                 50427.496694   \n",
       "std                        7.293929                 26258.142914   \n",
       "min                        0.335504                  1207.814804   \n",
       "25%                        8.468191                 30485.488153   \n",
       "50%                       13.005597                 46820.148017   \n",
       "75%                       18.135814                 65288.930834   \n",
       "max                       44.633747                160681.487851   \n",
       "\n",
       "       Miss Dist.(Astronomical)  Miss Dist.(lunar)  Miss Dist.(kilometers)  \\\n",
       "count               4457.000000        4457.000000            4.457000e+03   \n",
       "mean                   0.259454         100.927417            3.913578e+07   \n",
       "std                    0.144650          56.268857            2.447158e+07   \n",
       "min                    0.000178           0.069194            2.660989e+04   \n",
       "25%                    0.137115          53.337914            2.059791e+07   \n",
       "50%                    0.268401         104.408188            4.018810e+07   \n",
       "75%                    0.385801         150.076630            5.776776e+07   \n",
       "max                    0.499884         194.454910            5.333644e+08   \n",
       "\n",
       "          Orbit ID  Orbit Uncertainity  Minimum Orbit Intersection  \\\n",
       "count  4457.000000         4457.000000                 4457.000000   \n",
       "mean     26.892753            3.431456                    0.083663   \n",
       "std      29.348372            3.059747                    0.090652   \n",
       "min       1.000000            0.000000                    0.000002   \n",
       "25%      10.000000            0.000000                    0.015609   \n",
       "50%      17.000000            3.000000                    0.048679   \n",
       "75%      32.000000            6.000000                    0.125694   \n",
       "max     214.000000            9.000000                    0.477891   \n",
       "\n",
       "       Jupiter Tisserand Invariant  Epoch Osculation  Eccentricity  \\\n",
       "count                  4457.000000      4.457000e+03   4457.000000   \n",
       "mean                   5055.295266      2.457769e+06      0.382434   \n",
       "std                    1235.274308      7.687103e+02      0.180427   \n",
       "min                    2196.000000      2.453140e+06      0.007522   \n",
       "25%                    4046.000000      2.458000e+06      0.240375   \n",
       "50%                    5075.000000      2.458000e+06      0.372837   \n",
       "75%                    6008.000000      2.458000e+06      0.512357   \n",
       "max                    9025.000000      2.458000e+06      0.960261   \n",
       "\n",
       "       Semi Major Axis  Inclination  Asc Node Longitude  Orbital Period  \\\n",
       "count      4457.000000  4457.000000         4457.000000     4457.000000   \n",
       "mean          1.399211    13.475930          172.167655      634.408384   \n",
       "std           0.518951    10.925665          103.282188      364.581600   \n",
       "min           0.615920     0.014513            0.001941      176.557161   \n",
       "25%           1.001280     5.035044           82.672140      365.958345   \n",
       "50%           1.240195    10.427723          171.715314      504.467747   \n",
       "75%           1.681127    19.765560          255.173379      796.158072   \n",
       "max           3.359049    67.310143          359.905890     2248.655832   \n",
       "\n",
       "       Perihelion Distance  Perihelion Arg  Aphelion Dist  Perihelion Time  \\\n",
       "count          4457.000000     4457.000000    4457.000000     4.457000e+03   \n",
       "mean              0.813794      183.969744       1.984629     2.457774e+06   \n",
       "std               0.243057      103.407024       0.940348     7.974917e+02   \n",
       "min               0.080744        0.006918       0.803765     2.453089e+06   \n",
       "25%               0.630305       96.256273       1.266862     2.457819e+06   \n",
       "50%               0.833861      189.385574       1.618195     2.457977e+06   \n",
       "75%               0.998453      271.811263       2.461334     2.458110e+06   \n",
       "max               1.299832      359.993098       5.924213     2.458839e+06   \n",
       "\n",
       "       Mean Anomaly  Mean Motion    Hazardous  \n",
       "count   4457.000000  4457.000000  4457.000000  \n",
       "mean     182.247986     0.738006     0.164460  \n",
       "std      107.066958     0.342302     0.370734  \n",
       "min        0.003191     0.160096     0.000000  \n",
       "25%       88.451929     0.452172     0.000000  \n",
       "50%      186.864212     0.713623     0.000000  \n",
       "75%      276.531946     0.983719     0.000000  \n",
       "max      359.917991     2.039000     1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# outliers\n",
    "from scipy import stats\n",
    "dataset = dataset[(np.abs(stats.zscore(dataset)) < 5).all(axis=1)]\n",
    "\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding van de categorische features\n",
    "\n",
    "De feature 'Orbit ID' bevat categorische (niet-numerieke) variabelen. Daarom zetten we die om naar one-hot encoded vectoren.\n",
    "Dit kan in Pandas via de functie get_dummies.\n",
    "Op deze manier worden extra features gecreÃ«erd gelijk aan het aantal categorieÃ«n en worden deze aan het eind van de featureset toegevoegd. Vervolgens verwijderen we de originele feature kolom.\n",
    "Check of er nog categorische features aanwezig zijn en zet ze om naar one-hot encoded vectoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Absolute Magnitude</th>\n",
       "      <th>Est Dia in KM(min)</th>\n",
       "      <th>Est Dia in KM(max)</th>\n",
       "      <th>Relative Velocity km per sec</th>\n",
       "      <th>Relative Velocity km per hr</th>\n",
       "      <th>Miss Dist.(Astronomical)</th>\n",
       "      <th>Miss Dist.(lunar)</th>\n",
       "      <th>Miss Dist.(kilometers)</th>\n",
       "      <th>Orbit Uncertainity</th>\n",
       "      <th>Minimum Orbit Intersection</th>\n",
       "      <th>Jupiter Tisserand Invariant</th>\n",
       "      <th>Epoch Osculation</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>Semi Major Axis</th>\n",
       "      <th>Inclination</th>\n",
       "      <th>Asc Node Longitude</th>\n",
       "      <th>Orbital Period</th>\n",
       "      <th>Perihelion Distance</th>\n",
       "      <th>Perihelion Arg</th>\n",
       "      <th>Aphelion Dist</th>\n",
       "      <th>Perihelion Time</th>\n",
       "      <th>Mean Anomaly</th>\n",
       "      <th>Mean Motion</th>\n",
       "      <th>Hazardous</th>\n",
       "      <th>Orbit_ID_1</th>\n",
       "      <th>Orbit_ID_2</th>\n",
       "      <th>Orbit_ID_3</th>\n",
       "      <th>Orbit_ID_4</th>\n",
       "      <th>Orbit_ID_5</th>\n",
       "      <th>Orbit_ID_6</th>\n",
       "      <th>Orbit_ID_7</th>\n",
       "      <th>Orbit_ID_8</th>\n",
       "      <th>Orbit_ID_9</th>\n",
       "      <th>Orbit_ID_10</th>\n",
       "      <th>Orbit_ID_11</th>\n",
       "      <th>Orbit_ID_12</th>\n",
       "      <th>Orbit_ID_13</th>\n",
       "      <th>Orbit_ID_14</th>\n",
       "      <th>Orbit_ID_15</th>\n",
       "      <th>Orbit_ID_16</th>\n",
       "      <th>Orbit_ID_17</th>\n",
       "      <th>Orbit_ID_18</th>\n",
       "      <th>Orbit_ID_19</th>\n",
       "      <th>Orbit_ID_20</th>\n",
       "      <th>Orbit_ID_21</th>\n",
       "      <th>Orbit_ID_22</th>\n",
       "      <th>Orbit_ID_23</th>\n",
       "      <th>Orbit_ID_24</th>\n",
       "      <th>Orbit_ID_25</th>\n",
       "      <th>Orbit_ID_26</th>\n",
       "      <th>Orbit_ID_27</th>\n",
       "      <th>Orbit_ID_28</th>\n",
       "      <th>Orbit_ID_29</th>\n",
       "      <th>Orbit_ID_30</th>\n",
       "      <th>Orbit_ID_31</th>\n",
       "      <th>Orbit_ID_32</th>\n",
       "      <th>Orbit_ID_33</th>\n",
       "      <th>Orbit_ID_34</th>\n",
       "      <th>Orbit_ID_35</th>\n",
       "      <th>Orbit_ID_36</th>\n",
       "      <th>Orbit_ID_37</th>\n",
       "      <th>Orbit_ID_38</th>\n",
       "      <th>Orbit_ID_39</th>\n",
       "      <th>Orbit_ID_40</th>\n",
       "      <th>Orbit_ID_41</th>\n",
       "      <th>Orbit_ID_42</th>\n",
       "      <th>Orbit_ID_43</th>\n",
       "      <th>Orbit_ID_44</th>\n",
       "      <th>Orbit_ID_45</th>\n",
       "      <th>Orbit_ID_46</th>\n",
       "      <th>Orbit_ID_47</th>\n",
       "      <th>Orbit_ID_48</th>\n",
       "      <th>Orbit_ID_49</th>\n",
       "      <th>Orbit_ID_50</th>\n",
       "      <th>Orbit_ID_51</th>\n",
       "      <th>Orbit_ID_52</th>\n",
       "      <th>Orbit_ID_53</th>\n",
       "      <th>Orbit_ID_54</th>\n",
       "      <th>Orbit_ID_55</th>\n",
       "      <th>Orbit_ID_56</th>\n",
       "      <th>Orbit_ID_57</th>\n",
       "      <th>Orbit_ID_58</th>\n",
       "      <th>Orbit_ID_59</th>\n",
       "      <th>Orbit_ID_60</th>\n",
       "      <th>Orbit_ID_61</th>\n",
       "      <th>Orbit_ID_62</th>\n",
       "      <th>Orbit_ID_63</th>\n",
       "      <th>Orbit_ID_64</th>\n",
       "      <th>Orbit_ID_65</th>\n",
       "      <th>Orbit_ID_66</th>\n",
       "      <th>Orbit_ID_67</th>\n",
       "      <th>Orbit_ID_68</th>\n",
       "      <th>Orbit_ID_69</th>\n",
       "      <th>Orbit_ID_70</th>\n",
       "      <th>Orbit_ID_71</th>\n",
       "      <th>Orbit_ID_72</th>\n",
       "      <th>Orbit_ID_73</th>\n",
       "      <th>Orbit_ID_74</th>\n",
       "      <th>Orbit_ID_75</th>\n",
       "      <th>Orbit_ID_76</th>\n",
       "      <th>Orbit_ID_77</th>\n",
       "      <th>Orbit_ID_78</th>\n",
       "      <th>Orbit_ID_79</th>\n",
       "      <th>Orbit_ID_80</th>\n",
       "      <th>Orbit_ID_81</th>\n",
       "      <th>Orbit_ID_82</th>\n",
       "      <th>Orbit_ID_83</th>\n",
       "      <th>Orbit_ID_84</th>\n",
       "      <th>Orbit_ID_85</th>\n",
       "      <th>Orbit_ID_86</th>\n",
       "      <th>Orbit_ID_87</th>\n",
       "      <th>Orbit_ID_88</th>\n",
       "      <th>Orbit_ID_89</th>\n",
       "      <th>Orbit_ID_90</th>\n",
       "      <th>Orbit_ID_91</th>\n",
       "      <th>Orbit_ID_92</th>\n",
       "      <th>Orbit_ID_93</th>\n",
       "      <th>Orbit_ID_94</th>\n",
       "      <th>Orbit_ID_95</th>\n",
       "      <th>Orbit_ID_96</th>\n",
       "      <th>Orbit_ID_97</th>\n",
       "      <th>Orbit_ID_98</th>\n",
       "      <th>Orbit_ID_99</th>\n",
       "      <th>Orbit_ID_100</th>\n",
       "      <th>Orbit_ID_101</th>\n",
       "      <th>Orbit_ID_102</th>\n",
       "      <th>Orbit_ID_103</th>\n",
       "      <th>Orbit_ID_104</th>\n",
       "      <th>Orbit_ID_105</th>\n",
       "      <th>Orbit_ID_106</th>\n",
       "      <th>Orbit_ID_107</th>\n",
       "      <th>Orbit_ID_108</th>\n",
       "      <th>Orbit_ID_109</th>\n",
       "      <th>Orbit_ID_111</th>\n",
       "      <th>Orbit_ID_112</th>\n",
       "      <th>Orbit_ID_113</th>\n",
       "      <th>Orbit_ID_114</th>\n",
       "      <th>Orbit_ID_115</th>\n",
       "      <th>Orbit_ID_116</th>\n",
       "      <th>Orbit_ID_117</th>\n",
       "      <th>Orbit_ID_119</th>\n",
       "      <th>Orbit_ID_120</th>\n",
       "      <th>Orbit_ID_121</th>\n",
       "      <th>Orbit_ID_122</th>\n",
       "      <th>Orbit_ID_123</th>\n",
       "      <th>Orbit_ID_125</th>\n",
       "      <th>Orbit_ID_126</th>\n",
       "      <th>Orbit_ID_128</th>\n",
       "      <th>Orbit_ID_130</th>\n",
       "      <th>Orbit_ID_131</th>\n",
       "      <th>Orbit_ID_132</th>\n",
       "      <th>Orbit_ID_133</th>\n",
       "      <th>Orbit_ID_134</th>\n",
       "      <th>Orbit_ID_137</th>\n",
       "      <th>Orbit_ID_138</th>\n",
       "      <th>Orbit_ID_140</th>\n",
       "      <th>Orbit_ID_143</th>\n",
       "      <th>Orbit_ID_146</th>\n",
       "      <th>Orbit_ID_147</th>\n",
       "      <th>Orbit_ID_148</th>\n",
       "      <th>Orbit_ID_149</th>\n",
       "      <th>Orbit_ID_152</th>\n",
       "      <th>Orbit_ID_154</th>\n",
       "      <th>Orbit_ID_156</th>\n",
       "      <th>Orbit_ID_157</th>\n",
       "      <th>Orbit_ID_158</th>\n",
       "      <th>Orbit_ID_159</th>\n",
       "      <th>Orbit_ID_163</th>\n",
       "      <th>Orbit_ID_164</th>\n",
       "      <th>Orbit_ID_165</th>\n",
       "      <th>Orbit_ID_167</th>\n",
       "      <th>Orbit_ID_170</th>\n",
       "      <th>Orbit_ID_172</th>\n",
       "      <th>Orbit_ID_175</th>\n",
       "      <th>Orbit_ID_176</th>\n",
       "      <th>Orbit_ID_182</th>\n",
       "      <th>Orbit_ID_184</th>\n",
       "      <th>Orbit_ID_185</th>\n",
       "      <th>Orbit_ID_190</th>\n",
       "      <th>Orbit_ID_192</th>\n",
       "      <th>Orbit_ID_193</th>\n",
       "      <th>Orbit_ID_207</th>\n",
       "      <th>Orbit_ID_211</th>\n",
       "      <th>Orbit_ID_212</th>\n",
       "      <th>Orbit_ID_213</th>\n",
       "      <th>Orbit_ID_214</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.6</td>\n",
       "      <td>0.127220</td>\n",
       "      <td>0.284472</td>\n",
       "      <td>6.115834</td>\n",
       "      <td>22017.003799</td>\n",
       "      <td>0.419483</td>\n",
       "      <td>163.178711</td>\n",
       "      <td>62753692.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.025282</td>\n",
       "      <td>4634</td>\n",
       "      <td>2458000.5</td>\n",
       "      <td>0.425549</td>\n",
       "      <td>1.407011</td>\n",
       "      <td>6.025981</td>\n",
       "      <td>314.373913</td>\n",
       "      <td>609.599786</td>\n",
       "      <td>0.808259</td>\n",
       "      <td>57.257470</td>\n",
       "      <td>2.005764</td>\n",
       "      <td>2.458162e+06</td>\n",
       "      <td>264.837533</td>\n",
       "      <td>0.590551</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.3</td>\n",
       "      <td>0.146068</td>\n",
       "      <td>0.326618</td>\n",
       "      <td>18.113985</td>\n",
       "      <td>65210.346095</td>\n",
       "      <td>0.383014</td>\n",
       "      <td>148.992630</td>\n",
       "      <td>57298148.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.186935</td>\n",
       "      <td>5457</td>\n",
       "      <td>2458000.5</td>\n",
       "      <td>0.351674</td>\n",
       "      <td>1.107776</td>\n",
       "      <td>28.412996</td>\n",
       "      <td>136.717242</td>\n",
       "      <td>425.869294</td>\n",
       "      <td>0.718200</td>\n",
       "      <td>313.091975</td>\n",
       "      <td>1.497352</td>\n",
       "      <td>2.457795e+06</td>\n",
       "      <td>173.741112</td>\n",
       "      <td>0.845330</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.3</td>\n",
       "      <td>0.231502</td>\n",
       "      <td>0.517654</td>\n",
       "      <td>7.590711</td>\n",
       "      <td>27326.560182</td>\n",
       "      <td>0.050956</td>\n",
       "      <td>19.821890</td>\n",
       "      <td>7622911.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043058</td>\n",
       "      <td>4557</td>\n",
       "      <td>2458000.5</td>\n",
       "      <td>0.348248</td>\n",
       "      <td>1.458824</td>\n",
       "      <td>4.237961</td>\n",
       "      <td>259.475979</td>\n",
       "      <td>643.580228</td>\n",
       "      <td>0.950791</td>\n",
       "      <td>248.415038</td>\n",
       "      <td>1.966857</td>\n",
       "      <td>2.458120e+06</td>\n",
       "      <td>292.893654</td>\n",
       "      <td>0.559371</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.4</td>\n",
       "      <td>0.008801</td>\n",
       "      <td>0.019681</td>\n",
       "      <td>11.173874</td>\n",
       "      <td>40225.948191</td>\n",
       "      <td>0.285322</td>\n",
       "      <td>110.990387</td>\n",
       "      <td>42683616.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.005512</td>\n",
       "      <td>5093</td>\n",
       "      <td>2458000.5</td>\n",
       "      <td>0.216578</td>\n",
       "      <td>1.255903</td>\n",
       "      <td>7.905894</td>\n",
       "      <td>57.173266</td>\n",
       "      <td>514.082140</td>\n",
       "      <td>0.983902</td>\n",
       "      <td>18.707701</td>\n",
       "      <td>1.527904</td>\n",
       "      <td>2.457902e+06</td>\n",
       "      <td>68.741007</td>\n",
       "      <td>0.700277</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.6</td>\n",
       "      <td>0.127220</td>\n",
       "      <td>0.284472</td>\n",
       "      <td>9.840831</td>\n",
       "      <td>35426.991794</td>\n",
       "      <td>0.407832</td>\n",
       "      <td>158.646713</td>\n",
       "      <td>61010824.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.034798</td>\n",
       "      <td>5154</td>\n",
       "      <td>2458000.5</td>\n",
       "      <td>0.210448</td>\n",
       "      <td>1.225615</td>\n",
       "      <td>16.793382</td>\n",
       "      <td>84.629307</td>\n",
       "      <td>495.597821</td>\n",
       "      <td>0.967687</td>\n",
       "      <td>158.263596</td>\n",
       "      <td>1.483543</td>\n",
       "      <td>2.457814e+06</td>\n",
       "      <td>135.142133</td>\n",
       "      <td>0.726395</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Absolute Magnitude  Est Dia in KM(min)  Est Dia in KM(max)  \\\n",
       "0                21.6            0.127220            0.284472   \n",
       "1                21.3            0.146068            0.326618   \n",
       "2                20.3            0.231502            0.517654   \n",
       "3                27.4            0.008801            0.019681   \n",
       "4                21.6            0.127220            0.284472   \n",
       "\n",
       "   Relative Velocity km per sec  Relative Velocity km per hr  \\\n",
       "0                      6.115834                 22017.003799   \n",
       "1                     18.113985                 65210.346095   \n",
       "2                      7.590711                 27326.560182   \n",
       "3                     11.173874                 40225.948191   \n",
       "4                      9.840831                 35426.991794   \n",
       "\n",
       "   Miss Dist.(Astronomical)  Miss Dist.(lunar)  Miss Dist.(kilometers)  \\\n",
       "0                  0.419483         163.178711              62753692.0   \n",
       "1                  0.383014         148.992630              57298148.0   \n",
       "2                  0.050956          19.821890               7622911.5   \n",
       "3                  0.285322         110.990387              42683616.0   \n",
       "4                  0.407832         158.646713              61010824.0   \n",
       "\n",
       "   Orbit Uncertainity  Minimum Orbit Intersection  \\\n",
       "0                   5                    0.025282   \n",
       "1                   3                    0.186935   \n",
       "2                   0                    0.043058   \n",
       "3                   6                    0.005512   \n",
       "4                   1                    0.034798   \n",
       "\n",
       "   Jupiter Tisserand Invariant  Epoch Osculation  Eccentricity  \\\n",
       "0                         4634         2458000.5      0.425549   \n",
       "1                         5457         2458000.5      0.351674   \n",
       "2                         4557         2458000.5      0.348248   \n",
       "3                         5093         2458000.5      0.216578   \n",
       "4                         5154         2458000.5      0.210448   \n",
       "\n",
       "   Semi Major Axis  Inclination  Asc Node Longitude  Orbital Period  \\\n",
       "0         1.407011     6.025981          314.373913      609.599786   \n",
       "1         1.107776    28.412996          136.717242      425.869294   \n",
       "2         1.458824     4.237961          259.475979      643.580228   \n",
       "3         1.255903     7.905894           57.173266      514.082140   \n",
       "4         1.225615    16.793382           84.629307      495.597821   \n",
       "\n",
       "   Perihelion Distance  Perihelion Arg  Aphelion Dist  Perihelion Time  \\\n",
       "0             0.808259       57.257470       2.005764     2.458162e+06   \n",
       "1             0.718200      313.091975       1.497352     2.457795e+06   \n",
       "2             0.950791      248.415038       1.966857     2.458120e+06   \n",
       "3             0.983902       18.707701       1.527904     2.457902e+06   \n",
       "4             0.967687      158.263596       1.483543     2.457814e+06   \n",
       "\n",
       "   Mean Anomaly  Mean Motion  Hazardous  Orbit_ID_1  Orbit_ID_2  Orbit_ID_3  \\\n",
       "0    264.837533     0.590551          1           0           0           0   \n",
       "1    173.741112     0.845330          0           0           0           0   \n",
       "2    292.893654     0.559371          1           0           0           0   \n",
       "3     68.741007     0.700277          0           0           0           0   \n",
       "4    135.142133     0.726395          1           0           0           0   \n",
       "\n",
       "   Orbit_ID_4  Orbit_ID_5  Orbit_ID_6  Orbit_ID_7  Orbit_ID_8  Orbit_ID_9  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           0           0           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           0           0           1           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   Orbit_ID_10  Orbit_ID_11  Orbit_ID_12  Orbit_ID_13  Orbit_ID_14  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Orbit_ID_15  Orbit_ID_16  Orbit_ID_17  Orbit_ID_18  Orbit_ID_19  \\\n",
       "0            0            0            1            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Orbit_ID_20  Orbit_ID_21  Orbit_ID_22  Orbit_ID_23  Orbit_ID_24  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            1            0            0            0   \n",
       "2            0            0            1            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Orbit_ID_25  Orbit_ID_26  Orbit_ID_27  Orbit_ID_28  Orbit_ID_29  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            1            0            0            0            0   \n",
       "\n",
       "   Orbit_ID_30  Orbit_ID_31  Orbit_ID_32  Orbit_ID_33  Orbit_ID_34  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Orbit_ID_35  Orbit_ID_36  Orbit_ID_37  Orbit_ID_38  Orbit_ID_39  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Orbit_ID_40  Orbit_ID_41  Orbit_ID_42  Orbit_ID_43  Orbit_ID_44  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Orbit_ID_45  Orbit_ID_46  Orbit_ID_47  Orbit_ID_48  Orbit_ID_49  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Orbit_ID_50  Orbit_ID_51  Orbit_ID_52  Orbit_ID_53  Orbit_ID_54  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Orbit_ID_55  Orbit_ID_56  Orbit_ID_57  Orbit_ID_58  Orbit_ID_59  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Orbit_ID_60  Orbit_ID_61  Orbit_ID_62  Orbit_ID_63  Orbit_ID_64  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Orbit_ID_65  Orbit_ID_66  Orbit_ID_67  Orbit_ID_68  Orbit_ID_69  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Orbit_ID_70  Orbit_ID_71  Orbit_ID_72  Orbit_ID_73  Orbit_ID_74  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Orbit_ID_75  Orbit_ID_76  Orbit_ID_77  Orbit_ID_78  Orbit_ID_79  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Orbit_ID_80  Orbit_ID_81  Orbit_ID_82  Orbit_ID_83  Orbit_ID_84  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Orbit_ID_85  Orbit_ID_86  Orbit_ID_87  Orbit_ID_88  Orbit_ID_89  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Orbit_ID_90  Orbit_ID_91  Orbit_ID_92  Orbit_ID_93  Orbit_ID_94  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Orbit_ID_95  Orbit_ID_96  Orbit_ID_97  Orbit_ID_98  Orbit_ID_99  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Orbit_ID_100  Orbit_ID_101  Orbit_ID_102  Orbit_ID_103  Orbit_ID_104  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   Orbit_ID_105  Orbit_ID_106  Orbit_ID_107  Orbit_ID_108  Orbit_ID_109  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   Orbit_ID_111  Orbit_ID_112  Orbit_ID_113  Orbit_ID_114  Orbit_ID_115  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   Orbit_ID_116  Orbit_ID_117  Orbit_ID_119  Orbit_ID_120  Orbit_ID_121  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   Orbit_ID_122  Orbit_ID_123  Orbit_ID_125  Orbit_ID_126  Orbit_ID_128  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   Orbit_ID_130  Orbit_ID_131  Orbit_ID_132  Orbit_ID_133  Orbit_ID_134  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   Orbit_ID_137  Orbit_ID_138  Orbit_ID_140  Orbit_ID_143  Orbit_ID_146  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   Orbit_ID_147  Orbit_ID_148  Orbit_ID_149  Orbit_ID_152  Orbit_ID_154  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   Orbit_ID_156  Orbit_ID_157  Orbit_ID_158  Orbit_ID_159  Orbit_ID_163  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   Orbit_ID_164  Orbit_ID_165  Orbit_ID_167  Orbit_ID_170  Orbit_ID_172  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   Orbit_ID_175  Orbit_ID_176  Orbit_ID_182  Orbit_ID_184  Orbit_ID_185  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   Orbit_ID_190  Orbit_ID_192  Orbit_ID_193  Orbit_ID_207  Orbit_ID_211  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   Orbit_ID_212  Orbit_ID_213  Orbit_ID_214  \n",
       "0             0             0             0  \n",
       "1             0             0             0  \n",
       "2             0             0             0  \n",
       "3             0             0             0  \n",
       "4             0             0             0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encoding van 'Orbit ID'\n",
    "\n",
    "dataset = pd.concat([dataset,pd.get_dummies(dataset['Orbit ID'], prefix='Orbit_ID')],axis=1)\n",
    "\n",
    "dataset.drop(['Orbit ID'],axis=1, inplace=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Absolute Magnitude              float64\n",
       "Est Dia in KM(min)              float64\n",
       "Est Dia in KM(max)              float64\n",
       "Relative Velocity km per sec    float64\n",
       "Relative Velocity km per hr     float64\n",
       "Miss Dist.(Astronomical)        float64\n",
       "Miss Dist.(lunar)               float64\n",
       "Miss Dist.(kilometers)          float64\n",
       "Orbit Uncertainity                int64\n",
       "Minimum Orbit Intersection      float64\n",
       "Jupiter Tisserand Invariant       int64\n",
       "Epoch Osculation                float64\n",
       "Eccentricity                    float64\n",
       "Semi Major Axis                 float64\n",
       "Inclination                     float64\n",
       "Asc Node Longitude              float64\n",
       "Orbital Period                  float64\n",
       "Perihelion Distance             float64\n",
       "Perihelion Arg                  float64\n",
       "Aphelion Dist                   float64\n",
       "Perihelion Time                 float64\n",
       "Mean Anomaly                    float64\n",
       "Mean Motion                     float64\n",
       "Hazardous                         int64\n",
       "Orbit_ID_1                        uint8\n",
       "Orbit_ID_2                        uint8\n",
       "Orbit_ID_3                        uint8\n",
       "Orbit_ID_4                        uint8\n",
       "Orbit_ID_5                        uint8\n",
       "Orbit_ID_6                        uint8\n",
       "Orbit_ID_7                        uint8\n",
       "Orbit_ID_8                        uint8\n",
       "Orbit_ID_9                        uint8\n",
       "Orbit_ID_10                       uint8\n",
       "Orbit_ID_11                       uint8\n",
       "Orbit_ID_12                       uint8\n",
       "Orbit_ID_13                       uint8\n",
       "Orbit_ID_14                       uint8\n",
       "Orbit_ID_15                       uint8\n",
       "Orbit_ID_16                       uint8\n",
       "Orbit_ID_17                       uint8\n",
       "Orbit_ID_18                       uint8\n",
       "Orbit_ID_19                       uint8\n",
       "Orbit_ID_20                       uint8\n",
       "Orbit_ID_21                       uint8\n",
       "Orbit_ID_22                       uint8\n",
       "Orbit_ID_23                       uint8\n",
       "Orbit_ID_24                       uint8\n",
       "Orbit_ID_25                       uint8\n",
       "Orbit_ID_26                       uint8\n",
       "Orbit_ID_27                       uint8\n",
       "Orbit_ID_28                       uint8\n",
       "Orbit_ID_29                       uint8\n",
       "Orbit_ID_30                       uint8\n",
       "Orbit_ID_31                       uint8\n",
       "Orbit_ID_32                       uint8\n",
       "Orbit_ID_33                       uint8\n",
       "Orbit_ID_34                       uint8\n",
       "Orbit_ID_35                       uint8\n",
       "Orbit_ID_36                       uint8\n",
       "Orbit_ID_37                       uint8\n",
       "Orbit_ID_38                       uint8\n",
       "Orbit_ID_39                       uint8\n",
       "Orbit_ID_40                       uint8\n",
       "Orbit_ID_41                       uint8\n",
       "Orbit_ID_42                       uint8\n",
       "Orbit_ID_43                       uint8\n",
       "Orbit_ID_44                       uint8\n",
       "Orbit_ID_45                       uint8\n",
       "Orbit_ID_46                       uint8\n",
       "Orbit_ID_47                       uint8\n",
       "Orbit_ID_48                       uint8\n",
       "Orbit_ID_49                       uint8\n",
       "Orbit_ID_50                       uint8\n",
       "Orbit_ID_51                       uint8\n",
       "Orbit_ID_52                       uint8\n",
       "Orbit_ID_53                       uint8\n",
       "Orbit_ID_54                       uint8\n",
       "Orbit_ID_55                       uint8\n",
       "Orbit_ID_56                       uint8\n",
       "Orbit_ID_57                       uint8\n",
       "Orbit_ID_58                       uint8\n",
       "Orbit_ID_59                       uint8\n",
       "Orbit_ID_60                       uint8\n",
       "Orbit_ID_61                       uint8\n",
       "Orbit_ID_62                       uint8\n",
       "Orbit_ID_63                       uint8\n",
       "Orbit_ID_64                       uint8\n",
       "Orbit_ID_65                       uint8\n",
       "Orbit_ID_66                       uint8\n",
       "Orbit_ID_67                       uint8\n",
       "Orbit_ID_68                       uint8\n",
       "Orbit_ID_69                       uint8\n",
       "Orbit_ID_70                       uint8\n",
       "Orbit_ID_71                       uint8\n",
       "Orbit_ID_72                       uint8\n",
       "Orbit_ID_73                       uint8\n",
       "Orbit_ID_74                       uint8\n",
       "Orbit_ID_75                       uint8\n",
       "Orbit_ID_76                       uint8\n",
       "Orbit_ID_77                       uint8\n",
       "Orbit_ID_78                       uint8\n",
       "Orbit_ID_79                       uint8\n",
       "Orbit_ID_80                       uint8\n",
       "Orbit_ID_81                       uint8\n",
       "Orbit_ID_82                       uint8\n",
       "Orbit_ID_83                       uint8\n",
       "Orbit_ID_84                       uint8\n",
       "Orbit_ID_85                       uint8\n",
       "Orbit_ID_86                       uint8\n",
       "Orbit_ID_87                       uint8\n",
       "Orbit_ID_88                       uint8\n",
       "Orbit_ID_89                       uint8\n",
       "Orbit_ID_90                       uint8\n",
       "Orbit_ID_91                       uint8\n",
       "Orbit_ID_92                       uint8\n",
       "Orbit_ID_93                       uint8\n",
       "Orbit_ID_94                       uint8\n",
       "Orbit_ID_95                       uint8\n",
       "Orbit_ID_96                       uint8\n",
       "Orbit_ID_97                       uint8\n",
       "Orbit_ID_98                       uint8\n",
       "Orbit_ID_99                       uint8\n",
       "Orbit_ID_100                      uint8\n",
       "Orbit_ID_101                      uint8\n",
       "Orbit_ID_102                      uint8\n",
       "Orbit_ID_103                      uint8\n",
       "Orbit_ID_104                      uint8\n",
       "Orbit_ID_105                      uint8\n",
       "Orbit_ID_106                      uint8\n",
       "Orbit_ID_107                      uint8\n",
       "Orbit_ID_108                      uint8\n",
       "Orbit_ID_109                      uint8\n",
       "Orbit_ID_111                      uint8\n",
       "Orbit_ID_112                      uint8\n",
       "Orbit_ID_113                      uint8\n",
       "Orbit_ID_114                      uint8\n",
       "Orbit_ID_115                      uint8\n",
       "Orbit_ID_116                      uint8\n",
       "Orbit_ID_117                      uint8\n",
       "Orbit_ID_119                      uint8\n",
       "Orbit_ID_120                      uint8\n",
       "Orbit_ID_121                      uint8\n",
       "Orbit_ID_122                      uint8\n",
       "Orbit_ID_123                      uint8\n",
       "Orbit_ID_125                      uint8\n",
       "Orbit_ID_126                      uint8\n",
       "Orbit_ID_128                      uint8\n",
       "Orbit_ID_130                      uint8\n",
       "Orbit_ID_131                      uint8\n",
       "Orbit_ID_132                      uint8\n",
       "Orbit_ID_133                      uint8\n",
       "Orbit_ID_134                      uint8\n",
       "Orbit_ID_137                      uint8\n",
       "Orbit_ID_138                      uint8\n",
       "Orbit_ID_140                      uint8\n",
       "Orbit_ID_143                      uint8\n",
       "Orbit_ID_146                      uint8\n",
       "Orbit_ID_147                      uint8\n",
       "Orbit_ID_148                      uint8\n",
       "Orbit_ID_149                      uint8\n",
       "Orbit_ID_152                      uint8\n",
       "Orbit_ID_154                      uint8\n",
       "Orbit_ID_156                      uint8\n",
       "Orbit_ID_157                      uint8\n",
       "Orbit_ID_158                      uint8\n",
       "Orbit_ID_159                      uint8\n",
       "Orbit_ID_163                      uint8\n",
       "Orbit_ID_164                      uint8\n",
       "Orbit_ID_165                      uint8\n",
       "Orbit_ID_167                      uint8\n",
       "Orbit_ID_170                      uint8\n",
       "Orbit_ID_172                      uint8\n",
       "Orbit_ID_175                      uint8\n",
       "Orbit_ID_176                      uint8\n",
       "Orbit_ID_182                      uint8\n",
       "Orbit_ID_184                      uint8\n",
       "Orbit_ID_185                      uint8\n",
       "Orbit_ID_190                      uint8\n",
       "Orbit_ID_192                      uint8\n",
       "Orbit_ID_193                      uint8\n",
       "Orbit_ID_207                      uint8\n",
       "Orbit_ID_211                      uint8\n",
       "Orbit_ID_212                      uint8\n",
       "Orbit_ID_213                      uint8\n",
       "Orbit_ID_214                      uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for categorical features\n",
    "\n",
    "dataset.dtypes\n",
    "\n",
    "# no categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Controleer of de dataset al dan niet **gebalanceerd** is. **Antwoord** duidelijk of dit al dan niet het geval is en wat de **mogelijke gevolgen** kunnen zijn mocht deze niet gebalanceerd zijn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3724\n",
      "1     733\n",
      "Name: Hazardous, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Controleer of de dataset gebalanceerd is. \n",
    "sns.countplot(x='Hazardous',data=dataset)\n",
    "print(dataset['Hazardous'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, as you can see class 0 has 3724 samples and class 1 with 733 samples. Therefore, the dataset is not balanced.\n",
    "\n",
    "The consequences:\n",
    "- The cost of missing a minority class is much higher than missing a majority class.\n",
    "- Imbalanced classes may not maximize the overall accuracy due to the lack of dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainen van de classifier\n",
    "\n",
    "Splits eerst de features op in een training- en test set. \n",
    "\n",
    "Zorg ervoor dat er exact **1000 samples** in de test set steken en gebruik een **random_state = 0**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24.5         0.03346224  0.07482384 ...  0.          0.\n",
      "   0.        ]\n",
      " [21.          0.16770846  0.37500752 ...  0.          0.\n",
      "   0.        ]\n",
      " [23.9         0.04411182  0.09863703 ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [20.2         0.24241248  0.54205079 ...  0.          0.\n",
      "   0.        ]\n",
      " [17.7         0.76657557  1.71411509 ...  0.          0.\n",
      "   0.        ]\n",
      " [21.5         0.13321557  0.29787906 ...  0.          0.\n",
      "   0.        ]]\n",
      "[[2.33000000e+01 5.81507040e-02 1.30028927e-01 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.15000000e+01 1.33215567e-01 2.97879063e-01 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.96000000e+01 3.19561887e-01 7.14562102e-01 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [2.69000000e+01 1.10803882e-02 2.47765013e-02 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.45000000e+01 3.34622374e-02 7.48238376e-02 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.11000000e+01 1.60160338e-01 3.58129403e-01 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Opsplitsen in features en targets. \n",
    "X = dataset.drop('Hazardous', axis=1).values\n",
    "y = dataset['Hazardous'].values\n",
    "\n",
    "# Opsplitsen in test en training_set met 1000 waarden in test set en random_state = 0. Normaliseer de features.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1000, random_state = 0)\n",
    "print(X_train)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.05159565 -0.67187093 -0.67187093 ... -0.02405974  0.\n",
      "   0.        ]\n",
      " [-0.05495837 -0.10835817 -0.10835817 ... -0.02405974  0.\n",
      "   0.        ]\n",
      " [-0.05217212 -0.62716818 -0.62716818 ... -0.02405974  0.\n",
      "   0.        ]\n",
      " ...\n",
      " [-0.05572699  0.20521987  0.20521987 ... -0.02405974  0.\n",
      "   0.        ]\n",
      " [-0.05812893  2.40545003  2.40545003 ... -0.02405974  0.\n",
      "   0.        ]\n",
      " [-0.05447798 -0.25314576 -0.25314576 ... -0.02405974  0.\n",
      "   0.        ]]\n",
      "[[-0.05274858 -0.56823848 -0.56823848 ... -0.02405974  0.\n",
      "   0.        ]\n",
      " [-0.05447798 -0.25314576 -0.25314576 ... -0.02405974  0.\n",
      "   0.        ]\n",
      " [-0.05630346  0.52906268  0.52906268 ... -0.02405974  0.\n",
      "   0.        ]\n",
      " ...\n",
      " [-0.04928979 -0.76582112 -0.76582112 ... -0.02405974  0.\n",
      "   0.        ]\n",
      " [-0.05159565 -0.67187093 -0.67187093 ... -0.02405974  0.\n",
      "   0.        ]\n",
      " [-0.05486229 -0.14004222 -0.14004222 ... -0.02405974  0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Normaliseer de features\n",
    "\n",
    "## Standard scaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "print(X_train)\n",
    "print(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train een logistic regression classifier met een **C-waarde van 0.001**\n",
    "**Normaliseer** de data vooraleer je een classifier traint.\n",
    "Test deze classifier: bepaal de accuracy, precision, recall en f1-score. Geef ook de confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93       844\n",
      "           1       0.62      0.49      0.55       156\n",
      "\n",
      "    accuracy                           0.87      1000\n",
      "   macro avg       0.77      0.72      0.74      1000\n",
      "weighted avg       0.86      0.87      0.87      1000\n",
      "\n",
      "test set:  87.4\n",
      "[[797  47]\n",
      " [ 79  77]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93      2880\n",
      "           1       0.69      0.50      0.58       577\n",
      "\n",
      "    accuracy                           0.88      3457\n",
      "   macro avg       0.80      0.73      0.75      3457\n",
      "weighted avg       0.87      0.88      0.87      3457\n",
      "\n",
      "training set:  87.90859126410182\n",
      "[[2750  130]\n",
      " [ 288  289]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Trainen en testen van een logistic regression classifier met C=0.001\n",
    "\n",
    "logreg = linear_model.LogisticRegression(C=0.001, solver='liblinear')\n",
    "\n",
    "logreg.fit(X_train,y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "print('test set: ', accuracy_score(y_test,y_pred)*100)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = logreg.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# training set\n",
    "\n",
    "y_pred = logreg.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train,y_pred))\n",
    "\n",
    "print('training set: ', accuracy_score(y_train,y_pred)*100)\n",
    "\n",
    "print(confusion_matrix(y_train,y_pred))\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = logreg.predict_proba(X_train)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_train, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bespreek de bekomen testresultaten van de logistic regression classifier met C=0.001.\n",
    "\n",
    "**Heeft deze classifier last van underfitting of overfitting? Hoe kan je dat te weten komen? Illustreer.**\n",
    "\n",
    "**Bespreek de getallen in de confusion matrix**. Zijn deze te linken aan de al dan niet gebalanceerdheid van de data?\n",
    "\n",
    "\n",
    "**Antwoorden:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Heeft deze classifier last van underfitting of overfitting? Hoe kan je dat te weten komen? Illustreer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Heeft deze classifier last van underfitting of overfitting? Hoe kan je dat te weten komen? Illustreer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above from the accuracy on the test amounts 87,4% and on the training set 87.90%. The accuracy on the training set is slightly higher than the test set. This means that the classifier is dealing with an overfitting. For illustration, I have implemented the ROC. The area under the curve is slightly higher on the training set. (0.91 trainingset vs 0.90 testset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bespreek de getallen in de confusion matrix. Zijn deze te linken aan de al dan niet gebalanceerdheid van de data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our confusion matrix, we can see that our model got (797+77) 874 predictions right and (79+47) 126 predictions wrong. We have 47 false positive which means that our model predicted that 47 are hazardous but it turned out not to be. On the other hand, our model also has 79 false negative. What this means is that our model predicted 79 were not hazardous while they are positive. \n",
    "\n",
    "Moreover based on the classification report there is a preference for class 0 with 0.93% compared with class 1 with 0.55%. \n",
    "\n",
    "Yes there is a link with the unbalanced data. We can clearly see from the confusion matrix that there is a very low number of one class. In this case, it is 876 (797+79) for class 0 and 124 (47+77) for class 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gebruik **cross-validatie om een goede C-waarde te vinden voor de logistic regression classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 100 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  92 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done 246 tasks      | elapsed:   31.9s\n",
      "[Parallel(n_jobs=-1)]: Done 372 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 534 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 732 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 966 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1236 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1542 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1884 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed: 13.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.9123554913294798\n",
      "Best parameters : {'C': 100.001, 'class_weight': None, 'solver': 'newton-cg'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       844\n",
      "           1       0.81      0.71      0.76       156\n",
      "\n",
      "    accuracy                           0.93      1000\n",
      "   macro avg       0.88      0.84      0.86      1000\n",
      "weighted avg       0.93      0.93      0.93      1000\n",
      "\n",
      "[[818  26]\n",
      " [ 45 111]]\n",
      "92.9\n"
     ]
    }
   ],
   "source": [
    "# Cross-validatie logistic regression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "paramaters = [\n",
    "             {'C' : np.arange(0.001,1000,100),\n",
    "              'solver': ['liblinear','lbfgs', 'newton-cg', 'sag','saga'], \n",
    "              'class_weight': [None, 'balanced'],\n",
    "             },\n",
    "             ]\n",
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = paramaters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 20,\n",
    "                           n_jobs = -1,\n",
    "                           verbose=5)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_ \n",
    "best_parameters = grid_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', grid_search.best_score_)\n",
    "print('Best parameters :', grid_search.best_params_  )\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 20 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.914380293050141\n",
      "Best parameters : {'C': 16.682651210851347, 'class_weight': None, 'solver': 'newton-cg'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       844\n",
      "           1       0.81      0.70      0.75       156\n",
      "\n",
      "    accuracy                           0.93      1000\n",
      "   macro avg       0.88      0.83      0.85      1000\n",
      "weighted avg       0.92      0.93      0.92      1000\n",
      "\n",
      "[[818  26]\n",
      " [ 47 109]]\n",
      "92.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint \n",
    "from scipy.stats import uniform\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "parameters = [\n",
    "             {'C' : uniform(0.01, 20), \n",
    "              'solver': ['liblinear','lbfgs', 'newton-cg', 'sag','saga'], \n",
    "              'class_weight': [None, 'balanced'],\n",
    "             }\n",
    "             ]\n",
    "\n",
    "              \n",
    "\n",
    "n_iter_search = 20\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_distributions=parameters,cv=20,n_iter=n_iter_search,n_jobs = -1,verbose=1)\n",
    "\n",
    "random_search = random_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = random_search.best_score_ \n",
    "best_parameters = random_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', random_search.best_score_)\n",
    "print('Best parameters :',random_search.best_params_  )\n",
    "\n",
    "y_pred = random_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bespreek de resultaten na cross-validatie**\n",
    "\n",
    "**Antwoord:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our initial accuracy on the test set amounts 87,4%. After the cross-validation we can see an increase to 92,9% with grid search and 92,7% with random search. Moreover, we are not dealing with an overfitting. Therefore the logistic regression with grid search method is the most reliable model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train een Support Vector Machine**. Je mag onmiddellijk cross-validatie toepassen voor het vinden van de optimale parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, kernel='linear')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross-validatie Support Vector Machine\n",
    "\n",
    "# Trainen van SVM via cross-validation\n",
    "SVMlinear = svm.SVC(kernel='linear',C=1)\n",
    "SVMlinear.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       844\n",
      "           1       0.82      0.72      0.76       156\n",
      "\n",
      "    accuracy                           0.93      1000\n",
      "   macro avg       0.88      0.84      0.86      1000\n",
      "weighted avg       0.93      0.93      0.93      1000\n",
      "\n",
      "[[819  25]\n",
      " [ 44 112]]\n",
      "93.10000000000001\n"
     ]
    }
   ],
   "source": [
    "# test het model op de test set\n",
    "y_pred = SVMlinear.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96      2880\n",
      "           1       0.83      0.71      0.76       577\n",
      "\n",
      "    accuracy                           0.93      3457\n",
      "   macro avg       0.88      0.84      0.86      3457\n",
      "weighted avg       0.92      0.93      0.92      3457\n",
      "\n",
      "[[2794   86]\n",
      " [ 168  409]]\n",
      "92.65258894995661\n"
     ]
    }
   ],
   "source": [
    "# test het model op de training set\n",
    "y_pred = SVMlinear.predict(X_train)\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_train, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_train, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 260 candidates, totalling 5200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   34.6s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed: 18.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed: 21.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed: 25.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 29.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2170 tasks      | elapsed: 34.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed: 38.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3034 tasks      | elapsed: 43.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3520 tasks      | elapsed: 49.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed: 55.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4600 tasks      | elapsed: 61.0min\n",
      "[Parallel(n_jobs=-1)]: Done 5200 out of 5200 | elapsed: 67.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.914094636375857\n",
      "Best parameters : {'C': 8.894444444444444, 'class_weight': None, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       844\n",
      "           1       0.84      0.74      0.78       156\n",
      "\n",
      "    accuracy                           0.94      1000\n",
      "   macro avg       0.90      0.86      0.87      1000\n",
      "weighted avg       0.93      0.94      0.94      1000\n",
      "\n",
      "[[822  22]\n",
      " [ 41 115]]\n",
      "93.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC()\n",
    "\n",
    "paramaters = [ \n",
    "       {'kernel': ['linear'], \n",
    "         'C': np.linspace(0.01,20,10), \n",
    "         'class_weight': [None, 'balanced']},\n",
    "        {'kernel': ['rbf', 'poly', 'sigmoid'], \n",
    "         'C': np.linspace(0.01,20,10), \n",
    "         'gamma': [0.001, 0.01, 0.1, 0.2], \n",
    "         'class_weight': [None, 'balanced']},\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = paramaters,\n",
    "                           scoring = 'accuracy', \n",
    "                           cv = 20,\n",
    "                           n_jobs = -1,\n",
    "                           verbose =5)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_ \n",
    "best_parameters = grid_search.best_params_  \n",
    "print('Best accuracy : ', grid_search.best_score_)\n",
    "print('Best parameters :', grid_search.best_params_  )\n",
    "\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   35.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.9172670085241293\n",
      "Best parameters : {'C': 10.4486355123514, 'class_weight': None, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       844\n",
      "           1       0.83      0.74      0.78       156\n",
      "\n",
      "    accuracy                           0.94      1000\n",
      "   macro avg       0.89      0.85      0.87      1000\n",
      "weighted avg       0.93      0.94      0.93      1000\n",
      "\n",
      "[[820  24]\n",
      " [ 41 115]]\n",
      "93.5\n"
     ]
    }
   ],
   "source": [
    "# Train een SVM via random search\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint \n",
    "from scipy.stats import uniform\n",
    "\n",
    "\n",
    "#svc trainen\n",
    "model = SVC()\n",
    "\n",
    "parameters = [\n",
    "     {'kernel': ['linear'], \n",
    "     'C': uniform(0.01, 20), \n",
    "     'class_weight': [None, 'balanced']\n",
    "    },\n",
    "    {'kernel': ['rbf', 'poly', 'sigmoid'], \n",
    "     'C': uniform(0.01, 20), \n",
    "     'gamma': [0.001, 0.01, 0.1, 0.2], \n",
    "     'class_weight': [None, 'balanced']}\n",
    "]\n",
    " \n",
    "n_iter_search = 20\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_distributions=parameters,cv=5,n_iter=n_iter_search,n_jobs = -1,verbose=1)\n",
    "\n",
    "random_search = random_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = random_search.best_score_ \n",
    "best_parameters = random_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', random_search.best_score_)\n",
    "print('Best parameters :',random_search.best_params_  )\n",
    "\n",
    "y_pred = random_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bespreek de resultaten na cross-validatie op SVM**\n",
    "\n",
    "**Antwoord:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our initial accuracy on the test set amounts 93,1%. After the cross-validation we can see a slight increase to 93,7% with grid search and 93,5% with random search. Moreover, we are not dealing with an overfitting. Therefore the SVM with grid search method is the most reliable model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train een **Random Forest Classifier**. Het max_number_of_features is een hyperparameter waarvan je zelf de optimale waarde zoekt. Start met een 200-tal bomen. Dit aantal kan je tijdens de hyperparametertuning aanpassen.\n",
    "\n",
    "- Test deze classifier op de trainingset. Wat zijn jouw bevindingen en conclusies? Vergelijk de resultaten met deze van logistic regression en SVM.\n",
    "\n",
    "- Bepaal via deze random forest tree classifier de belangrijkste features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainen en testen van een random forest tree classifier\n",
    "number_of_trees = 200\n",
    "max_number_of_features = 10\n",
    "\n",
    "RFCmodel = RandomForestClassifier(n_estimators=number_of_trees, max_features=max_number_of_features)\n",
    "\n",
    "\n",
    "RFCmodel.fit(X_train,y_train)\n",
    "\n",
    "# print(RFCmodel.feature_importances_)\n",
    "\n",
    "importance  = RFCmodel.feature_importances_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = dataset.columns\n",
    "importances = importance\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "# customized number \n",
    "num_features = 10 \n",
    " \n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title('Feature Importances')\n",
    "\n",
    "# only plot the customized number of features\n",
    "plt.barh(range(num_features), importances[indices[-num_features:]], color='b', align='center')\n",
    "plt.yticks(range(num_features), [features[i] for i in indices[-num_features:]])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       844\n",
      "           1       0.98      0.99      0.98       156\n",
      "\n",
      "    accuracy                           0.99      1000\n",
      "   macro avg       0.99      0.99      0.99      1000\n",
      "weighted avg       1.00      0.99      1.00      1000\n",
      "\n",
      "[[841   3]\n",
      " [  2 154]]\n",
      "99.5\n"
     ]
    }
   ],
   "source": [
    "# test random forest classifier --> test set\n",
    "y_pred = RFCmodel.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2880\n",
      "           1       1.00      1.00      1.00       577\n",
      "\n",
      "    accuracy                           1.00      3457\n",
      "   macro avg       1.00      1.00      1.00      3457\n",
      "weighted avg       1.00      1.00      1.00      3457\n",
      "\n",
      "[[2880    0]\n",
      " [   0  577]]\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "# test random forest classifier --> training set \n",
    "y_pred = RFCmodel.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_train, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_train, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross-validation random forest tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 378 candidates, totalling 7560 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed: 15.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 20.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2170 tasks      | elapsed: 25.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed: 32.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3034 tasks      | elapsed: 40.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3520 tasks      | elapsed: 48.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed: 59.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4600 tasks      | elapsed: 70.1min\n",
      "[Parallel(n_jobs=-1)]: Done 5194 tasks      | elapsed: 82.6min\n",
      "[Parallel(n_jobs=-1)]: Done 5824 tasks      | elapsed: 96.3min\n",
      "[Parallel(n_jobs=-1)]: Done 6490 tasks      | elapsed: 111.4min\n",
      "[Parallel(n_jobs=-1)]: Done 7192 tasks      | elapsed: 128.0min\n",
      "[Parallel(n_jobs=-1)]: Done 7560 out of 7560 | elapsed: 136.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.995086705202312\n",
      "Best parameters : {'max_features': 14, 'min_samples_leaf': 3, 'min_samples_split': 8, 'n_estimators': 600}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       844\n",
      "           1       0.99      0.99      0.99       156\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       0.99      1.00      0.99      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "[[842   2]\n",
      " [  1 155]]\n",
      "99.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "paramaters = [\n",
    "             {'n_estimators' : [100, 200, 300, 600, 800, 1000],\n",
    "              'max_features': [2, 4, 6, 8, 10, 12, 14], \n",
    "              'min_samples_leaf': [3, 4, 5],\n",
    "              'min_samples_split': [8, 10, 12],\n",
    "             },\n",
    "             ]\n",
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = paramaters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 20,\n",
    "                           n_jobs = -1,\n",
    "                           verbose=5)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_ \n",
    "best_parameters = grid_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', grid_search.best_score_)\n",
    "print('Best parameters :', grid_search.best_params_  )\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 20 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   44.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  6.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.995086705202312\n",
      "Best parameters : {'n_estimators': 1000, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 14}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       844\n",
      "           1       0.99      0.99      0.99       156\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       0.99      1.00      0.99      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "[[842   2]\n",
      " [  1 155]]\n",
      "99.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint \n",
    "from scipy.stats import uniform\n",
    "\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "parameters = [\n",
    "             {'n_estimators' : [100, 200, 300, 600, 800, 1000],\n",
    "              'max_features': [2, 4, 6, 8, 10, 12, 14], \n",
    "              'min_samples_leaf': [3, 4, 5],\n",
    "              'min_samples_split': [8, 10, 12],\n",
    "             },\n",
    "             ]\n",
    "\n",
    "              \n",
    "\n",
    "n_iter_search = 20\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_distributions=parameters,cv=20,n_iter=n_iter_search,n_jobs = -1,verbose=1)\n",
    "\n",
    "random_search = random_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = random_search.best_score_ \n",
    "best_parameters = random_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', random_search.best_score_)\n",
    "print('Best parameters :',random_search.best_params_  )\n",
    "\n",
    "y_pred = random_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test deze classifier op de trainingset. Wat zijn jouw bevindingen en conclusies? Vergelijk de resultaten met deze van logistic regression en SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy on the training set with the random forest classifier amounts 100% compared with 87,9% (logistic regression) and 92,65% (SVM). Therefore for this dataset the random forest classifier is the most reliable model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bepaal via deze random forest tree classifier de belangrijkste features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 Feature importances are:\n",
      "\n",
      "Minimum Orbit Intersection, Score: 0.285\n",
      "Absolute Magnitude, Score: 0.091\n",
      "Est Dia in KM(min), Score: 0.087\n",
      "Est Dia in KM(max), Score: 0.086\n",
      "Inclination, Score: 0.04\n",
      "Orbit Uncertainity, Score: 0.038\n",
      "Perihelion Distance, Score: 0.037\n",
      "Eccentricity, Score: 0.023\n",
      "Miss Dist.(kilometers), Score: 0.023\n",
      "Miss Dist.(lunar), Score: 0.022\n"
     ]
    }
   ],
   "source": [
    "imp_list = []\n",
    "for i,v in enumerate(importance):\n",
    "    imp_list.append((i, v))\n",
    "sorted_list = sorted(imp_list, key=lambda x: x[1], reverse=True)\n",
    "print('The top 10 Feature importances are:' '\\n')\n",
    "for f, i in sorted_list[:10]:\n",
    "    print(f'{dataset.columns[f]}, Score: {round(i, 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot importances:\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.ylim(0, 0.08)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Feature Importance Value')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot top ten importances\n",
    "plt.bar(range(1, 11), [x[1] for x in sorted_list[:10]], \n",
    "            tick_label=[x[0] for x in sorted_list[:10]], \n",
    "            color = (0.2,0.5,0.7,0.6))\n",
    "plt.title('Top Ten Feature Importances')\n",
    "plt.xlabel('Feature Number')\n",
    "plt.ylabel('Feature Importance Value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bepaal uit de gertrainde Random Forest Classifier de belangrijkheid van de features (model.feature_importances_). \n",
    "\n",
    "Welke zijn de 10 belangrijkste features?\n",
    "\n",
    "- Minimum Orbit Intersection, Score: 0.285\n",
    "- Absolute Magnitude, Score: 0.091\n",
    "- Est Dia in KM(min), Score: 0.087\n",
    "- Est Dia in KM(max), Score: 0.086\n",
    "- Inclination, Score: 0.04\n",
    "- Orbit Uncertainity, Score: 0.038\n",
    "- Perihelion Distance, Score: 0.037\n",
    "- Eccentricity, Score: 0.023\n",
    "- Miss Dist.(kilometers), Score: 0.023\n",
    "- Miss Dist.(lunar), Score: 0.022\n",
    "\n",
    "Train het model opnieuw met deze 10 belangrijkste features. Test het model en verklaar de resulaten.\n",
    "\n",
    "Reduceer het aantal features nog verder en bekijk telkens de accuracy. Verklaar de resultaten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train het model opnieuw met deze 10 belangrijkste features. Test het model en verklaar de resulaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train het model opnieuw met deze 10 belangrijkste features. Test het model en verklaar de resulaten.\n",
    "\n",
    "sum_column = dataset[['Minimum Orbit Intersection', 'Absolute Magnitude','Est Dia in KM(min)', 'Est Dia in KM(max)', 'Inclination', 'Perihelion Distance', 'Orbit Uncertainity', 'Miss Dist.(lunar)', 'Eccentricity', 'Miss Dist.(kilometers)']]\n",
    "X = sum_column.values\n",
    "y = dataset['Hazardous'].values\n",
    "\n",
    "#print(X)\n",
    "#print(y)\n",
    "# Opsplitsen in test en training_set met 1000 waarden in test set en random_state = 0. Normaliseer de features.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1000, random_state = 0)\n",
    "#print(X_train)\n",
    "#print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliseer de features\n",
    "\n",
    "## Standard scaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "# print(X_train)\n",
    "# print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainen en testen van een random forest tree classifier\n",
    "number_of_trees = 200\n",
    "max_number_of_features = 10\n",
    "\n",
    "RFCmodel = RandomForestClassifier(n_estimators=number_of_trees, max_features=max_number_of_features)\n",
    "\n",
    "\n",
    "RFCmodel.fit(X_train,y_train)\n",
    "\n",
    "#print(RFCmodel.feature_importances_)\n",
    "importance  = RFCmodel.feature_importances_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       844\n",
      "           1       0.97      1.00      0.99       156\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       0.99      1.00      0.99      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "[[840   4]\n",
      " [  0 156]]\n",
      "99.6\n"
     ]
    }
   ],
   "source": [
    "# test random forest classifier\n",
    "y_pred = RFCmodel.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2880\n",
      "           1       1.00      1.00      1.00       577\n",
      "\n",
      "    accuracy                           1.00      3457\n",
      "   macro avg       1.00      1.00      1.00      3457\n",
      "weighted avg       1.00      1.00      1.00      3457\n",
      "\n",
      "[[2880    0]\n",
      " [   0  577]]\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "# test random forest classifier --> train\n",
    "y_pred = RFCmodel.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_train, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_train, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross validate random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 378 candidates, totalling 7560 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   21.3s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed: 18.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 23.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2170 tasks      | elapsed: 29.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed: 35.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3034 tasks      | elapsed: 43.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3520 tasks      | elapsed: 51.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed: 61.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4600 tasks      | elapsed: 72.2min\n",
      "[Parallel(n_jobs=-1)]: Done 5194 tasks      | elapsed: 84.8min\n",
      "[Parallel(n_jobs=-1)]: Done 5824 tasks      | elapsed: 90.4min\n",
      "[Parallel(n_jobs=-1)]: Done 6490 tasks      | elapsed: 91.8min\n",
      "[Parallel(n_jobs=-1)]: Done 7192 tasks      | elapsed: 93.4min\n",
      "[Parallel(n_jobs=-1)]: Done 7560 out of 7560 | elapsed: 94.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.9965317919075145\n",
      "Best parameters : {'max_features': 8, 'min_samples_leaf': 3, 'min_samples_split': 8, 'n_estimators': 200}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       844\n",
      "           1       0.98      0.99      0.98       156\n",
      "\n",
      "    accuracy                           0.99      1000\n",
      "   macro avg       0.99      0.99      0.99      1000\n",
      "weighted avg       1.00      0.99      1.00      1000\n",
      "\n",
      "[[841   3]\n",
      " [  2 154]]\n",
      "99.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "paramaters = [\n",
    "             {'n_estimators' : [100, 200, 300, 600, 800, 1000],\n",
    "              'max_features': [2, 4, 6, 8, 10, 12, 14], \n",
    "              'min_samples_leaf': [3, 4, 5],\n",
    "              'min_samples_split': [8, 10, 12],\n",
    "             },\n",
    "             ]\n",
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = paramaters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 20,\n",
    "                           n_jobs = -1,\n",
    "                           verbose=5)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_ \n",
    "best_parameters = grid_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', grid_search.best_score_)\n",
    "print('Best parameters :', grid_search.best_params_  )\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 20 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  5.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.9959537572254336\n",
      "Best parameters : {'n_estimators': 600, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 10}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       844\n",
      "           1       0.98      0.99      0.99       156\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       0.99      1.00      0.99      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "[[841   3]\n",
      " [  1 155]]\n",
      "99.6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint \n",
    "from scipy.stats import uniform\n",
    "\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "parameters = [\n",
    "             {'n_estimators' : [100, 200, 300, 600, 800, 1000],\n",
    "              'max_features': [2, 4, 6, 8, 10, 12, 14], \n",
    "              'min_samples_leaf': [3, 4, 5],\n",
    "              'min_samples_split': [8, 10, 12],\n",
    "             },\n",
    "             ]\n",
    "\n",
    "              \n",
    "\n",
    "n_iter_search = 20\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_distributions=parameters,cv=20,n_iter=n_iter_search,n_jobs = -1,verbose=1)\n",
    "\n",
    "random_search = random_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = random_search.best_score_ \n",
    "best_parameters = random_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', random_search.best_score_)\n",
    "print('Best parameters :',random_search.best_params_  )\n",
    "\n",
    "y_pred = random_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train het model opnieuw met deze 10 belangrijkste features. Test het model en verklaar de resulaten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By reducing the features to the top 10, we can see that the accuracy score decreased from 99,7% to 99,6% (random search). The slight decrease has to do with using a smaller dataset for the X values. Eventhough the model has not been improved, we clearly can see that the execution time has been reduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reduceer het aantal features nog verder en bekijk telkens de accuracy. Verklaar de resultaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduceren van het aantal features en hertrainen via een random forest classifier.\n",
    "\n",
    "# Train het model opnieuw met deze 6 belangrijkste features. Test het model en verklaar de resulaten.\n",
    "\n",
    "sum_column = dataset[['Minimum Orbit Intersection', 'Absolute Magnitude','Est Dia in KM(min)', 'Est Dia in KM(max)', 'Inclination', 'Perihelion Distance']]\n",
    "X = sum_column.values\n",
    "y = dataset['Hazardous'].values\n",
    "\n",
    "#print(X)\n",
    "#print(y)\n",
    "# Opsplitsen in test en training_set met 1000 waarden in test set en random_state = 0. Normaliseer de features.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1000, random_state = 0)\n",
    "#print(X_train)\n",
    "#print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliseer de features\n",
    "\n",
    "## Standard scaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "#print(X_train)\n",
    "#print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features=4, n_estimators=200)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trainen en testen van een random forest tree classifier\n",
    "number_of_trees = 200\n",
    "max_number_of_features = 4\n",
    "\n",
    "RFCmodel = RandomForestClassifier(n_estimators=number_of_trees, max_features=max_number_of_features)\n",
    "\n",
    "\n",
    "RFCmodel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       844\n",
      "           1       0.97      0.99      0.98       156\n",
      "\n",
      "    accuracy                           0.99      1000\n",
      "   macro avg       0.99      0.99      0.99      1000\n",
      "weighted avg       1.00      0.99      1.00      1000\n",
      "\n",
      "[[840   4]\n",
      " [  1 155]]\n",
      "99.5\n"
     ]
    }
   ],
   "source": [
    "# test random forest classifier\n",
    "y_pred = RFCmodel.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2880\n",
      "           1       1.00      1.00      1.00       577\n",
      "\n",
      "    accuracy                           1.00      3457\n",
      "   macro avg       1.00      1.00      1.00      3457\n",
      "weighted avg       1.00      1.00      1.00      3457\n",
      "\n",
      "[[2880    0]\n",
      " [   0  577]]\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "# test random forest classifier --> train\n",
    "y_pred = RFCmodel.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_train, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_train, y_pred) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross validate random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 378 candidates, totalling 7560 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   18.9s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed: 16.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 20.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2170 tasks      | elapsed: 25.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed: 31.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3034 tasks      | elapsed: 38.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3520 tasks      | elapsed: 42.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed: 43.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4600 tasks      | elapsed: 44.9min\n",
      "[Parallel(n_jobs=-1)]: Done 5194 tasks      | elapsed: 46.1min\n",
      "[Parallel(n_jobs=-1)]: Done 5824 tasks      | elapsed: 47.3min\n",
      "[Parallel(n_jobs=-1)]: Done 6490 tasks      | elapsed: 48.7min\n",
      "[Parallel(n_jobs=-1)]: Done 7192 tasks      | elapsed: 50.0min\n",
      "[Parallel(n_jobs=-1)]: Done 7560 out of 7560 | elapsed: 50.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.9965317919075145\n",
      "Best parameters : {'max_features': 4, 'min_samples_leaf': 3, 'min_samples_split': 8, 'n_estimators': 1000}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       844\n",
      "           1       0.97      0.99      0.98       156\n",
      "\n",
      "    accuracy                           0.99      1000\n",
      "   macro avg       0.99      0.99      0.99      1000\n",
      "weighted avg       1.00      0.99      1.00      1000\n",
      "\n",
      "[[840   4]\n",
      " [  1 155]]\n",
      "99.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "paramaters = [\n",
    "             {'n_estimators' : [100, 200, 300, 600, 800, 1000],\n",
    "              'max_features': [2, 4, 6, 8, 10, 12, 14], \n",
    "              'min_samples_leaf': [3, 4, 5],\n",
    "              'min_samples_split': [8, 10, 12],\n",
    "             },\n",
    "             ]\n",
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = paramaters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 20,\n",
    "                           n_jobs = -1,\n",
    "                           verbose=5)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_ \n",
    "best_parameters = grid_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', grid_search.best_score_)\n",
    "print('Best parameters :', grid_search.best_params_  )\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 20 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   34.6s\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy :  0.995663059551015\n",
      "Best parameters : {'n_estimators': 300, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': 4}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       844\n",
      "           1       0.97      0.99      0.98       156\n",
      "\n",
      "    accuracy                           0.99      1000\n",
      "   macro avg       0.99      0.99      0.99      1000\n",
      "weighted avg       1.00      0.99      1.00      1000\n",
      "\n",
      "[[840   4]\n",
      " [  1 155]]\n",
      "99.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint \n",
    "from scipy.stats import uniform\n",
    "\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "parameters = [\n",
    "             {'n_estimators' : [100, 200, 300, 600, 800, 1000],\n",
    "              'max_features': [2, 4, 6, 8, 10, 12, 14], \n",
    "              'min_samples_leaf': [3, 4, 5],\n",
    "              'min_samples_split': [8, 10, 12],\n",
    "             },\n",
    "             ]\n",
    "\n",
    "              \n",
    "\n",
    "n_iter_search = 20\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_distributions=parameters,cv=20,n_iter=n_iter_search,n_jobs = -1,verbose=1)\n",
    "\n",
    "random_search = random_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = random_search.best_score_ \n",
    "best_parameters = random_search.best_params_  \n",
    "\n",
    "print('Best accuracy : ', random_search.best_score_)\n",
    "print('Best parameters :',random_search.best_params_  )\n",
    "\n",
    "y_pred = random_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reduceer het aantal features nog verder en bekijk telkens de accuracy. Verklaar de resultaten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By reducing the features to the top 6, we can see that the accuracy score decreased from 99,6% to 99,5%. The slight decrease has to do with using a smaller dataset for the X values.Eventhough the model has not been improved, we clearly can see that the execution time has been further reduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kijk of je via boosting (Adaboost) de accuracy op de test set nog kunt verhogen. Het type classifier (base estimator) mag je zelf kiezen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       844\n",
      "           1       0.99      0.99      0.99       156\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      0.99      0.99      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "[[843   1]\n",
      " [  2 154]]\n",
      "99.7\n"
     ]
    }
   ],
   "source": [
    "clf_adaboost = AdaBoostClassifier(n_estimators=150,learning_rate=0.9)\n",
    "clf_adaboost.fit(X_train,y_train)\n",
    "\n",
    "y_pred = clf_adaboost.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the boosting method, I opted for the random forest classifier as it has the highest accuracy compared with the logistic regression and SVM classifier. As we can see from the adaboost result, the accuracy increased slightly from 99,5% to 99,7%. Therefore, there is a slight improvement with implementing the adaboost but remained the same with the initial classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general we can see that reducing the features for the random forest classifier is not ideal as it is not improving the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
